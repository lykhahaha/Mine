{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(image, kernel):\n",
    "    # grab the dimension of image nad kernel\n",
    "    iH, iW = image.shape[:2]\n",
    "    kH, kW = kernel.shape[:2]\n",
    "    \n",
    "    # allocate memory for the output image, taking care to \"pad\"\n",
    "    # the borders of the input image so the spatial size (i.e.,\n",
    "    # width and height) are not reduced\n",
    "    pad = (kW - 1) // 2\n",
    "    image = cv2.copyMakeBorder(image, pad, pad, pad, pad, cv2.BORDER_REPLICATE)\n",
    "    output = np.zeros((iH, iW), dtype='float')\n",
    "    \n",
    "    for y in range(pad, iH + pad):\n",
    "        for x in range(pad, iW + pad):\n",
    "            # extract the ROI of the image by extracting the *center* region of the current (x, y)-coordinates dimensions\n",
    "            roi = image[y - pad: y + pad + 1, x - pad: x + pad + 1]\n",
    "            # perform the actual convolution by taking the element-wise multiplication between the ROI and the kernel, then summing the matrix\n",
    "            K = (roi * kernel).sum()\n",
    "            # store the convolved value in the output (x, y)-coordinate of the output image\n",
    "            output[y - pad, x - pad] = K\n",
    "            \n",
    "    # rescale the output image to be in the range [0, 255]        \n",
    "    output = rescale_intensity(output, in_range=(0, 255))#  51.,  102.,  153. --> 0.2,  0.4,  0.6\n",
    "    output = (output * 255).astype('unit8')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['image'] = 'jemma.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct average blurring kernels used to smooth an image\n",
    "smallBlur = np.ones((7, 7), dtype=\"float\") * (1.0 / (7 * 7))\n",
    "largeBlur = np.ones((21, 21), dtype=\"float\") * (1.0 / (21 * 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a sharpening filter\n",
    "sharpen = np.array([[0, -1, 0],\n",
    "                    [-1, 5, -1],\n",
    "                    [0, -1, 0]], dtype=\"int\")\n",
    "# construct the Laplacian kernel used to detect edge-like regions of an imag\n",
    "laplacian = np.array([[0, 1, 0],\n",
    "                      [1, -4, 1],\n",
    "                      [0, 1, 0]], dtype=\"int\")\n",
    "# construct the Sobel x-axis kernel\n",
    "sobelX = np.array([[-1, 0, 1],\n",
    "                   [-2, 0, 2],\n",
    "                   [-1, 0, 1]], dtype=\"int\")\n",
    "# construct the Sobel y-axis kernel\n",
    "sobelY = np.array([[-1, -2, -1],\n",
    "                   [0, 0, 0],\n",
    "                   [1, 2, 1]], dtype=\"int\")\n",
    "# construct an emboss kernel\n",
    "emboss = np.array(([-2, -1, 0],\n",
    "                   [-1, 1, 1],\n",
    "                   [0, 1, 2]), dtype=\"int\")\n",
    "kernel_bank = ((\"small_blur\", smallBlur),\n",
    "              (\"large_blur\", largeBlur),\n",
    "              (\"sharpen\", sharpen),\n",
    "              (\"laplacian\", laplacian),\n",
    "              (\"sobel_x\", sobelX),\n",
    "              (\"sobel_y\", sobelY),\n",
    "              (\"emboss\", emboss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the input image and convert it to grayscale\n",
    "image = cv2.imread(args['image'])\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# loop over the kernels\n",
    "for kernel_name, K in kernel_bank:\n",
    "    # apply the kernel to the grayscale image using both our custom ‘convolve‘ function and OpenCV’s ‘filter2D‘ function\n",
    "    print(f'[INFO] applying {kernel_name} kernel')\n",
    "    convolve_output = convolve(gray, K)\n",
    "    opencv_output = cv2.filter2D(gray, -1, K)\n",
    "    \n",
    "    # show the output images\n",
    "    cv2.imshow('Original', gray)\n",
    "    cv2.imshow(f'{kernel_name} - convolve', convolve_output)\n",
    "    cv2.imshow(f'{kernel_name} - opencv', opencv_output)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

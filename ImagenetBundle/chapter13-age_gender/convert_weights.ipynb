{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from pyimagesearch.nn.conv import AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mxnet = mx.model.FeedForward.load('../../DL4CV/IB_Code/chapter05-alexnet/checkpoints/alexnet', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allow_extra_params',\n",
       " 'arg_params',\n",
       " 'aux_params',\n",
       " 'begin_epoch',\n",
       " 'ctx',\n",
       " 'epoch_size',\n",
       " 'initializer',\n",
       " 'num_epoch',\n",
       " 'numpy_batch_size',\n",
       " 'optimizer',\n",
       " 'symbol']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_mxnet.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fullyconnected1_bias', 'convolution3_bias', 'convolution1_weight', 'fullyconnected2_weight', 'batchnorm5_gamma', 'convolution1_bias', 'convolution3_weight', 'batchnorm0_beta', 'convolution0_weight', 'batchnorm4_beta', 'batchnorm1_beta', 'batchnorm1_gamma', 'convolution4_weight', 'batchnorm4_gamma', 'batchnorm6_gamma', 'convolution4_bias', 'batchnorm6_beta', 'batchnorm0_gamma', 'batchnorm2_gamma', 'fullyconnected1_weight', 'batchnorm2_beta', 'batchnorm3_beta', 'fullyconnected2_bias', 'convolution2_bias', 'batchnorm5_beta', 'batchnorm3_gamma', 'fullyconnected0_bias', 'convolution2_weight', 'fullyconnected0_weight', 'convolution0_bias', 'batchnorm0_moving_mean', 'batchnorm6_moving_mean', 'batchnorm4_moving_mean', 'batchnorm5_moving_mean', 'batchnorm4_moving_var', 'batchnorm3_moving_mean', 'batchnorm0_moving_var', 'batchnorm2_moving_mean', 'batchnorm2_moving_var', 'batchnorm6_moving_var', 'batchnorm5_moving_var', 'batchnorm1_moving_var', 'batchnorm1_moving_mean', 'batchnorm3_moving_var']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "layers_list = list(model_mxnet.get_params()['arg_params'].keys())\n",
    "layers_list.extend(list(model_mxnet.get_params()['aux_params'].keys()))\n",
    "print(layers_list)\n",
    "\n",
    "layers_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['fullyconnected1_bias',\n",
       "  'convolution1_weight',\n",
       "  'convolution1_bias',\n",
       "  'batchnorm1_beta',\n",
       "  'batchnorm1_gamma',\n",
       "  'fullyconnected1_weight',\n",
       "  'batchnorm1_moving_var',\n",
       "  'batchnorm1_moving_mean'],\n",
       " 3: ['convolution3_bias',\n",
       "  'convolution3_weight',\n",
       "  'batchnorm3_beta',\n",
       "  'batchnorm3_gamma',\n",
       "  'batchnorm3_moving_mean',\n",
       "  'batchnorm3_moving_var'],\n",
       " 2: ['fullyconnected2_weight',\n",
       "  'batchnorm2_gamma',\n",
       "  'batchnorm2_beta',\n",
       "  'fullyconnected2_bias',\n",
       "  'convolution2_bias',\n",
       "  'convolution2_weight',\n",
       "  'batchnorm2_moving_mean',\n",
       "  'batchnorm2_moving_var'],\n",
       " 5: ['batchnorm5_gamma',\n",
       "  'batchnorm5_beta',\n",
       "  'batchnorm5_moving_mean',\n",
       "  'batchnorm5_moving_var'],\n",
       " 0: ['batchnorm0_beta',\n",
       "  'convolution0_weight',\n",
       "  'batchnorm0_gamma',\n",
       "  'fullyconnected0_bias',\n",
       "  'fullyconnected0_weight',\n",
       "  'convolution0_bias',\n",
       "  'batchnorm0_moving_mean',\n",
       "  'batchnorm0_moving_var'],\n",
       " 4: ['batchnorm4_beta',\n",
       "  'convolution4_weight',\n",
       "  'batchnorm4_gamma',\n",
       "  'convolution4_bias',\n",
       "  'batchnorm4_moving_mean',\n",
       "  'batchnorm4_moving_var'],\n",
       " 6: ['batchnorm6_gamma',\n",
       "  'batchnorm6_beta',\n",
       "  'batchnorm6_moving_mean',\n",
       "  'batchnorm6_moving_var']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in layers_list:\n",
    "    layer_nb = re.findall('[\\d+]', layer)[0]\n",
    "    layer_list = layers_dict.get(int(layer_nb), [])\n",
    "    layer_list.append(layer)\n",
    "    layers_dict[int(layer_nb)] = layer_list\n",
    "layers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\huong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\huong\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model_keras = AlexNet.build(227, 227, 3, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(11, 11, 3, 96)\tconv2d_1/kernel:0\n",
      "(96,)\tconv2d_1/bias:0\n",
      "\n",
      "1\n",
      "(96,)\tbatch_normalization_1/gamma:0\n",
      "(96,)\tbatch_normalization_1/beta:0\n",
      "(96,)\tbatch_normalization_1/moving_mean:0\n",
      "(96,)\tbatch_normalization_1/moving_variance:0\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "(5, 5, 96, 256)\tconv2d_2/kernel:0\n",
      "(256,)\tconv2d_2/bias:0\n",
      "\n",
      "5\n",
      "(256,)\tbatch_normalization_2/gamma:0\n",
      "(256,)\tbatch_normalization_2/beta:0\n",
      "(256,)\tbatch_normalization_2/moving_mean:0\n",
      "(256,)\tbatch_normalization_2/moving_variance:0\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "(3, 3, 256, 384)\tconv2d_3/kernel:0\n",
      "(384,)\tconv2d_3/bias:0\n",
      "\n",
      "9\n",
      "(384,)\tbatch_normalization_3/gamma:0\n",
      "(384,)\tbatch_normalization_3/beta:0\n",
      "(384,)\tbatch_normalization_3/moving_mean:0\n",
      "(384,)\tbatch_normalization_3/moving_variance:0\n",
      "\n",
      "10\n",
      "(3, 3, 384, 384)\tconv2d_4/kernel:0\n",
      "(384,)\tconv2d_4/bias:0\n",
      "\n",
      "11\n",
      "(384,)\tbatch_normalization_4/gamma:0\n",
      "(384,)\tbatch_normalization_4/beta:0\n",
      "(384,)\tbatch_normalization_4/moving_mean:0\n",
      "(384,)\tbatch_normalization_4/moving_variance:0\n",
      "\n",
      "12\n",
      "(3, 3, 384, 256)\tconv2d_5/kernel:0\n",
      "(256,)\tconv2d_5/bias:0\n",
      "\n",
      "13\n",
      "(256,)\tbatch_normalization_5/gamma:0\n",
      "(256,)\tbatch_normalization_5/beta:0\n",
      "(256,)\tbatch_normalization_5/moving_mean:0\n",
      "(256,)\tbatch_normalization_5/moving_variance:0\n",
      "\n",
      "14\n",
      "\n",
      "15\n",
      "\n",
      "16\n",
      "\n",
      "17\n",
      "(9216, 4096)\tdense_1/kernel:0\n",
      "(4096,)\tdense_1/bias:0\n",
      "\n",
      "18\n",
      "(4096,)\tbatch_normalization_6/gamma:0\n",
      "(4096,)\tbatch_normalization_6/beta:0\n",
      "(4096,)\tbatch_normalization_6/moving_mean:0\n",
      "(4096,)\tbatch_normalization_6/moving_variance:0\n",
      "\n",
      "19\n",
      "\n",
      "20\n",
      "(4096, 4096)\tdense_2/kernel:0\n",
      "(4096,)\tdense_2/bias:0\n",
      "\n",
      "21\n",
      "(4096,)\tbatch_normalization_7/gamma:0\n",
      "(4096,)\tbatch_normalization_7/beta:0\n",
      "(4096,)\tbatch_normalization_7/moving_mean:0\n",
      "(4096,)\tbatch_normalization_7/moving_variance:0\n",
      "\n",
      "22\n",
      "\n",
      "23\n",
      "(4096, 1000)\tdense_3/kernel:0\n",
      "(1000,)\tdense_3/bias:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_keras.layers):\n",
    "    print(i)\n",
    "    for weight in layer.weights:\n",
    "        print(f'{weight.shape}\\t{weight.name}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batchnorm0_beta', 'convolution0_weight', 'batchnorm0_gamma', 'fullyconnected0_bias', 'fullyconnected0_weight', 'convolution0_bias', 'batchnorm0_moving_mean', 'batchnorm0_moving_var']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Layer 0: Conv2D -> BN\n",
    "layers_name = layers_dict[0]\n",
    "print(layers_name)\n",
    "\n",
    "conv_weight = model_mxnet.arg_params['convolution0_weight'].asnumpy()\n",
    "conv = [np.transpose(conv_weight.T, (1, 0, 2, -1)), \n",
    "        model_mxnet.arg_params['convolution0_bias'].asnumpy()]\n",
    "model_keras.layers[0].set_weights(conv)\n",
    "\n",
    "batch_norm = [model_mxnet.arg_params['batchnorm0_gamma'].asnumpy(),\n",
    "             model_mxnet.arg_params['batchnorm0_beta'].asnumpy(),\n",
    "             model_mxnet.aux_params['batchnorm0_moving_mean'].asnumpy(),\n",
    "             model_mxnet.aux_params['batchnorm0_moving_var'].asnumpy()]\n",
    "model_keras.layers[1].set_weights(batch_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fullyconnected1_bias', 'convolution1_weight', 'convolution1_bias', 'batchnorm1_beta', 'batchnorm1_gamma', 'fullyconnected1_weight', 'batchnorm1_moving_var', 'batchnorm1_moving_mean']\n"
     ]
    }
   ],
   "source": [
    "# Layer 1: Conv2D -> BN\n",
    "layers_name = layers_dict[1]\n",
    "print(layers_name)\n",
    "\n",
    "conv_weight = model_mxnet.arg_params['convolution1_weight'].asnumpy()\n",
    "conv = [np.transpose(conv_weight.T, (1, 0, 2, -1)), \n",
    "        model_mxnet.arg_params['convolution1_bias'].asnumpy()]\n",
    "model_keras.layers[4].set_weights(conv)\n",
    "\n",
    "batch_norm = [model_mxnet.arg_params['batchnorm1_gamma'].asnumpy(),\n",
    "             model_mxnet.arg_params['batchnorm1_beta'].asnumpy(),\n",
    "             model_mxnet.aux_params['batchnorm1_moving_mean'].asnumpy(),\n",
    "             model_mxnet.aux_params['batchnorm1_moving_var'].asnumpy()]\n",
    "model_keras.layers[5].set_weights(batch_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fullyconnected2_weight', 'batchnorm2_gamma', 'batchnorm2_beta', 'fullyconnected2_bias', 'convolution2_bias', 'convolution2_weight', 'batchnorm2_moving_mean', 'batchnorm2_moving_var']\n",
      "['convolution3_bias', 'convolution3_weight', 'batchnorm3_beta', 'batchnorm3_gamma', 'batchnorm3_moving_mean', 'batchnorm3_moving_var']\n",
      "['batchnorm4_beta', 'convolution4_weight', 'batchnorm4_gamma', 'convolution4_bias', 'batchnorm4_moving_mean', 'batchnorm4_moving_var']\n"
     ]
    }
   ],
   "source": [
    "# Layer 2: Conv2D -> BN -> Conv2D -> BN -> Conv2D -> BN\n",
    "mxnet_start_idx = 2\n",
    "keras_layer_idx = 8\n",
    "nb_layer_repeat = 3\n",
    "for m_idx, k_idx in zip(range(mxnet_start_idx, mxnet_start_idx+nb_layer_repeat), range(keras_layer_idx, keras_layer_idx+nb_layer_repeat*2, 2)):\n",
    "    layers_name = layers_dict[m_idx]\n",
    "    print(layers_name)\n",
    "    \n",
    "    conv_weight = model_mxnet.arg_params[f'convolution{m_idx}_weight'].asnumpy()\n",
    "    conv = [np.transpose(conv_weight.T, (1, 0, 2, -1)), \n",
    "            model_mxnet.arg_params[f'convolution{m_idx}_bias'].asnumpy()]\n",
    "    model_keras.layers[k_idx].set_weights(conv)\n",
    "\n",
    "    batch_norm = [model_mxnet.arg_params[f'batchnorm{m_idx}_gamma'].asnumpy(),\n",
    "                 model_mxnet.arg_params[f'batchnorm{m_idx}_beta'].asnumpy(),\n",
    "                 model_mxnet.aux_params[f'batchnorm{m_idx}_moving_mean'].asnumpy(),\n",
    "                 model_mxnet.aux_params[f'batchnorm{m_idx}_moving_var'].asnumpy()]\n",
    "    model_keras.layers[k_idx+1].set_weights(batch_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batchnorm5_gamma', 'batchnorm5_beta', 'batchnorm5_moving_mean', 'batchnorm5_moving_var']\n",
      "['batchnorm6_gamma', 'batchnorm6_beta', 'batchnorm6_moving_mean', 'batchnorm6_moving_var']\n"
     ]
    }
   ],
   "source": [
    "# Last layers: FC -> BN -> FC -> BN -> FC\n",
    "layers_name = layers_dict[5]\n",
    "print(layers_name)\n",
    "\n",
    "dense_weight = model_mxnet.arg_params['fullyconnected0_weight'].asnumpy()\n",
    "conv = [dense_weight.T, \n",
    "        model_mxnet.arg_params['fullyconnected0_bias'].asnumpy()]\n",
    "model_keras.layers[17].set_weights(conv)\n",
    "\n",
    "batch_norm = [model_mxnet.arg_params['batchnorm5_gamma'].asnumpy(),\n",
    "             model_mxnet.arg_params['batchnorm5_beta'].asnumpy(),\n",
    "             model_mxnet.aux_params['batchnorm5_moving_mean'].asnumpy(),\n",
    "             model_mxnet.aux_params['batchnorm5_moving_var'].asnumpy()]\n",
    "model_keras.layers[18].set_weights(batch_norm)\n",
    "\n",
    "layers_name = layers_dict[6]\n",
    "print(layers_name)\n",
    "\n",
    "dense_weight = model_mxnet.arg_params['fullyconnected1_weight'].asnumpy()\n",
    "conv = [dense_weight.T, \n",
    "        model_mxnet.arg_params['fullyconnected1_bias'].asnumpy()]\n",
    "model_keras.layers[20].set_weights(conv)\n",
    "\n",
    "batch_norm = [model_mxnet.arg_params['batchnorm6_gamma'].asnumpy(),\n",
    "             model_mxnet.arg_params['batchnorm6_beta'].asnumpy(),\n",
    "             model_mxnet.aux_params['batchnorm6_moving_mean'].asnumpy(),\n",
    "             model_mxnet.aux_params['batchnorm6_moving_var'].asnumpy()]\n",
    "model_keras.layers[21].set_weights(batch_norm)\n",
    "\n",
    "dense_weight = model_mxnet.arg_params['fullyconnected2_weight'].asnumpy()\n",
    "conv = [dense_weight.T, \n",
    "        model_mxnet.arg_params['fullyconnected2_bias'].asnumpy()]\n",
    "\n",
    "model_keras.layers[23].set_weights(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.save('alexnet_imagenet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

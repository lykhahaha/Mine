{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from random import randint\n",
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = np.load('wordsList.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mì_chính'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = wordsList.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordVectors = np.load('wordVectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordVectors = np.float32(wordVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of `nhà_nước` in wordsList: 10829\n",
      "Vector representation of `nhà_nước`: [-7.800e-03  2.060e-02  1.900e-02  2.570e-02 -2.250e-02 -1.470e-02\n",
      "  6.100e-02  8.300e-03  4.170e-02  1.230e-02 -1.670e-02 -5.700e-02\n",
      " -5.400e-03  1.860e-02 -1.170e-02  8.800e-03  1.200e-03  1.430e-02\n",
      " -2.770e-02 -2.160e-02  4.490e-02 -2.500e-03 -4.000e-03  1.660e-02\n",
      "  5.520e-02 -3.600e-03  3.690e-02  1.640e-02  2.260e-02 -2.640e-02\n",
      "  9.400e-03  1.040e-02 -6.000e-03 -9.700e-03  4.900e-03 -2.300e-03\n",
      "  4.570e-02 -1.420e-02 -7.400e-03  3.190e-02  1.930e-02 -3.430e-02\n",
      "  1.340e-02  1.020e-02 -4.980e-02 -5.600e-03 -7.400e-03  7.200e-03\n",
      "  2.640e-02 -2.000e-02  5.200e-03 -1.400e-03  3.230e-02  1.270e-02\n",
      " -2.950e-02  8.400e-03  2.520e-02 -2.990e-02 -2.050e-02 -2.250e-02\n",
      " -3.000e-03  7.400e-03 -3.320e-02 -4.490e-02  1.490e-02 -3.640e-02\n",
      "  8.200e-03 -1.940e-02  6.470e-02  1.400e-03 -3.800e-03  1.080e-02\n",
      "  2.320e-02 -5.800e-03 -5.300e-03  1.360e-02 -2.200e-03  2.640e-02\n",
      "  1.660e-02 -1.810e-02 -4.240e-02  1.150e-02 -3.370e-02 -3.250e-02\n",
      " -3.940e-02  2.990e-02  6.800e-03 -1.310e-02  4.580e-02  6.100e-03\n",
      " -4.200e-02 -5.200e-03 -4.480e-02 -1.500e-03 -1.900e-03  1.710e-02\n",
      " -5.200e-03  2.580e-02 -3.100e-03  2.800e-03 -2.510e-02 -3.460e-02\n",
      " -3.430e-02 -2.590e-02 -1.530e-02 -4.350e-02 -9.800e-03  1.630e-02\n",
      " -1.000e-04  3.000e-03 -6.420e-02 -1.030e-02  2.450e-02 -1.240e-02\n",
      " -4.630e-02 -6.600e-03 -4.000e-04  2.600e-03  9.200e-03 -3.790e-02\n",
      "  2.350e-02  2.570e-02  1.050e-02 -7.000e-04 -1.700e-02 -4.000e-04\n",
      "  5.270e-02 -1.090e-02 -1.220e-02  2.770e-02 -6.900e-03 -7.300e-03\n",
      " -1.250e-02 -4.100e-03  2.600e-03 -4.660e-02 -2.510e-02  5.570e-02\n",
      "  5.810e-02  1.810e-02  1.300e-03 -2.090e-02 -3.200e-03 -2.810e-02\n",
      "  1.100e-02 -1.200e-03  3.250e-02  3.580e-02  1.900e-03  1.400e-03\n",
      "  1.380e-02  2.960e-02  2.800e-03 -2.270e-02 -5.800e-03 -3.170e-02\n",
      " -1.890e-02 -2.250e-02 -5.210e-02  1.410e-02 -3.390e-02 -3.400e-02\n",
      " -4.020e-02 -1.630e-02 -3.200e-03  8.020e-02 -1.600e-03  2.630e-02\n",
      " -6.100e-03  3.670e-02  5.900e-03  4.700e-03  4.450e-02  1.040e-02\n",
      "  1.420e-02  3.300e-03  1.000e-03  3.500e-02 -1.610e-02  1.080e-02\n",
      "  2.490e-02 -8.600e-03  5.470e-02  3.000e-02  5.510e-02 -8.600e-03\n",
      "  5.160e-02  3.620e-02  8.000e-04 -1.510e-02 -2.240e-02 -2.300e-03\n",
      " -2.760e-02 -3.090e-02 -1.820e-02  5.500e-02  7.200e-03 -1.910e-02\n",
      "  3.020e-02 -1.910e-02  3.050e-02 -2.770e-02  9.300e-03 -2.550e-02\n",
      " -3.320e-02 -1.850e-02  2.190e-02  5.720e-02  2.860e-02 -2.800e-03\n",
      "  4.430e-02 -4.410e-02 -1.200e-03 -2.520e-02  4.240e-02 -1.510e-02\n",
      "  1.910e-02  9.500e-03 -1.840e-02  7.000e-03  3.850e-02  3.470e-02\n",
      " -1.880e-02  1.190e-02 -1.740e-02 -5.100e-03 -1.010e-02 -2.400e-03\n",
      "  4.750e-02 -1.063e-01  1.530e-02 -4.080e-02 -1.820e-02  1.870e-02\n",
      " -1.300e-02  9.300e-03  1.060e-02  1.080e-02  2.080e-02 -4.750e-02\n",
      "  5.130e-02 -1.810e-02 -5.580e-02  4.250e-02 -4.680e-02 -1.290e-02\n",
      " -2.430e-02 -1.090e-02  2.660e-02 -2.400e-03 -6.000e-03 -1.120e-02\n",
      "  4.760e-02 -9.000e-03  4.470e-02  4.500e-03  5.400e-03  1.800e-03\n",
      " -2.720e-02 -5.820e-02  3.300e-03 -4.900e-03 -5.680e-02 -3.160e-02\n",
      "  2.400e-03 -2.630e-02  3.260e-02  2.750e-02 -9.800e-03  3.780e-02\n",
      " -1.690e-02 -1.480e-02  3.080e-02 -1.570e-02 -4.700e-03 -4.670e-02\n",
      " -1.080e-02 -9.000e-03 -4.440e-02  3.700e-03  1.460e-02 -5.560e-02\n",
      "  5.680e-02  1.970e-02 -2.920e-02 -5.800e-03 -2.070e-02  8.200e-03\n",
      " -3.110e-02  2.180e-02  3.030e-02 -9.300e-03  5.400e-02  7.200e-03\n",
      "  1.130e-02 -4.700e-03  3.630e-02 -9.120e-02 -3.010e-02  1.490e-02]\n"
     ]
    }
   ],
   "source": [
    "nn_idx = wordsList.index('nhà_nước')\n",
    "print('Index of `nhà_nước` in wordsList:', nn_idx)\n",
    "nn_vec = wordVectors[nn_idx]\n",
    "print('Vector representation of `nhà_nước`:', nn_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  119,  8136,  4884, 18791, 16614, 15951,  3371,     0,     0,\n",
       "           0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Món này ăn hoài không biết chán'\n",
    "maxSeqLength = 10\n",
    "numDimensions = 300\n",
    "sentenceIndexes = np.zeros((maxSeqLength), dtype=np.int32)\n",
    "\n",
    "word_in_sentence = [word.lower() for word in sentence.split()]\n",
    "for i in range(len(word_in_sentence)):\n",
    "    idx =  wordsList.index(word_in_sentence[i])\n",
    "    sentenceIndexes[i] = idx\n",
    "\n",
    "sentenceIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    lookup_words = sess.run(tf.nn.embedding_lookup(wordVectors, sentenceIndexes))\n",
    "\n",
    "lookup_words.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveFiles = ['positiveReviews/' + f for f in listdir('positiveReviews/') if isfile(join('positiveReviews/', f))]\n",
    "negativeFiles = ['negativeReviews/' + f for f in listdir('negativeReviews/') if isfile(join('negativeReviews/', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWords = []\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, 'r', encoding='utf-8') as f:\n",
    "        line = f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nf in negativeFiles:\n",
    "    with open(nf, 'r', encoding='utf-8') as f:\n",
    "        line = f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of files is 30000\n",
      "The total number of words in the files is 1770824\n",
      "The average number of words in the files is 59.02746666666667\n"
     ]
    }
   ],
   "source": [
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 400, 0, 4000]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2cb77564080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 400, 0, 4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A positive sentence:\n",
      "Hôm_nay mình quay lại quán cùng_với mấy người bạn ở Sài_Gòn xuống , cũng lâu lắm rồi mình không ghé quán ốc này luôn nên được bữa ăn cho đã nè Vẫn không_gian tấp_nập xô_bồ , nhưng hên là vẫn còn bàn cho nhóm tụi mình , nhưng đợi xếp bàn hơi lâu không được vô rồi ngồi liền đâu , hôm_nay lại là ngày cao_điểm nữa\n",
      "\n",
      "A negative sentence:\n",
      "nhân_viên phục_vụ không mấy tận_tình , đồ_ăn ra lâu và không đều , món cơm thịt bò nướng ngon , còn mì soba xào không được ngon cho lắm .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('A positive sentence:')\n",
    "fname = positiveFiles[3]\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    print(line)\n",
    "\n",
    "print('A negative sentence:')\n",
    "fname = negativeFiles[3]\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "strip_special_chars = re.compile('[^\\w0-9 ]+')\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.zeros((numFiles, maxSeqLength), dtype=np.int32)\n",
    "nFiles = 0\n",
    "unk_idx = wordsList.index('UNK')\n",
    "\n",
    "for pf_idx in range(len(positiveFiles)):\n",
    "    with open(positiveFiles[pf_idx], 'r', encoding='utf-8') as f:\n",
    "        # nIndexes = 0\n",
    "        line = f.readline()\n",
    "        cleanedLine = cleanSentences(line)\n",
    "        split = cleanedLine.split()\n",
    "        for word_idx in range(len(split)):\n",
    "            if word_idx >= maxSeqLength:\n",
    "                break\n",
    "            try:\n",
    "                idx = wordsList.index(split[word_idx])\n",
    "                ids[pf_idx, word_idx] = idx\n",
    "            except ValueError:\n",
    "                ids[pf_idx, word_idx] = unk_idx\n",
    "\n",
    "for nf_idx in range(len(positiveFiles), len(positiveFiles)+len(negativeFiles)):\n",
    "    with open(negativeFiles[nf_idx-len(positiveFiles)], 'r', encoding='utf-8') as f:\n",
    "        # nIndexes = 0\n",
    "        line = f.readline()\n",
    "        cleanedLine = cleanSentences(line)\n",
    "        split = cleanedLine.split()\n",
    "        for word_idx in range(len(split)):\n",
    "            if word_idx >= maxSeqLength:\n",
    "                break\n",
    "            try:\n",
    "                idx = wordsList.index(split[word_idx])\n",
    "                ids[nf_idx, word_idx] = idx\n",
    "            except ValueError:\n",
    "                ids[nf_idx, word_idx] = unk_idx\n",
    "            \n",
    "np.save('idsMatrix.npy', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positiveFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xe_đẩy bán cơm_chiên nằm ngay đầu đường vào khu dân_cư metro , chạy từ ngoài vô là xe thứ_hai nhé . Mình hay mua cơm của chị này lắm , cơm_chiên mềm , nóng_ăn chung với trứng chiên , lạp_xưởng , thịt heo và chà bông nên vừa ăn lắm mà có thêm dưa_leo và cà_chua nên ăn_không ngán , ăn xong hợp cơm là bao no đến trưa . Giá chủ có 10/1 hộp à . Buổi_sáng rất đông người ghé mua , vì bán vừa ngon vừa rẻ lại ăn rất no . Tuy đông nhưng chị làm nhanh lắm mà nói_chuyện với khách cũng vui_vẻ lịch_sự nữa nên lần nào đi ngang buổi_sáng là ghé mua hoài à .\n",
      "\n",
      "xe_đẩy bán cơm_chiên nằm ngay đầu đường vào khu dân_cư metro  chạy từ ngoài vô là xe thứ_hai nhé  mình hay mua cơm của chị này lắm  cơm_chiên mềm  nóng_ăn chung với trứng chiên  lạp_xưởng  thịt heo và chà bông nên vừa ăn lắm mà có thêm dưa_leo và cà_chua nên ăn_không ngán  ăn xong hợp cơm là bao no đến trưa  giá chủ có 101 hộp à  buổi_sáng rất đông người ghé mua  vì bán vừa ngon vừa rẻ lại ăn rất no  tuy đông nhưng chị làm nhanh lắm mà nói_chuyện với khách cũng vui_vẻ lịch_sự nữa nên lần nào đi ngang buổi_sáng là ghé mua hoài à \n"
     ]
    }
   ],
   "source": [
    "with open(positiveFiles[0], 'r', encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    cleanedLine = cleanSentences(line)\n",
    "    split = cleanedLine.split()\n",
    "    print(line)\n",
    "    print(cleanedLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19898,  1906,  4454,  5284, 10661, 11694, 11994, 18784, 18569,\n",
       "       18619, 13174,  9821, 14794,  8884,  6443,  5767,  8589, 18850,\n",
       "       15570,  5596,   799, 11060,  4222, 16893, 13078,  8136,  3364,\n",
       "        4454,  4756, 10304,  8885,  3553,  9782,  1232, 14359, 10606,\n",
       "         579, 15522,  2219, 15092, 14855, 15253,  4884,  3364,  5519,\n",
       "        4558,  9649,   269, 15522, 12309, 14855, 11503,  2212,  4884,\n",
       "        7155, 11577,  4222,  5767, 15076, 12225, 10774,  1218,  2876,\n",
       "       19584,  4558,  2974, 13452,  5013,   842, 10642, 17292, 11895,\n",
       "         803, 11060, 16760,  1906, 15253, 14598, 15253,  1047,  5668,\n",
       "        4884, 10642, 12225,  7090, 17292, 18109, 13078, 16334,  1238,\n",
       "        3364,  5519,  4135,  3553, 14967,  4964, 15385,  9673,  2997,\n",
       "       14855,  7446,  8038, 11440,  1345,   842,  5767,   803, 11060,\n",
       "       18791,  5013,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.load('idsMatrix.npy')\n",
    "ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19898,  1906,  4454,  5284, 10661, 11694, 11994, 18784, 18569,\n",
       "        18619, 13174,  9821, 14794,  8884,  6443,  5767,  8589, 18850,\n",
       "        15570,  5596,   799, 11060,  4222, 16893, 13078,  8136,  3364,\n",
       "         4454,  4756, 10304,  8885,  3553,  9782,  1232, 14359, 10606,\n",
       "          579, 15522,  2219, 15092, 14855, 15253,  4884,  3364,  5519,\n",
       "         4558,  9649,   269, 15522, 12309, 14855, 11503,  2212,  4884,\n",
       "         7155, 11577,  4222,  5767, 15076, 12225, 10774,  1218,  2876,\n",
       "        19584,  4558,  2974, 13452,  5013,   842, 10642, 17292, 11895,\n",
       "          803, 11060, 16760,  1906, 15253, 14598, 15253,  1047,  5668,\n",
       "         4884, 10642, 12225,  7090, 17292, 18109, 13078, 16334,  1238,\n",
       "         3364,  5519,  4135,  3553, 14967,  4964, 15385,  9673,  2997,\n",
       "        14855,  7446,  8038, 11440,  1345,   842,  5767,   803, 11060,\n",
       "        18791,  5013,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros((batchSize, maxSeqLength))\n",
    "    for i in range(batchSize):\n",
    "        if i % 2 == 0:\n",
    "            # Pick positive samples randomly\n",
    "            num = randint(1, 14000)\n",
    "            labels.append([1, 0])\n",
    "        else:\n",
    "            # Pick negative samples randomly\n",
    "            num = randint(16001, 30000)\n",
    "            labels.append([0, 1])\n",
    "            \n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros((batchSize, maxSeqLength))\n",
    "    for i in range(batchSize):\n",
    "        num = randint(14001, 16000)\n",
    "        if num <= 15000:\n",
    "            labels.append([1, 0])\n",
    "        else:\n",
    "            labels.append([0, 1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize paramters\n",
    "numDimensions = 300\n",
    "batchSize = 64\n",
    "lstmUnits = 128\n",
    "nLayers = 2\n",
    "numClasses = 2\n",
    "iterations = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "labels = tf.placeholder(tf.float32, shape=[batchSize, numClasses], name='labels')\n",
    "inputs = tf.placeholder(tf.int32, shape=[batchSize, maxSeqLength], name='inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.Variable(tf.zeros((batchSize, maxSeqLength, numDimensions)), dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "def generate_a_lstm_layer():\n",
    "    basic_lstm = tf.contrib.rnn.BasicLSTMCell(num_units=lstmUnits)\n",
    "    drop_out = tf.contrib.rnn.DropoutWrapper(cell=basic_lstm, output_keep_prob=0.75)\n",
    "    return drop_out\n",
    "\n",
    "multi_layer = tf.nn.rnn_cell.MultiRNNCell([generate_a_lstm_layer() for _ in range(nLayers)])\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(3), Dimension(2)])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[[ 1,  2,  3],\n",
    "                  [ 4,  5,  6]],\n",
    "                 [[ 7,  8,  9],\n",
    "                  [10, 11, 12]]])\n",
    "print(x.shape)\n",
    "x = tf.transpose(x, perm=[1, 2, 0])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(3), Dimension(2)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[[1, 4], [2, 5], [3, 6]], [[7, 10], [8, 11], [9, 12]]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "\n",
    "outputs = tf.transpose(outputs, [1, 0 , 2])\n",
    "last = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)\n",
    "\n",
    "predict = tf.matmul(last, weight) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_result = tf.equal(tf.argmax(predict, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_result, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-4be5307e4de4>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to models/pretrained_lstm.ckpt-2000\n",
      "saved to models/pretrained_lstm.ckpt-4000\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# saver = tf.train.Saver()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for i in range(iterations):\n",
    "#     next_batch, next_batch_labels = getTrainBatch()\n",
    "#     sess.run(optimizer, feed_dict={inputs: next_batch, labels: next_batch_labels})\n",
    "    \n",
    "#     if (i % 50 == 0):\n",
    "#         summary = sess.run(merged, {inputs: next_batch, labels: next_batch_labels})\n",
    "#         writer.add_summary(summary, i)\n",
    "\n",
    "#     # Save model every 2000 training iterations\n",
    "#     if (i % 2000 == 0 and i != 0):\n",
    "#         save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "#         print(\"saved to %s\" % save_path)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models_3\\pretrained_lstm.ckpt-30000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models_3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'Món này ăn hơi đắng'\n",
    "# input_sentence = ViTokenizer.tokenize(input_sentence)\n",
    "input_sentence = word_tokenize(input_sentence, format='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 180)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input_sentence = 'Món này ăn ngon mê ly luôn. Vị ngọt và thơm quá trời quá đất.'\n",
    "#input_sentence = 'Món bánh_bao này ăn có_vẻ đã để lâu'\n",
    "\n",
    "def input_to_batch_size(input_sentence):\n",
    "    arr = np.zeros((batchSize, maxSeqLength), dtype=np.int32)\n",
    "    cleanedLine = cleanSentences(input_sentence)\n",
    "    split = cleanedLine.split()\n",
    "    unk_idx = wordsList.index('UNK')\n",
    "    \n",
    "    tmp = np.zeros(maxSeqLength)\n",
    "    for word_idx in range(len(split)):\n",
    "        if word_idx >= maxSeqLength:\n",
    "            break\n",
    "        try:\n",
    "            idx = wordsList.index(split[word_idx])\n",
    "            tmp[word_idx] = idx\n",
    "        except ValueError:\n",
    "            tmp[word_idx] = unk_idx\n",
    "    \n",
    "    arr[0] = tmp\n",
    "    return arr\n",
    "\n",
    "input_sentence = input_to_batch_size(input_sentence)\n",
    "input_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.350616 ,  1.8715616], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence = sess.run(predict, feed_dict={inputs: input_sentence})\n",
    "predict_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The comment is Negative\n"
     ]
    }
   ],
   "source": [
    "idx = sess.run(tf.argmax(predict_sentence,1))\n",
    "if idx[0] == 1:\n",
    "    print('The comment is Negative')\n",
    "else:\n",
    "    print('The comment is Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentence = sess.run(predict, feed_dict={inputs: input_sentence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = sess.run(tf.argmax(predict_sentence,1))\n",
    "idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giới thiệu\n",
    "\n",
    "### Tổng quan\n",
    "\n",
    "Chào mừng đã đến bài lab đầu tiên trong Khóa học VietAI. Lần này bạn sẽ học cách tương tác với hai thư viện được biết đến nhiều nhất - Numpy và TensorFlow. Bài toán chúng ta sẽ giải quyết trong buổi hôm nay là linear regression.\n",
    "\n",
    "Trong lớp thí điểm này, các bài tập sẽ được áp dụng từ chương trình mở về khóa học sâu từ các trường đại học và nhiều nguồn mở khác.\n",
    " \n",
    "### Mục tiêu học tập\n",
    "\n",
    "* Hiểu thêm về cách hoạt động của Numpy và Tensorflow \n",
    "* Có thể viết một thuật toán đơn giản (và debug) với `Tensorflow` và `Numpy` qua ví dụ về hồi quy tuyến tính.\n",
    "* Hiểu thêm về hồi quy tuyến tính.\n",
    "\n",
    "# Giới thiệu\n",
    "\n",
    "Bài toán lần này, chúng ta sẽ cùng nhau dự đoán giá nhà tại một thành phố Boston ở Mỹ với kích thước mẫu với 506 giá trị với 13 thuộc tính như sau\n",
    "\n",
    "```\n",
    "- CRIM per capita crime rate by town\n",
    "- ZN proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS proportion of non-retail business acres per town\n",
    "- CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX nitric oxides concentration (parts per 10 million)\n",
    "- RM average number of rooms per dwelling\n",
    "- AGE proportion of owner-occupied units built prior to 1940\n",
    "- DIS weighted distances to five Boston employment centres\n",
    "- RAD index of accessibility to radial highways\n",
    "- TAX full-value property-tax rate per $10,000\n",
    "- PTRATIO pupil-teacher ratio by town\n",
    "- B 1000(Bk - 0.63)ˆ2 where Bk is the proportion of blacks by town\n",
    "- LSTAT % lower status of the population\n",
    "- MEDV Median value of owner-occupied homes in $1000's\n",
    "```\n",
    "\n",
    "Với thông tin này, ta sẽ cùng nhau tiến hành xây dựng một hàm giả thuyết theo mô hình hồi quy tuyến tính dựa trên `numpy` và `tensorflow` để đưa ra giá nhà dựa trên ít nhất là 2 thuộc tính."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tìm nghiệm xấp xỉ bằng `Numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nhập thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected original features are ['INDUS' 'RM']\n"
     ]
    }
   ],
   "source": [
    "from utils_function import load_Boston_housing_data\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = load_Boston_housing_data(feature_ind = [2,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vừa rồi, ta vừa mới tải tập dữ liệu xuống và chiết ra thành 4 tập. \n",
    "\n",
    "Trong đó, `train_X` và `train_Y` được dùng để xây dựng mô hình. Còn `test_X`, `test_Y` được giữ lại và chỉ được dùng để đánh giá độ tốt của mô hình ở phút cuối. \n",
    "\n",
    "Tỉ lệ được chia ra giữa các phần xây dựng và kiểm chứng là 1:4 Sau này, chúng ta sẽ học kỹ hơn về phần này nên phần đánh giá độ tốt của mô hình mình chỉ dừng lại ở mức là thực thi câu hàm đánh giá.\n",
    "\n",
    "Để đơn giản, dữ liệu được lấy vào chỉ gồm 2 đặc tính\n",
    "\n",
    "```\n",
    "    - INDUS proportion of non-retail business acres per town\n",
    "    - RM average number of rooms per dwelling\n",
    "```\n",
    "\n",
    "Tạm dịch\n",
    "\n",
    "```\n",
    "    - INDUS: tỷ lệ diện tích không dùng cho kinh doanh bán lẻ mỗi thị trấn\n",
    "    - RM: số phòng trung bình mỗi căn hộ/ nhà\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn có thể lấy thêm các đặc tính khác qua việc thiết lập lại hàm `load_data` như sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mload_Boston_housing_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_ind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Load Boston Dataset from Sklearn.\n",
       "\n",
       "Args:\n",
       "  test_ratio(float)       : a proportion between train set and test set. Default = 0.2\n",
       "  feature_ind(list(int))  : a list of index feature to be extracted from the original data set. No indication\n",
       "                            means that all feature is chosen.\n",
       "  random_state(int)       : a seed value for shuffling between values\n",
       "  print_info(boolean)     : True if print the information of data set. Default: False\n",
       "  \n",
       "Returns:\n",
       "  a tuple of four np.array data sets train_data, test_data, train_targets, test_targets\n",
       "  \n",
       "\u001b[1;31mFile:\u001b[0m      f:\\data science\\vietai\\week03\\utils_function.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_Boston_housing_data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để hiểu thêm về tập dữ liệu ta có thể làm thêm một số minh họa như sau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minh họa dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnX2cHWV597+/XRbYRGATiUiWhGBEqBggsEJorBV8QUVwCwpGaWlrtS+2SmvzGFpaQosPsRHQ+rT2QW2LEhEEuoJRwUdoKamJbkjSEIEqbwkLSjAsb1nIZnM9f8yccPbszJyZc86c1+v7+ezn7LnPnJl75szc131frzIzHMdxnM6lq9EdcBzHcRqLCwLHcZwOxwWB4zhOh+OCwHEcp8NxQeA4jtPhuCBwHMfpcFwQdACSlku6tk7H+pCk21NuW7d+tTKS3iLpsUb3o55kuY+c6nFB0CJIekTS2xp4/HmSTNI+SduZ2Soze0e9+tVMFF2je0raD5a0S9IjOR3XJL22pK2phGzYn3FJz0salfRfkk6J276T76NG4ILAqRnlhEQHMV3SG4refxB4uFGdaSKuN7NXALOAu4GbJal0I7+P6o8LghZE0m9LulvSZyU9LelhSe8q+vwISf8h6TlJ3wcOLvpsipqheLUh6SRJw5KelfQLSVeGm90Vvo6Gs7pTwn6skXSVpB3A8kLfivb9eUnbwv2tl/RrMedUmE1fIGmrpKck/WXR512Slkl6UNIvJd0gaWb42f6Srg3bRyX9WNIhRdfqofBaPCzpQxHHni1prLC/sG1h2IceSa8Nr+czYdv1ZX6irwEXFL3/LeCrEce8SdL2sF8fL/qsV9K/hr/tT4A3ljleWST9anhdnglff7Xos0mrzeLVRJlre5Ckr0h6QtKIpMskdZfri5mNA9cArwZemfI+OkbS9yXtCO/LvwjbY+8LJz0uCFqXk4EHCAb5vwO+UjS7+jqwPvzsb5k8KJXj88DnzexAYD5wQ9j+5vC1z8xeYWY/LOrHQ8CrgE9H7O/HwPHAzLBf35S0f8Lx3wQcBbwV+GtJvxK2fxwYBH4dmA08DfxD+NkFwEHAHOCVwB8AY5KmA38PvMvMDgB+FdhYekAzexz4IXBOUfMHgRvDQetvgduBGcBhwBcS+g9wLfABSd1h/w8A1hU+lNQF3ApsAvrDc71Q0unhJpcQXPv5wOlk+/2mEA6MqwmuxSuBK4HVkl6Z4uuR1zb87BpgN/BaYCHwDuD3UvRnP+C3gcfM7KmwOfY+knQA8P+A7xH89q8FfhB+nHRfOClxQdC6PGpmXzKzCYIH8lDgEElzCWaQf2VmL5nZXQSDTlrGgddKOtjMnjeztWW2f9zMvmBmu81srPRDM7vWzH4Zfn4FsB/BQB/HpWY2ZmabCAbK48L23wf+0sweM7OXgOXA+xSoEcYJBqnXmtmEma03s2fD7+0B3iCp18yeMLMtMcf9OrAEIBSoHwjbCtfkcGC2mb1oZndH72IvjxEI6bcRDKRfLfn8jcAsM/sbM9tlZg8BXwqPCXAu8Gkz22Fm2wgG8HLcE87YRyWNAsuKPjsD+KmZfS38Ha4D7gfOTLHfyGsbrgreBVxoZi+Y2ZPAVUXnEMW5Yd+2AScSDOAFku6j9wA/N7Mrwuv/nJkVBGvSfeGkxAVB6/Lzwj9mtjP89xWEsyIze6Fo20cz7PfDwOuA+0M1wHvKbL8t6UNJn5R0X6iSGCWYXR6c8JWfF/2/k+CcIBiI/61ooLsPmAAOIVDF3AZ8Q9Ljkv5OUk94Dc4jmMU+IWm1pKNjjnsjcIqk2QSrHwP+M/zsfwECfiRpi6TfTTrnkK8SzHqXEKwQijkcmF0ycP9FeC4Q/IbF1zXN73eCmfUV/oAVRZ/NjtjHowSrkXJEXtvwHHoIrmvhHP4vwYw+jhvC/r3KzE4zs/VFnyXdR3OAB2M+S7ovnJS4IGg/ngBmhGqRAnOL/n8BmFZ4E+p0ZxXem9lPzWwJwQP9GeDGcF9xaWpj09cqsAd8imCGOyMcoJ4hGFSzso1AxdNX9Le/mY2Y2biZXWpmrydQ/7yHQC+Pmd1mZm8nWDHdTzDznnoSZqME6p9zCdRC11mYmtfMfm5mHzGz2QQz0H9UiZdOBDcRzMQfMrPSQXgb8HDJuRxgZu8OP3+CYPArMJfqeJxgwCxmLjAS/j/pniDQ3QOBPj/m2m4DXgIOLjqHA83smAr7mJQGeRuBmizus8j7osJ+dCQuCNqMcNAZBi6VtK+kNzFZBfA/wP6SzghndhcTqGsAkHS+pFlmtgcYDZsngO0EapbXZOjOAQQ65O3APpL+GjiwwlP7J+DTkg4P+zlL0nvD/0+VtCAUas8SqDMmJB0i6axQkL0EPB+eSxxfJxjkzuFltRCS3i/psPDt0wSDVtJ+CFcjpxGtM/8R8KykT4WG4W5Jb5BUMArfAFwkaUZ43D9JOlYKvgO8TtIHJe0j6Tzg9cC3w883Etg0eiQNAO8rfDHu2prZEwSC8wpJB4ZG2/mSfr3KvkbxbeDVki6UtJ+kAySdHH4We1846XFB0J58kMD4toPA8LhXR21mzwB/BHyZYEb4AoFOu8A7gS2SnicwHH8g1MvuJDDirQmX4YtS9OM24LsEwudR4EXKqJIS+DxwC3C7pOeAteE5QjCDvZFgoLoP+A8CdUwX8EmCGfEOAoPiHyUc4xbgSOAXoY2iwBuBdeE1uQX4hJmVdQc1s2Ezm6LSCO06ZxIY0R8GniL4PQ4KN7mU4Ho9TDDYfq3cscr045cEM/lPAr8kUHW9p8hQ+1cEM+6nw2N/vejrcdcWAqG5L/CT8Ls3Eqy8aoqZPQe8neCa/Rz4KXBq+HHSfeGkRF6YxnEcp7PxFYHjOE6H44LAcRynw3FB4DiO0+G4IHAcx+lwWiL67uCDD7Z58+Y1uhuO4zgtxfr1658ys1nltmsJQTBv3jyGh4cb3Q3HcZyWQlKqrAKuGnIcx+lwXBA4juN0OC4IHMdxOhwXBI7jOB2OCwLHcZwOJ1evIQXFup8jyNS428wGwmpJ1wPzgEeAc83s6Vofe2jDCCtve4DHR8eY3dfL0tOPYnBhf+ZtkvZ7UG8PEozuHE/9fYCLhzZz3bptTJjRLbHk5DlcNrigqvN1nHJ86Es/ZM2DO/a+Xzx/Jqs+Els/vubfd5qXeqwITjWz481sIHy/DPiBmR1JUG5uWfxXK2NowwgX3byZkdExDBgZHeOimzcztGEk0zbl9js6Ns7TO8dTfx8CIXDt2q1MhMn+Jsy4du1WLh7aXP2JO04MpYM4wJoHd/ChL/0w5hu1/b7T3DRCNfRegtKKhK+DCdtWxMrbHmBsfHK6+LHxCVbe9kCmbdLsN8v3Aa5bF52FOa7dcWpB6SBerr3W33eam7wFgRHkCV8v6aNh2yFhUQvC18jSdpI+KmlY0vD27dszHfTx0Smlc6e0p9kmy2dpt5mISfsd1+44jpM3eQuCxWZ2AkGR649JenPaL5rZ1WY2YGYDs2aVjZCexOy+3rLtabbJ8lnabboVXaUxrt1xHCdvchUEZvZ4+Pok8G/AScAvJB0KEL4+WevjLj39KHp7uie19fZ0s/T0ozJtk2a/Wb4PsOTkOZnaHacWLJ4/M1N7rb/vNDe5CQJJ0yUdUPgfeAdwL0FZuQvCzS4AvlXrYw8u7OfysxfQ39eLgP6+Xi4/e8Ekj54025Tbb19vDzOm9aT+PsBlgwumPDyL5890ryEnV1Z95JTI+y6t10+133eam9xKVUp6DcEqAAI31a+b2aclvZKgOPdcYCvwfjNLtDgNDAxYMyadq9T99KKbN08yOvf2dKcSIo7jOFmQtL7IYzOW3OIIzOwh4LiI9l8Cb83ruPWidEAvuI8CiQN6kreSCwLHcRqBRxZXSCXup1CZt5LjOE6euCCokEoH9Eq8lRzHcfLEBUGFVDqgV+Kt5DiOkycuCCqk0gG9Em8lx3GcPGmJUpXNSGHgzuo1VPiuD/yO4zQLLgiqwAd0x3HaARcEbUolMQ6O43QmLgjakEpjHBzH6UzcWNyGVBrj4DhOZ+IrgpxopGrGg9Ycx8mCrwhyoJLqZ7XEg9Ycx8mCC4IcaLRqxoPWHMfJgquGcmAkRgUT115rqolxcByn83BBkAPdUmTpyXpWIfMYB8dx0uKqoRzwusSO47QSLghyoD/GKBvX7jiO00hcEOSAG2sdx2kl3EaQA26sdRynlXBBkBNRxlrP/+M4TjPigqAGpBngPf+P4zjNiguCKkk7wMcFmX3yhk1TtnUcx6knbiyukrRRxHF5fibM6pp+wnEcpxQXBFWSNsFbUp4fzwzqOE4jcUFQJWkTvEW5lBZTr/QTjuM4pbggqJK0MQOFovVx1DP9hOM4TjEuCMowtGGExSvu4Ihlq1m84o4puvzCAN/f14sIoocvP3tBpPE3ySDs6Sccx2kU7jWUQFqPoCwJ3vr7eiPVQJ5+wnGcRuErggTyqCvg6Sccx2k2fEWQQB4lH+uVfsKjmB3HSYsLggRmx6hxqi35mHetAI9idvLAJxfti6uGEmhVNU6jS2U67Uej63A7+eKCIIEsHkHNRB4qLaez8clFe+OqoTK0YsnHvFRaTufik4v2xlcEbUirqrSc5iVtBL3TmrggaENaVaXlNC8+uWhvclcNSeoGhoERM3uPpCOAbwAzgXuA3zSzXXn3o9NoRZWW07x41b32ph42gk8A9wEHhu8/A1xlZt+Q9E/Ah4Ev1qEfNcFd6JxOxScX7UuuqiFJhwFnAF8O3ws4Dbgx3OQaYDDPPtQSd6FzHKcdydtG8DngfwF7wvevBEbNbHf4/jEgcooh6aOShiUNb9++PedupsNd6BzHaUdyEwSS3gM8aWbri5sjNo1Mu2lmV5vZgJkNzJo1K5c+ZsVd6BzHaUfytBEsBs6S9G5gfwIbweeAPkn7hKuCw4DHc+xDTXH/fMdx2pHcVgRmdpGZHWZm84APAHeY2YeAO4H3hZtdAHwrrz7UGnehcxynHWlEHMGngD+T9DMCm8FXGtCHinD/fMdx2hFZC1TGGhgYsOHh4UZ3w3Ecp6WQtN7MBspt57mGMuJxBI7jtBsuCDLgef4dx2lHXBBkICmOoNkEga9cHMdJiwuCDDQijqCSAd1XLo7jZMEFQQb6pvXw9M7xyPYoqp2VVzqgt9LKxXGcxuNpqDMQ52AV1V6LvESVprTwCGjHcbLggiADz4xNXQ3EtdciL1GlA7oXEXEcJwsuCDKQZYBNGsSHNoyweMUdHLFsNYtX3BG7Sqh0QPcIaMdxsuCCIAUXD21m/kXficwz1NOlyAH2oN5ou0FvT1dqlVGlA7pHQDuOkwU3Fpfh4qHNXLt2a/wGUflUAcW0j+3eM8WmEGfIraYqlBcRcRwnLWUFgaRpwCeBuWb2EUlHAkeZ2bdz710TcN26bYmfj09Y5CA+GuFdBPEG56jVBviA7jhO/qRZEfwLsB44JXz/GPBNoOUFQRr3zokUuZii7AFxrqZxdMctIRzHcXImjSCYb2bnSVoCYGZjYcnJliatj363VFYYlBpvhzaM8PyLu6ds19Mtxiei95VG4NQajz52HAfSGYt3SeolrCQmaT7wUq69qgNp3TuXnDwncT9RxtuVtz3A+J6pA/v0ffehP8bjJ649L7z+suM4BdIIgkuA7wFzJK0CfkBQh7iliXPvHAndOwtcNriA8xfN3au6kWBaT9cUb5xil9A4ff/o2HjTuHbGCcJLb91S1344jtN4yqqGzOz7ku4BFhH4yHzCzJ7KvWc5E1d2EuBPr9/I8KM7uGxwARAIg8L/UZSqmcpx+dkLGq6SiROET+8cZ2jDiKuIHKeDKLsikPQbwG4zWx16Cu2WNJh/1/IlamZewIBVa7emVpNEza6Tth1c2M+aZafx8IozWLPstIYMuklBaVminx3HaX1SqYbM7JnCGzMbJVAXtTSFoKs4jPQDYpYcPs2S7ydJFdUsfXQcpz6kEQRR27RFINrgwv5EI23aATFLDp/Zfb2pU0zkyeDCfvpiop89J5HjdBZpBMGwpCslzZf0GklXEcQVtAVLTz8qLjg49YAYpWbqithpb083px49q2m8dZafdUxTGK4dx2ksaWb2fwL8FXA9gbH4duBjeXaqngwu7Gf40R2sWruVYofP4gHx4qHNXLduGxNmdEssOXnOJONxXCqIqLZmqhVQTQoLx3HaB1kDApmyMjAwYMPDw7keIy64Ki7X0PmL5u4VBlkCs45YtpqoKy7g4RVn1PCMAsoJMcdx2hdJ681soNx2sSsCSZ8zswsl3QpTxy4zO6vKPjYFQxtGuPTWLXvTQfT19kwayONyDV23bhuXDS7IXEUszm01D718qRCbMNv73oWB4zgFkmwEXwtfPwtcEfHX8gxtGGHpjZsm5QQaHRvnwus3cvFQMJjHpX4otGctQFPPgLIkIeY4jlMgdkVgZusldQMfMbPz69inurHytgdic/+sWruVgcNnJuYaWrzijtigtDiPo3rq5csJMcdxHChjLDazCUmzJO1rZrvq1al6keQeWogjWHLynNh6BCOjY4gIvRnxBe2hfqml44SYZzp1HKeYNF5DjwBrJN0CvFBoNLMr8+pUvUhKMwGBoCjo0gsG11Li5tbPv7ibi4c2c+f92xvmkbPoNTNY8+COyHbHcZwCaeIIHieoPdAFHFD01/IsPf0oerrjZ8cFA+5lgwt48PJ3x8YbRDG+x1i1dmtD4wW2PP5cpnbHcTqTxBWBpFnAauBnYWqJtiIuhgCiDbjlVhCllO6znvECFw9tZnQsujBOXLvjOJ1J7IpA0u8BW4AvAPdLagt30WKGNoxw0/qRKQN2X29PZLH3OI+fuFQNUdQjj0/ZOsuO4zhFJK0ILgSOMbPtkl4DrAJuqU+36kNc1tDp++0TOWtPiiBe+s1NkcVoSqlHHp9V65KFwIwEQ7bjOJ1HkiDYZWbbAczsIUn71alPdSNudp40a4/y+BnaMEKpAaG7S3TBJOFQUDflXSIyyTu0p1tccuYxNTuW4zitT5IgOEzS38e9N7OP59et+lCrKN+oeISJPcaB03qYtu8+iauHkdExln5zExAdiVxrVr7vOM8l5DjOJJK8hpYSZBkt/JW+b3lqFeUbZ0AujlgusPyWLVNUSON7jOW31K5E5LSe6J91Wk+XCwHHcaaQFFl8TT070giKdf4jo2N0S5PSQ6QdNJOijwtCouA+GlfJrJaePP/77GP5sxs2UixvuhS0O47jlJJbgRlJ+wN3AfuFx7nRzC6RdATwDWAmcA/wm42MWi4M9nGJ46B8Ooi0KRvSlrOsloJbbGnWUV8NOI4TRZ6Vxl4CTjOz5yX1AHdL+i7wZ8BVZvYNSf8EfBj4Yo79KEtc4rhLb93Ci+N7ymYW7c8YXxDFvgmBbVkpuMUWBNSEGTetH2Hg8JkuDDqYvJ0UnNalLvUIJE0D7gb+kCBA7dVmtlvSKcByMzs96ft51yOIqxEQR7fEHrNJBuBStU9cDqK4doDPnXd8xQ9m8UPeFaOq6u/rZc2y0yrav9PalKZLh8AeFhUv47QPaesRlE0xIel1kn4g6d7w/bGSLk7ZiW5JG4Enge8DDwKjZrY73OQxIPIulPRRScOShrdv357mcBWT1UtowmxS2giAy89eQH9fLyIYcD+0aG6kITpJ4MSlri5H4SEvpLOIU1V5UfrOJWu6dKezSJNr6EvARcA4gJn9N/CBNDs3swkzOx44DDgJ+JWozWK+e7WZDZjZwKxZs9IcrmKqiRiOe5gGDp85RTgU3sdR6UAdFxhXihel71wqiZlxOoc0NoJpZvYjTU5dvDtu4yjMbFTSvwOLgD5J+4SrgsMIkto1lKSI4SRPnwKlHkGF95efvSBSFfOn12+MlH6VDtRpH+ZTj85XoDrNSz0r4zmtRxpB8JSk+YQzd0nvA54o96UwYd14KAR6gbcBnwHuBN5H4Dl0AfCtCvteU5JqBBSXsoyi4HZazNj4BMtv2RJpnItKdFdNlbK0yfDuvD9fFVsn0Ko1oJeeflSkjSCPynhO65FGEHwMuBo4WtII8DCQpmLZocA1YZWzLuAGM/u2pJ8A35B0GbAB+EplXa8fz78YvwDq7elOjA0oxAcU2xMuG1zAwOEzU3lwpPH0iHrIo3A1QHW0cg3oelbGc1qP1F5DkqYDXWZW92T2eXsNJXH8pbfHBnv19/Vy6tGzItNYx5HFcyeLp4d7DeXP/Iu+E1vx7cHL392AHjlOMrX0GvqEpAOBncBVku6R9I5adLIVSIr4XbPsNO68f3sm19Mss/JLb92S2tNjcGE/a5adxsMrzuCKc4+rSeoMZzJeA9ppV9J4Df2umT0LvAN4FfA7wIpce9VCZFW3pDXODW0YibVLlLMHDC7sj/RYcjVAdcTVevYa0E6rk0YQFO7ydwP/YmabmJJ0uXOJG9hnTOupalae5N/tA09jWHLynEztzcbQhhEWr7iDI5atZvGKO+paNtVpbtIIgvWSbicQBLdJOgDYk2+3moe4WIJCe1wMwiVnHlPVrDxppVFOFVEaYNaIesntyGWDCzh/0dy9grhb4vxFc5veUAx+TzjJpPEa+jBwPPCQme2U9EoC9VBHsPysY6ZUH+vpEsvPCoq7lPPGqFQdk+QSmhSUVuhLnG2hkv54jpqXGTh8Jnfev53HR8d49UH7M3D4zEZ3KRW1uCf8Pmhf0giCN4Wvx6oDVRJp3O6SYhAqZenpR0WWv+zpVln1Ui2jSEs9l+IS73UCrXwtqr0nWvncnfKkEQRLi/7fnyBVxHqg5f0Q085w8hjo0/TnvJPm8O1NT+z1XJoxrYdLzjymbF/SRJGmPfdyM8lOmiXWeqVVT6qNLG7lc3fKU1YQmNmZxe8lzQH+Lrce1YlKZzh5DXxR/blp/UhF3j7zXhn90BdSTGQ596SZZKfNEls5X0+1kcWtfO5OedIYi0t5DHhDrTtSbyrJxpinwa3a7JAFj5B5y1az5sEdkdsUUkxkOVbcjHF2X2/HZbRMuhbNTrUuxa187k55yq4IJH2BlzOEdhEYjjfl2al6UMkMJ8/lcTUzrqgI5KR9ZTlW0kzyT6/fWHGfW5FWz9dTjYqz1c/dSSbNimCYlwvW/xD4lJmlyTXU1FQyw8lzeVzNjCtrGuosx0qaSXbaLLGTA/U6+dw7gTQ2gmsk7Qu8Lmxqi3V/JTOcPFP5VjPjSiOIFB6jkmPFzSQ7cZZYL8eBZqSTz73dSZNr6C3AT4F/AP4R+B9Jb865X7lTyQwnLnisFgNfNTOucoJIwIcWzZ0U23DOif10TfIGzp4vx2eJjtMelM0+Kmk98EEzeyB8/zrgOjM7sQ79AxqbfbSURrlLxh13aMNI2XoJpW6nQxtGWHrjJsYnJv/2XcBB03oY3TneFK6g7eKa2iznUW0thWY5Dyc9abOPphEE/21mx5Zry5NmEgT1pPDgjYyORRa9n75vN7t275kSdBZFcfrqxSvuSFXIppHFzdul2HqznEdpLYUCaVNkNMt5ONmoWRpqYFjSVyS9Jfz7EoHhuO3JM0lXuX0Xu6pCtOLmhV0TqYQATHbrTCMESr9TS9Jc13ZxTW2W87hu3bZM7aU0y3k4+ZAmsvgPCaqUfZxA3XwXga2grckzWCrNvtN6AmWhYFTujilcE0VaoZGWtNe1XQKYmuU8qq2l0Czn4eRD2RWBmb1kZlea2dlm9htmdpWZvVSPzjWCwmz1wus3Rs6A/vT6jVWvENLMrvJ4wApG5SyFVGqd8jrtzLJvWnTWV4Oars7yTs3cLC621dZSiPs94tqd1iJ2RSBpMwmuJPW0EdSLNIFZhQtSyQqhWOcfxcjoGItX3JFYbrIaCikm+lMWu4faV9+KE3AjYcqKwrVMOmyaa5/GsFmPFBnN4mK75OQ5kTaCtLUU4n4PL87WHiSpht4TvgpYTVCPoK3Jqo4pF1VcPBj1Tevh+Rd3J+r0xcuqmLQDcE+3pnj/xFFIMbH09KO4MCYquJRyKa+zkpReu3gQfiahRCgkX/u0A3w9Eqk1S9H4gkG4Uq+huJKtSaVcndYhVhCY2aOF/yW9VPy+XalEHRP3ndLBKMm9E4j0CopjWk8XY+N7mN3Xy6lHz2LVuq2pZmaFvg4u7Gf5LVvKPsR5zFyjZsgFigfhg3p7yvYv7tqnHeDrpfdulkCsywYXtEQRHaf+pDEWdwxJs9Wk70SRdXWRZYW9czwoEPfCS7u5/sfbUi/Pi/u6/KxjpgzIXQCCPRbojs85ceoAVq0veWHbuBVJYRBOo7qO00+nHeAriRRvZV/6Vu67ky9JNoITit72SlpIUa1iM7snz47Vg9IH49SjZ3HT+pHUA3jSjLke3hRxM+YuBQN5sRqqtK+lKouDent4YdfuvWqmCTNuWj+ytwJXVDxDpTr1wYX9sUFwhcF9tMwKCuL102kH+Kz6+2ZLXZ6Fau0hcZ5medTPbobr1WkkeQ1dUfT3c+DKovefzb9r+RKVUvqm9SOcc2L/pJQJ5y+au/f9jGk99PX2pEqn0MjEa2aw8v3HlU39MLiwnzXLTuPhFWcwfb99ptgaxsYnuPTWLYnxDJX6kscN4qM7xxnaMJLq+sXZEdKmAsmaIqPZUpdnodo4gDijclpjc1qa5Xp1Gkk2glPr2ZF6E/dg3Hn/dtYsm1p8LessJWq22dMt9ukSY6FqJy9m9/Vm1kvHrWDK2TaSvptE3GrGCIzG55zYz9fXbSUpXu6g3mjV0ODCfoYf3THJMBql5ipsm/Y6NVvq8iwkeaqlYeDwmXx97VaK79yusL2WNMv16jQqKUzTFmR5qCuZpUTNNle+7zhmTt+vRmcQTaUG3mpWMJV8N0mlMDY+wc3rH0sUAhBvRxjaMMJN60f2qjIKaq5qZ5XNlro8C3FXO61iZ+VtD1A6fdkTtteSZrlenUbHCoIsD3Utw+vzuKGn9XRNUm0MP7qD+Rd9h3nLVjP/ou9w8dDmsvsoxBiU0tuTfItUKnjKucfuTLFqirMj5JUOoZLss80SUBZ3tdM6KVS7okhLs1yvNOQdjFhPOlYQZHmoK3kI4lYReURizpi+Hw+vOIM1y05j+NEdXLt266TZ8LVTgTVuAAAVTklEQVRrt5YVBoUYg1L27+mecp0Ks8hK004PbRhJ5RVUjrjBIa9Bq9lSl9eTaiOT09Iq16vdbBmxgkDSCUl/9exkHmR5qCt5COJmpWbpl+NpKV5lxCURW7VualRp3D6KGd05PuU6XXXe8TwSCh4g06yo8AAlLQh6e7rLCoqebsUODnkOWsOP7uDnz7yIAT9/5kWGH42uD12gWWo27NMVfe5x7aVUm6soLc1yvcrRbkn4kuIIrghf9wcGCOoUCzgWWAe8Kd+u5U9aQ2ElD0HcwPrM2DgfWjSXVWu3VlAKJprimXFcn8yYlMIhah9xLpdx16kSl8Q08RUF9VZUSoSXTyj+o7wGrdJUzoXVFpAYqNUMAWW7Ywwuce2lzJjWE+k4MCOHFW4zXK9ytJstI3ZFYGanhp5DjwInmNlAWIxmIfCzenWwGYhLs5CUfiFJ13nZ4AKuOu/4KW6qPd3ZZ6w9XZNnxuVWKQWGNoxw/KW3M2/ZauYtW83ozl30lMwOyy3JK5kVpX1QLhtcwPmL5saez/geiz1OJb9XGqpN5dzKeK6hycR5rMW1NztpbARHm9leBbOZ3Qscn1+Xmo9K9JZR3ynkElq84g6AvT78a5adxmWDC1j5vuOmCocyS/fzTpozafaU5NddGISHNoyw9JubJrlwvrBrgj1QNk6i2EAWp3NPGuzT2EgKutbLBhfw4OXvjlWlxR0ny++VxeBXL/VIMxIXs1EuJ1S7EjffyiG+ri6kSTFxn6QvA9cSLMjPB+7LtVdNQGncwDkn9nPn/dtTxxEUR+6mjciNWhIPHD4zMWNpqZF34PCZsSqVwipl5W0PRCa/m9hjTN9vHzZe8o7I76fJzlp8nCjSjJmlfuNZU0GkjSPIqtqqNLq2HSJlK0nH0c7EeayliYhvRtKsCH4H2AJ8ArgQ+EnY1rbERR0vPf2ovTP4NA9yIXK3v6+34ojcwj7iKKwwCjPaS2/dErmdYO+MOGnGPjI6Fjs7TqPfL7dSSjuDLO5j1hVZ2jiCrKqtSqJr28W7pFW8eepFK7m5piFNYZoXgX8ClhUVpnkx/641jlp7BORtWCoeZOIigQ0mzbCTiBuwktwv03p4pH1QilVIeaWCyPq7lNotuqWyNX/bxbukVbx56kVc3E1ce7NTVjUk6SxgJbAvcISk44G/MbOzynxvDvBV4NUEQYhXm9nnJc0ErgfmAY8A55rZ09WcRK2pRPedRDMsq4sNpWnrEZSqaLrCzKTVkJSGupiCl1MlKpW0A3xfjCdMkh0jayrndvIuaQVvnnrx7U1PxLbXItV3vdWJaVRDlwAnAaMAZraRYBAvx27gk2b2K8Ai4GOSXg8sA35gZkcCPwjfNw1DG0ZijZOVDty1WFZX4wMflXk0rdtf8YCVJASypN4458TyN/To2HjFKpW0y/Z6eMK0mwrBCcizUE8j1IlpBMFuM3sm647N7IlCqmoze47AwNwPvBe4JtzsGmAw677zZOVtD0S6qBfr2LNSi2X1otfMqOjY3VLksS4585gpwimKrANWmmycN60vf0N3SxWrVNIK3np4wrSTbr1eKRXaKXVDJTRCnZjGa+heSR8EuiUdCXwc+K8sB5E0jyD+YB1wiJk9AYGwkPSqmO98FPgowNy5c7McririluzFOvZyFNcmLnia9FexvBvaMMKPHq5Me5bk2rjfPl17b7jp+3aza/eexBoGfSmqhkGyLSGNwbmnS7ElPdOoVNKWh6yHyq5ZSlVWSz3qO9fzONWSZ4BdI9SJaVYEfwIcA7wEXAc8S+A9lApJrwBuAi40s2fTfs/Mrg6D2AZmzaqfASZuEEgbjFS8rIOXB+Jqlndx7p5pKT1uoY/Fg/oeC2ISklYty886pmxcQznS3MwTZrHJ7tIG7BTXWojz8qrXbD1NX5qdes1SW8W4fsmZx0wJAO3pFpeceUzV+26EOrHsisDMdgJ/Gf5lQlIPgRBYZWY3h82/kHRouBo4FHgy637zJGvVqlKSZryV5lWvdiZQetystRguHtq81ye/S0FG0hfH91SUIiNNOdA9RmzNhloG7LTLbL0e1GuWWq8sp9USFaty3hvn1OTeqXYMqoSkUpW3JH0xhdeQgK8A95nZlUUf3QJcAKwIX7+Vurd1oNrBodyDUcmDU0kt5aTjZnmoS/PrFAbp8xfNTc4FFENar6E4ah2w454w6aiX51s9S2JWQ1ysysDhM6u+nxoxQUlaEZwCbCNQB60je9LMxcBvApslFXwV/4JAANwg6cPAVuD9GfebO9UMDuUG7UoenHLunv0pBEXxceP6eFBvD4tX3DHp5ovLo1OJEICXb/JP3rCpotQM7m3TGOo1S22VNB55V1Kr9wQlyUbwaoKB+w3A54G3A0+Z2X+Y2X+U27GZ3W1mMrNjzez48O87ZvZLM3urmR0Zvibn8W0QlXouROmdC1T64Awu7GdajM68r7en7D5LjxvVx54u8cKu3VNc1ip5AM9flGzcH1zYzxXnHlfWa6ldvG3agXoFlMUZW/PIcloN7RQfAsk1iyeA7wHfk7QfsAT4d0l/Y2ZfqFcHG0E1ngulOYZq4TUEsF9Pd2TVLim5XGCU+2jU0nPnrt1TvCCyqm+6JZacPCdVQE2hD0krncvPXuD6+xrRBVNKTRba01KPWepLMfdcXHujaIYg0VqSaCwOBcAZBEJgHvD3wM1J32kHql325fHAJCW5StKbX3HucamKth+xbHVV/XtkxRlVfT8K19/XjrjCn+ULgr5MPaJd40qUpildWk8aYdDNkyRj8TUEaqHvApeG6ac7gkYs+8o9ZOVmIHE2gsJqodwDG7f//r5eTj161l7viFowtGGE5bdsSYxJaDbjYKcztGGEpTduYnziZXfopTduAprLv79etJvHWdLK8DeB1xFkHf0vSc+Gf89JSh0P0IrU2483TUh5ks97UqKrtPELSfsv1AWoBVExDFEkZfR06s+lt27ZKwQKjE9YbLZbp7VIqlDWZWYHhH8HFv0dYGYH1rOT9abeaQHSBNEkGeviCs/H7SuKNMbAOIN1XHsUaSKLy2X0dOpPXFbbuPZ2p13SixdIk2Ki46j3si+tKipOZ55GZZU2NUPSOcYFecW1V9KP/rCUp+M0M3m7j9YbFwQx1NNQWa0HQpqAs9J9ZTH8FbaNsxBkUZkdlJCvqJWNbe1OXJ6pvhrX6K3Xcaql3dxHs3iPOTlRrSoqKXYhal9ZlrWluZOiyFKMI84G3CU6utBJsxOVZ6qnSyw/q/rcOo04TrW0W3pxFwRNQLXBOqXfnzGtJ7EIfZbEXml0+uVsFMXEubpWW/DGyZfBhf2sfP9xk+7Rle+Pdk2u9jjnnTRnUhW4806qTQ6fWtJO6cXBVUNNQzlVVDlVThZVVpZlba3sDwWS1FjNmG7YeZl6qEvzzOFTSzrJfdRpEmrtoZBlWZtmqZtlOZykxmrGdMPOy1w8tJn5F32HectWM/+i73Dx0OaaH6NV0lC3Gy4IWoBaPxxZlrXl7A+QzUZQUGPF0arGtnankIW2eKZ+7dqtNRcGrWKEbTf3URcELUCtH44sNonibePIYiMo7DNuf61qbGt3Vq2LzjYb114prWKEzXvlUu9ynW4jaAHySHCVRd9b2HZeTD6iSmoltFuulmZn+r7dvLBrqtF/+r7l61YDxGUXqXV26Fa5L/JcuTSiXKevCFqAZvFQiMv/U0leoHqlNXYCooRAUnujaJX7Is+VS7MWr3caTLN4KNS6aIhnF3WiaIX7Is+VSyPsJC4IWoRaPxz1SCnstA/TeroiU0FnyTOVluIa2VlqXNSTPCdnjah14IKgA2mEDtJpbeIKI+1XxqMsK6U1sgveSUBTCoM8npdG2EncRtCBuK+2k5Wkwki1pF7eSc1MI+wkLgg6kFbx1Xaah76YmsFx7ZVSL+8kZzIuCDqQSj0e9tsn+naJa3faBx+g60cjgtX8Ce5AKnVHfWl3dN2BuHanfYhLHV6u0lxW4mzPOdikmxZ3H3XqQrO4ozqtgyCyHkWtK0u/Yv+eyKpnr9i/ueoR5Im7jzp1oxV8tZ3mIU4DVGvNUL2M0s1MI9xHO2jB5ThOs9MquYbypBGZBFwQOI5Tlhkx3kFx7ZXSLOlUGkkj3EddNeQ4TlkuOfMYlt64ifGJl5VBPd3ikjNrW0LS7VcB9VbduiBwUtMfo7tMSlHttAf1HKDdflV/XBA4qWmVFMFOPvgA3b64IHBS48t2x2lPXBA4mfBZoeO0H+415DiO0+G4IHAcx+lwXBA4juN0OC4IHMdxOpzcBIGkf5b0pKR7i9pmSvq+pJ+GrzPyOr7jOI6TjjxXBP8KvLOkbRnwAzM7EvhB+N5xHMdpILkJAjO7C9hR0vxe4Jrw/2uAwbyO7ziO46Sj3jaCQ8zsCYDw9VVxG0r6qKRhScPbt2+vWwcdx3E6jaY1FpvZ1WY2YGYDs2bNanR3HMdx2pZ6C4JfSDoUIHx9ss7HdxzHcUqotyC4Bbgg/P8C4Ft1Pr7jOI5TQp7uo9cBPwSOkvSYpA8DK4C3S/op8PbwveM4ORNXW7jWNYed1iS3pHNmtiTmo7fmdUzHcaKpV81hpzYMbRipa5Zfzz7qOI7TRAxtGJlU92NkdIyLbt4MkJswaFqvIcdxnE5k5W0PTCr+BDA2PsHK2x7I7ZguCBzHcZqIxyPKwSa11wIXBI7TARz5qumZ2p3GMTumBnhcey1wQeA4HcAjT72Qqd1pHEtPP4qersn+XD1dyrU2uAsCx+kAxvdka3caTKlfb85+vi4IHMdxmoiVtz3A+MRkx97xCXNjseM4TqfgxmLHcXKhO0a1ENfuNA43FjuOkwsH7N+Tqd1pHEtPP4renu5Jbb093bkaiz2y2HE6gGfGxjO1O42jED3sKSYcx6kps/t6GYnQMeepbnAqZ3Bhf64DfymuGnKcDqAR6gandXBB4DgdwODCfk6Ye9CkthPmHlTXWafTvLggcJwO4OKhzax5cMektjUP7uDioc0N6pHTTLggcJwO4Lp12zK1O52FCwLH6QAmLLoETVy701m4IHCcDqBb0ZFjce1OZ+GCwHE6gCUnz8nU7nQWHkfgOB3AZYMLgMAmMGFGt8SSk+fsbXc6G1kL6AgHBgZseHi40d1wHMdpKSStN7OBctu5ashxHKfDcUHgOI7T4bggcBzH6XBcEDiO43Q4Lggcx3E6nJbwGpK0HXg0xaYHA0/l3J1G4ufXurTzuYGfX7NyuJnNKrdRSwiCtEgaTuMq1ar4+bUu7Xxu4OfX6rhqyHEcp8NxQeA4jtPhtJsguLrRHcgZP7/WpZ3PDfz8Wpq2shE4juM42Wm3FYHjOI6TERcEjuM4HU7bCAJJ75T0gKSfSVrW6P7UEkmPSNosaaOklk/DKumfJT0p6d6itpmSvi/pp+HrjEb2sRpizm+5pJHwN9wo6d2N7GOlSJoj6U5J90naIukTYXtb/H4J59cWv18cbWEjkNQN/A/wduAx4MfAEjP7SUM7ViMkPQIMmFkrBrRMQdKbgeeBr5rZG8K2vwN2mNmKUJDPMLNPNbKflRJzfsuB583ss43sW7VIOhQ41MzukXQAsB4YBH6bNvj9Es7vXNrg94ujXVYEJwE/M7OHzGwX8A3gvQ3ukxODmd0F7Chpfi9wTfj/NQQPX0sSc35tgZk9YWb3hP8/B9wH9NMmv1/C+bU17SII+oFtRe8fo71+PANul7Re0kcb3ZmcOMTMnoDgYQRe1eD+5MEfS/rvUHXUkqqTYiTNAxYC62jD36/k/KDNfr9i2kUQRFXgbn2d18ssNrMTgHcBHwtVD05r8UVgPnA88ARwRWO7Ux2SXgHcBFxoZs82uj+1JuL82ur3K6VdBMFjQHEV7sOAxxvUl5pjZo+Hr08C/0agCms3fhHqZwt62icb3J+aYma/MLMJM9sDfIkW/g0l9RAMkqvM7OawuW1+v6jza6ffL4p2EQQ/Bo6UdISkfYEPALc0uE81QdL00GiFpOnAO4B7k7/VktwCXBD+fwHwrQb2peYUBsmQ36BFf0NJAr4C3GdmVxZ91Ba/X9z5tcvvF0dbeA0BhO5cnwO6gX82s083uEs1QdJrCFYBAPsAX2/1c5N0HfAWgtS+vwAuAYaAG4C5wFbg/WbWkgbXmPN7C4FawYBHgN8v6NRbCUlvAv4T2AzsCZv/gkCP3vK/X8L5LaENfr842kYQOI7jOJXRLqohx3Ecp0JcEDiO43Q4Lggcx3E6HBcEjuM4HY4LAsdxnA7HBYHTkkh6PuP2b5H07QqPdaGkaQmff1nS68vs498ltW3xc6e1cUHgOOW5EIgUBJK6zez32iXTrdOZuCBwWppwpv/vkm6UdL+kVWF0aKFGxf2S7gbOLvrOckl/XvT+Xknzwiju1ZI2hW3nSfo4MBu4U9Kd4fbPS/obSeuAU4pn+5K+KGk4zGV/aUyfn5f06fA4ayUdErbPknSTpB+Hf4vD9l8vyoO/QdIBkg6VdFfYdq+kX8vnCjudgAsCpx1YSDBrfz3wGmCxpP0JcsKcCfwa8OoU+3kn8LiZHRfWEfiemf09Qd6qU83s1HC76cC9Znaymd1dso+/NLMB4Fjg1yUdG3Gc6cBaMzsOuAv4SNj+eeAqM3sjcA7w5bD9z4GPmdnx4bmMAR8EbgvbjgM2pjg/x4nEBYHTDvzIzB4LE4JtBOYBRwMPm9lPLQifvzbFfjYDb5P0GUm/ZmbPxGw3QZCULIpzJd0DbACOIRBOpewCCvaK9WF/Ad4G/B9JGwly9xwY5plaA1wZrk76zGw3QX6t3wkL3iwIc+c7TkW4IHDagZeK/p8gyMkE8anIdzP53t8fwMz+BziRQCBcLumvY77/oplNlDZKOoJg9v5WMzsWWF3Ydwnj9nJul+L+dgGnmNnx4V+/mT1nZiuA3wN6gbWSjg6L37wZGAG+Jum3YvrqOGVxQeC0K/cDR0iaH75fUvTZI8AJAJJOAI4I/58N7DSza4HPFrYBngMOSHHMA4EXgGdCvf+7Mvb5duCPC28kHR++zjezzWb2GWAYOFrS4cCTZvYlgmyZJ0Tt0HHSsE/5TRyn9TCzF8NqbqslPQXcDbwh/Pgm4LdCFcyPCepdAywAVkraA4wDfxi2Xw18V9ITRXaCqGNukrQB2AI8RKDSycLHgX+Q9N8Ez+ZdwB8AF0o6lWD18BPguwSp1pdKGieoj+wrAqdiPPuo4zhOh+OqIcdxnA7HBYHjOE6H44LAcRynw3FB4DiO0+G4IHAcx+lwXBA4juN0OC4IHMdxOpz/D9mGKFsmAnbgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils_function import scatter_plot\n",
    "\n",
    "scatter_plot(train_X[:, 0], train_Y,\\\n",
    "            title=\"Industrialness vs Med House Price\",\\\n",
    "            x_label = \"Industrialness\",\\\n",
    "            y_label = \"Med House Price\")\n",
    "\n",
    "\n",
    "scatter_plot(train_X[:, 1], train_Y,\\\n",
    "            title=\"Avg Num Rooms vs Med House Price\",\\\n",
    "            x_label = \"Avg Num Rooms\",\\\n",
    "            y_label = \"Med House Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 1. Viết hàm cost function\n",
    "Nhắc lại, từ công thức tính **mean squared error**, ta có:\n",
    "$$\\mathcal{E}(\\hat{y}, y) = \\frac{1}{2N} \\sum_{i=1}^N (\\hat{y}^{(i)}-y^{(i)})^2 $$\n",
    "Khai triển, kết quả có là\n",
    "$$\\mathcal{E}(\\hat{y}, y) = \\frac{1}{2N} \\sum_{i=1}^N (w_1 x_1^{(i)} + w_2 x_2^{(i)} + b - y^{(i)})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Viết chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_cost(w1, w2, b, X, y):\n",
    "    '''\n",
    "    Evaluate the cost function in a non-vectorized manner for \n",
    "    inputs `X` and targets `y`, at weights `w1`, `w2` and `b`.\n",
    "    '''\n",
    "    \n",
    "    costs = 0\n",
    "    N = len(y)\n",
    "    for i in range(len(y)):\n",
    "        \n",
    "        # TODO: complete below expression to calculate cost function\n",
    "        y_hat = w1 * X[i, 0] + w2 * X[i, 1] + b\n",
    "        costs += (y_hat - y[i]) * (y_hat - y[i])\n",
    "        \n",
    "    return costs / (2 * N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Chạy thử chương trình "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2256.1627893564355"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_cost(3, 5, 20, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1210.8142745049508"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_cost(3, 5, 0, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 2. Vector hóa hàm cost\n",
    "\n",
    "Ngoài ra, ta còn có thể viết lại công thức trên như sau:\n",
    "\n",
    "$$\\mathcal{E}(\\hat{y}, y) = \\frac{1}{2N} \\| \\bf{X} \\bf{w} + b \\mathbb{1} - \\bf{y} \\| ^2$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Viết chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_cost_vectorized(w1, w2, b, X, y):\n",
    "    '''\n",
    "    Evaluate the cost function in a vectorized manner for \n",
    "    inputs `X` and targets `t`, at weights `w1`, `w2` and `b`.\n",
    "    '''\n",
    "    \n",
    "    #TODO: Complete the following expression\n",
    "    N = len(y)\n",
    "    w = np.array((w1, w2))\n",
    "    #y_hat = np.dot(train_X, w.reshape(-1, 1)) + b\n",
    "    y_hat = np.dot(train_X, w) + b\n",
    "    \n",
    "    return np.sum((y_hat - y)**2) / (2.0 * N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Chạy thử chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2256.1627893564355"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_cost_vectorized(3, 5, 20, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1210.8142745049504"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_cost_vectorized(3, 5, 0, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tìm nghiệm chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 3. Tính nghiệm chính xác\n",
    "\n",
    "Hiên thời, vecto của ta đang có dạng như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data X Matrix (404, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of data X Matrix %s\"  % str(train_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data Y array (404,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of data Y array %s\"  % str(train_Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để chuyển qua phép tính ma trận có dạng như sau $X *w + b$ ta cần bổ sung thêm một chiều cho hệ số tự do ở phần cuối của mỗi dòng trong ma trận. \n",
    "\n",
    "**Ví dụ** Lấy dòng đầu tiên của ma trận hiện thời, ta có: `array([ 6.2  ,  6.951 ])`   $\\,\\to\\,$  `array([ 6.2  ,  6.951,  1.   ])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 1 Tái tạo vecto cho tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.2  ,  6.951,  1.   ],\n",
       "       [10.81 ,  5.961,  1.   ],\n",
       "       [ 4.93 ,  6.897,  1.   ],\n",
       "       ...,\n",
       "       [10.01 ,  6.021,  1.   ],\n",
       "       [ 6.91 ,  6.03 ,  1.   ],\n",
       "       [ 4.05 ,  5.572,  1.   ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Add one at the end of each row in train_X by np.concatenate\n",
    "train_X_new = np.concatenate((train_X, np.ones(len(train_X)).reshape(-1, 1)), axis=1)\n",
    "train_X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.2  , 6.951, 1.   ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_new[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Viết chương trình tính nghiệm\n",
    " \n",
    "$$\\theta = \\left(X^{\\rm T}X\\right)^{-1} \\left(X^{\\rm T}y \\right) =  A * c $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_solve_exactly(X, y):\n",
    "    '''\n",
    "    Solve linear regression exactly. (fully vectorized)\n",
    "    \n",
    "    Given `X` - NxD matrix of inputs\n",
    "          `t` - target outputs\n",
    "    Returns the optimal weights as a D-dimensional vector\n",
    "\n",
    "    '''\n",
    "    \n",
    "    #TODO: Complete the below followed the above expressions\n",
    "    A = np.dot(X.T, X)\n",
    "    c = np.dot(X.T, y)\n",
    "    \n",
    "    return np.matmul(np.linalg.inv(A), c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Chạy thử chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.37785864,   7.83254633, -22.54414787])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_solve_exactly(train_X_new, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Cách dùng `Numpy`\n",
    "\n",
    "Một cách khác nhanh hơn mà `Numpy` hỗ trợ cho người dùng để tính nghiệm của phương trình tuyến tính là `np.linalg.lstsq`\n",
    "\n",
    "```\n",
    "Parameters\n",
    "----------\n",
    "a : (M, N) array_like\n",
    "    \"Coefficient\" matrix.\n",
    "b : {(M,), (M, K)} array_like\n",
    "    Ordinate or \"dependent variable\" values. If `b` is two-dimensional,\n",
    "    the least-squares solution is calculated for each of the `K` columns\n",
    "    of `b`.\n",
    "rcond : float, optional\n",
    "    Cut-off ratio for small singular values of `a`.\n",
    "    For the purposes of rank determination, singular values are treated\n",
    "    as zero if they are smaller than `rcond` times the largest singular\n",
    "    value of `a`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "x : {(N,), (N, K)} ndarray\n",
    "    Least-squares solution. If `b` is two-dimensional,\n",
    "    the solutions are in the `K` columns of `x`.\n",
    "residuals : {(), (1,), (K,)} ndarray\n",
    "    Sums of residuals; squared Euclidean 2-norm for each column in\n",
    "    ``b - a*x``.\n",
    "    If the rank of `a` is < N or M <= N, this is an empty array.\n",
    "    If `b` is 1-dimensional, this is a (1,) shape array.\n",
    "    Otherwise the shape is (K,).\n",
    "rank : int\n",
    "    Rank of matrix `a`.\n",
    "s : (min(M, N),) ndarray\n",
    "    Singular values of `a`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the above function to calculate a solution of the linear equation\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tìm nghiệm xấp xỉ bằng `Numpy`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 4. Véc-tơ hóa hàm tính grad\n",
    "\n",
    "Với $i = 1...m $ và $j = 1...n$ xét\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal{E}}{\\partial w_j} = \\frac{1}{N}\\sum_i x_j^{(i)}(\\hat{y}^{(i)}-y^{(i)}) $$\n",
    "\n",
    "\n",
    "\n",
    "#### 4.1 Viết chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_gradfn(weights, X, y):\n",
    "    '''\n",
    "    Given `weights` - a current \"Guess\" of what our weights should be\n",
    "          `X` - matrix of shape (N,D) of input features\n",
    "          `t` - target y values\n",
    "    Return gradient of each weight evaluated at the current value\n",
    "    '''\n",
    "    \n",
    "    #TODO: Complete the below followed the above expressions\n",
    "    N, D = X.shape\n",
    "    y_hat = np.dot(X, weights)\n",
    "    error = y_hat - y\n",
    "    \n",
    "    return np.matmul(np.transpose(X), error) / float(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài  5. Tính dựa trên Gradient Descent\n",
    "\n",
    "Xấp xỉ giá trị $\\theta$ như sau\n",
    "\n",
    "$$ \\hat{\\theta} := \\hat{\\theta} - \\alpha * \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right)x_j^{(i)}$$\n",
    "\n",
    "#### 5.1 Viết chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_solve_via_gradient_descent(X, y, print_every=5000,\n",
    "                               niter=100000, alpha=0.005):\n",
    "    '''\n",
    "    Given `X` - matrix of shape (N,D) of input features\n",
    "          `y` - target y values\n",
    "    Solves for linear regression weights.\n",
    "    Return weights after `niter` iterations.\n",
    "    '''\n",
    "    N, D = np.shape(X)\n",
    "    # initialize all the weights to zeros\n",
    "    w = np.zeros([D])\n",
    "    for k in range(niter):\n",
    "        \n",
    "        #TODO: Complete the below followed the above expressions\n",
    "        dw = np_gradfn(w, X, y)\n",
    "        w = w - alpha * dw\n",
    "        \n",
    "        if k % print_every == 0:\n",
    "            print('Weight after %d iteration: %s' % (k, str(w)))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Chạy thử chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight after 0 iteration: [1.08841881 0.73504649 0.11305941]\n",
      "Weight after 5000 iteration: [-0.52280011  5.12987932 -3.74261504]\n",
      "Weight after 10000 iteration: [-0.49539334  5.64092276 -7.29776997]\n",
      "Weight after 15000 iteration: [ -0.47316887   6.05533373 -10.18068575]\n",
      "Weight after 20000 iteration: [ -0.4551468    6.39138431 -12.5184751 ]\n",
      "Weight after 25000 iteration: [ -0.44053249   6.66389158 -14.41421522]\n",
      "Weight after 30000 iteration: [ -0.42868158   6.88487083 -15.95149255]\n",
      "Weight after 35000 iteration: [ -0.41907154   7.06406544 -17.19808831]\n",
      "Weight after 40000 iteration: [ -0.41127866   7.20937639 -18.20896706]\n",
      "Weight after 45000 iteration: [ -0.40495931   7.3272107  -19.02870019]\n",
      "Weight after 50000 iteration: [ -0.39983489   7.42276389 -19.69343116]\n",
      "Weight after 55000 iteration: [ -0.39567943   7.50024907 -20.2324691 ]\n",
      "Weight after 60000 iteration: [ -0.39230972   7.56308268 -20.66958113]\n",
      "Weight after 65000 iteration: [ -0.38957719   7.61403518 -21.02404027]\n",
      "Weight after 70000 iteration: [ -0.38736135   7.65535314 -21.31147524]\n",
      "Weight after 75000 iteration: [ -0.38556449   7.68885835 -21.54455955]\n",
      "Weight after 80000 iteration: [ -0.38410741   7.7160281  -21.73357027]\n",
      "Weight after 85000 iteration: [ -0.38292584   7.73806037 -21.88684123]\n",
      "Weight after 90000 iteration: [ -0.38196769   7.75592659 -22.0111304 ]\n",
      "Weight after 95000 iteration: [ -0.38119071   7.7704145  -22.11191791]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -0.38056077,   7.78216081, -22.19363296])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_solve_via_gradient_descent(train_X_new, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tìm nghiệm xấp xỉ bằng TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nhập thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Khai báo biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.006\n",
    "training_epochs = 55000\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 6. Khai báo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(train_X_new)\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float64, name='x')\n",
    "Y = tf.placeholder(dtype=tf.float64, name='y')\n",
    "\n",
    "W = tf.Variable(initial_value=np.random.randn(train_X_new.shape[1], 1), name='weights')\n",
    "\n",
    "train_Y = train_Y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 7. Xây dựng mô hình hồi quy tuyến tính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: implement a gradient descent function\n",
    "pred = tf.matmul(X, W)\n",
    "# pred = tf.add(tf.reshape(tf.maul(X, W), [-1,]), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 8. Viết hàm cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: implement a cost function\n",
    "\n",
    "cost = tf.reduce_sum(tf.pow(pred - Y, 2)) / (2*n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 9. Viết hàm train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: implemement GD\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 10. Chạy chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.38961234]\n",
      " [  7.61337973]\n",
      " [-21.01948052]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(optimizer, feed_dict={X: train_X_new, Y: train_Y})\n",
    "    \n",
    "    print(sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'x_8' with dtype double\n\t [[Node: x_8 = Placeholder[dtype=DT_DOUBLE, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'x_8', defined at:\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-70-4041eb9d89ae>\", line 3, in <module>\n    X = tf.placeholder(name='x', dtype=tf.float64)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1777, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5495, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3309, in create_op\n    op_def=op_def)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1669, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'x_8' with dtype double\n\t [[Node: x_8 = Placeholder[dtype=DT_DOUBLE, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m       Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1315\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1422\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1423\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'x_8' with dtype double\n\t [[Node: x_8 = Placeholder[dtype=DT_DOUBLE, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-dbab388ce7be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# TODO: implement sess.run for every pair of data x, y in train_X and train_Y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_X_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Display logs per epoch step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 908\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    909\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1143\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1144\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1324\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1325\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1341\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1343\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1345\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'x_8' with dtype double\n\t [[Node: x_8 = Placeholder[dtype=DT_DOUBLE, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'x_8', defined at:\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-70-4041eb9d89ae>\", line 3, in <module>\n    X = tf.placeholder(name='x', dtype=tf.float64)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1777, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5495, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3309, in create_op\n    op_def=op_def)\n  File \"D:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1669, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'x_8' with dtype double\n\t [[Node: x_8 = Placeholder[dtype=DT_DOUBLE, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        # TODO: implement sess.run for every pair of data x, y in train_X and train_Y\n",
    "        sess.run(optimizer, feed_dict = {X: train_X_new, Y: train_Y})\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={'x1:0': train_X_new, Y: train_Y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X_new, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost= 0.265281640 W= [ 0.95222931  3.54588731] b= [ 4.83365221  0.75297634]\n",
      "Epoch: 0100 cost= 0.184618099 W= [ 0.73674735  3.57990604] b= [ 8.18622282  0.53595119]\n",
      "Epoch: 0150 cost= 0.126933328 W= [ 0.5495877  3.6137264] b= [ 11.0981414    0.32019145]\n",
      "Epoch: 0200 cost= 0.086173390 W= [ 0.38702776  3.64734957] b= [ 13.62732596   0.10568975]\n",
      "Epoch: 0250 cost= 0.057825143 W= [ 0.24583423  3.6807767 ] b= [ 15.82408193  -0.10756126]\n",
      "Epoch: 0300 cost= 0.038530730 W= [ 0.12319876  3.71400892] b= [ 17.73210275  -0.31956886]\n",
      "Epoch: 0350 cost= 0.025797683 W= [ 0.01668213  3.74704737] b= [ 19.38933891  -0.53034031]\n",
      "Epoch: 0400 cost= 0.017781031 W= [-0.07583426  3.77989318] b= [ 20.82875283  -0.7398828 ]\n",
      "Epoch: 0450 cost= 0.013119634 W= [-0.15619057  3.81254748] b= [ 22.0789744   -0.94820351]\n",
      "Epoch: 0500 cost= 0.010813313 W= [-0.22598508  3.84501138] b= [ 23.16487053  -1.15530957]\n",
      "Epoch: 0550 cost= 0.010130696 W= [-0.28660601  3.87728599] b= [ 24.10803966  -1.36120805]\n",
      "Epoch: 0600 cost= 0.010540151 W= [-0.3392591   3.90937242] b= [ 24.92724141  -1.56590599]\n",
      "Epoch: 0650 cost= 0.011658089 W= [-0.38499162  3.94127177] b= [ 25.63876969  -1.76941039]\n",
      "Epoch: 0700 cost= 0.013210306 W= [-0.42471319  3.97298511] b= [ 26.25677678  -1.97172822]\n",
      "Epoch: 0750 cost= 0.015003121 W= [-0.45921388  4.00451355] b= [ 26.79355483  -2.1728664 ]\n",
      "Epoch: 0800 cost= 0.016901870 W= [-0.4891799   4.03585815] b= [ 27.25978036  -2.37283179]\n",
      "Epoch: 0850 cost= 0.018814904 W= [-0.51520727  4.06701999] b= [ 27.66472657  -2.57163124]\n",
      "Epoch: 0900 cost= 0.020681719 W= [-0.53781368  4.09800013] b= [ 28.01644784  -2.76927155]\n",
      "Epoch: 0950 cost= 0.022464169 W= [-0.55744878  4.12879964] b= [ 28.3219399   -2.96575947]\n",
      "Epoch: 1000 cost= 0.024139990 W= [-0.57450309  4.15941956] b= [ 28.58727898  -3.16110173]\n",
      "Optimization Finished!\n",
      "Training cost= 0.0241399896865 W= [-0.57450309  4.15941956] b= [ 28.58727898  -3.16110173] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(optimizer, feed_dict = {X: train_X, Y: train_Y})\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: x, Y:y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: x, Y: y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fill the blanks\n",
    "\n",
    "n_samples = train_X_new.shape[0]\n",
    "\n",
    "# tf Graph Input\n",
    "X = tf.placeholder(tf.float64, name='x') # Ko phai la np array, tf.placeholder\n",
    "Y = tf.placeholder(tf.float64, name='y')\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(np.zeros((train_X_new.shape[1],1)), name=\"weights\")\n",
    "\n",
    "# init = tf.global_variables_initializer()\n",
    "# sess = tf.Session()\n",
    "# sess.run(init)\n",
    "# print(sess.run(W))\n",
    "\n",
    "train_Y = train_Y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 7. Xây dựng mô hình hồi quy tuyến tính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(1)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implement a gradient descent function\n",
    "pred = tf.matmul(X, W) # y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 8. Viết hàm cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implement a cost function\n",
    "\n",
    "cost = tf.reduce_sum(tf.pow(pred - Y, 2))/(2*train_X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 9. Viết hàm train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implemement GD\n",
    "learning_rate = 0.006\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 10. Chạy chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost= 20.873978736 W= [[-0.50876485]\n",
      " [ 4.39846583]\n",
      " [ 0.56889287]]\n",
      "Epoch: 0100 cost= 20.778875347 W= [[-0.55441209]\n",
      " [ 4.51326197]\n",
      " [ 0.5257399 ]]\n",
      "Epoch: 0150 cost= 20.767386007 W= [[-0.555226  ]\n",
      " [ 4.52450369]\n",
      " [ 0.46819587]]\n",
      "Epoch: 0200 cost= 20.756016501 W= [[-0.55481484]\n",
      " [ 4.53289293]\n",
      " [ 0.41039984]]\n",
      "Epoch: 0250 cost= 20.744704091 W= [[-0.55437126]\n",
      " [ 4.54118386]\n",
      " [ 0.35273815]]\n",
      "Epoch: 0300 cost= 20.733448443 W= [[-0.55392789]\n",
      " [ 4.54945184]\n",
      " [ 0.29522101]]\n",
      "Epoch: 0350 cost= 20.722249272 W= [[-0.5534856 ]\n",
      " [ 4.557699  ]\n",
      " [ 0.23784835]]\n",
      "Epoch: 0400 cost= 20.711106296 W= [[-0.55304442]\n",
      " [ 4.56592544]\n",
      " [ 0.1806198 ]]\n",
      "Epoch: 0450 cost= 20.700019231 W= [[-0.55260436]\n",
      " [ 4.57413122]\n",
      " [ 0.12353502]]\n",
      "Epoch: 0500 cost= 20.688987799 W= [[-0.55216539]\n",
      " [ 4.58231638]\n",
      " [ 0.06659363]]\n",
      "Epoch: 0550 cost= 20.678011719 W= [[-0.55172753]\n",
      " [ 4.59048099]\n",
      " [ 0.00979528]]\n",
      "Epoch: 0600 cost= 20.667090713 W= [[-0.55129077]\n",
      " [ 4.59862508]\n",
      " [-0.0468604 ]]\n",
      "Epoch: 0650 cost= 20.656224506 W= [[-0.55085511]\n",
      " [ 4.60674871]\n",
      " [-0.10337375]]\n",
      "Epoch: 0700 cost= 20.645412822 W= [[-0.55042054]\n",
      " [ 4.61485194]\n",
      " [-0.15974514]]\n",
      "Epoch: 0750 cost= 20.634655389 W= [[-0.54998707]\n",
      " [ 4.62293481]\n",
      " [-0.21597493]]\n",
      "Epoch: 0800 cost= 20.623951932 W= [[-0.54955468]\n",
      " [ 4.63099738]\n",
      " [-0.27206347]]\n",
      "Epoch: 0850 cost= 20.613302183 W= [[-0.54912338]\n",
      " [ 4.6390397 ]\n",
      " [-0.32801111]]\n",
      "Epoch: 0900 cost= 20.602705871 W= [[-0.54869316]\n",
      " [ 4.64706181]\n",
      " [-0.38381821]]\n",
      "Epoch: 0950 cost= 20.592162728 W= [[-0.54826402]\n",
      " [ 4.65506377]\n",
      " [-0.43948512]]\n",
      "Epoch: 1000 cost= 20.581672488 W= [[-0.54783596]\n",
      " [ 4.66304563]\n",
      " [-0.4950122 ]]\n",
      "Optimization Finished!\n",
      "Training cost= 20.58167248753463 W= [[-0.54783596]\n",
      " [ 4.66304563]\n",
      " [-0.4950122 ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        # TODO: implement sess.run for for full batch gradient descent\n",
    "        sess.run(optimizer, feed_dict={X: train_X_new, Y: train_Y})\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % 50 == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X_new, Y: train_Y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X_new, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#TODO: Fill the blanks\n",
    "\n",
    "n_samples = train_X_new.shape[0]\n",
    "\n",
    "# tf Graph Input\n",
    "X = tf.placeholder(tf.float64, name='x1') # Ko phai la np array, tf.placeholder\n",
    "Y = tf.placeholder(tf.float64, name='y')\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(np.zeros((train_X.shape[1],1)), name=\"weights\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(W))\n",
    "b = tf.Variable(np.zeros((1,1)), name=\"bias\")\n",
    "\n",
    "train_Y = train_Y.reshape(train_Y.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 7. Xây dựng mô hình hồi quy tuyến tính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implement a gradient descent function\n",
    "pred = tf.matmul(X, W) + b # y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 8. Viết hàm cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implement a cost function\n",
    "\n",
    "cost = tf.reduce_sum(tf.pow(pred - Y, 2))/(2*train_X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 9. Viết hàm train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implemement GD\n",
    "learning_rate = 0.006\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 10. Chạy chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost= 20.873978736 W= [[-0.50876485]\n",
      " [ 4.39846583]] b= [[0.56889287]]\n",
      "Epoch: 0100 cost= 20.778875347 W= [[-0.55441209]\n",
      " [ 4.51326197]] b= [[0.5257399]]\n",
      "Epoch: 0150 cost= 20.767386007 W= [[-0.555226  ]\n",
      " [ 4.52450369]] b= [[0.46819587]]\n",
      "Epoch: 0200 cost= 20.756016501 W= [[-0.55481484]\n",
      " [ 4.53289293]] b= [[0.41039984]]\n",
      "Epoch: 0250 cost= 20.744704091 W= [[-0.55437126]\n",
      " [ 4.54118386]] b= [[0.35273815]]\n",
      "Epoch: 0300 cost= 20.733448443 W= [[-0.55392789]\n",
      " [ 4.54945184]] b= [[0.29522101]]\n",
      "Epoch: 0350 cost= 20.722249272 W= [[-0.5534856]\n",
      " [ 4.557699 ]] b= [[0.23784835]]\n",
      "Epoch: 0400 cost= 20.711106296 W= [[-0.55304442]\n",
      " [ 4.56592544]] b= [[0.1806198]]\n",
      "Epoch: 0450 cost= 20.700019231 W= [[-0.55260436]\n",
      " [ 4.57413122]] b= [[0.12353502]]\n",
      "Epoch: 0500 cost= 20.688987799 W= [[-0.55216539]\n",
      " [ 4.58231638]] b= [[0.06659363]]\n",
      "Epoch: 0550 cost= 20.678011719 W= [[-0.55172753]\n",
      " [ 4.59048099]] b= [[0.00979528]]\n",
      "Epoch: 0600 cost= 20.667090713 W= [[-0.55129077]\n",
      " [ 4.59862508]] b= [[-0.0468604]]\n",
      "Epoch: 0650 cost= 20.656224506 W= [[-0.55085511]\n",
      " [ 4.60674871]] b= [[-0.10337375]]\n",
      "Epoch: 0700 cost= 20.645412822 W= [[-0.55042054]\n",
      " [ 4.61485194]] b= [[-0.15974514]]\n",
      "Epoch: 0750 cost= 20.634655389 W= [[-0.54998707]\n",
      " [ 4.62293481]] b= [[-0.21597493]]\n",
      "Epoch: 0800 cost= 20.623951932 W= [[-0.54955468]\n",
      " [ 4.63099738]] b= [[-0.27206347]]\n",
      "Epoch: 0850 cost= 20.613302183 W= [[-0.54912338]\n",
      " [ 4.6390397 ]] b= [[-0.32801111]]\n",
      "Epoch: 0900 cost= 20.602705871 W= [[-0.54869316]\n",
      " [ 4.64706181]] b= [[-0.38381821]]\n",
      "Epoch: 0950 cost= 20.592162728 W= [[-0.54826402]\n",
      " [ 4.65506377]] b= [[-0.43948512]]\n",
      "Epoch: 1000 cost= 20.581672488 W= [[-0.54783596]\n",
      " [ 4.66304563]] b= [[-0.4950122]]\n",
      "Epoch: 1050 cost= 20.571234884 W= [[-0.54740898]\n",
      " [ 4.67100744]] b= [[-0.5503998]]\n",
      "Epoch: 1100 cost= 20.560849653 W= [[-0.54698306]\n",
      " [ 4.67894925]] b= [[-0.60564825]]\n",
      "Epoch: 1150 cost= 20.550516532 W= [[-0.54655822]\n",
      " [ 4.68687111]] b= [[-0.66075793]]\n",
      "Epoch: 1200 cost= 20.540235260 W= [[-0.54613445]\n",
      " [ 4.69477307]] b= [[-0.71572917]]\n",
      "Epoch: 1250 cost= 20.530005576 W= [[-0.54571174]\n",
      " [ 4.70265518]] b= [[-0.77056232]]\n",
      "Epoch: 1300 cost= 20.519827222 W= [[-0.54529009]\n",
      " [ 4.71051749]] b= [[-0.82525773]]\n",
      "Epoch: 1350 cost= 20.509699940 W= [[-0.5448695 ]\n",
      " [ 4.71836005]] b= [[-0.87981574]]\n",
      "Epoch: 1400 cost= 20.499623473 W= [[-0.54444997]\n",
      " [ 4.7261829 ]] b= [[-0.93423671]]\n",
      "Epoch: 1450 cost= 20.489597567 W= [[-0.54403149]\n",
      " [ 4.73398611]] b= [[-0.98852096]]\n",
      "Epoch: 1500 cost= 20.479621968 W= [[-0.54361406]\n",
      " [ 4.74176972]] b= [[-1.04266886]]\n",
      "Epoch: 1550 cost= 20.469696424 W= [[-0.54319768]\n",
      " [ 4.74953377]] b= [[-1.09668074]]\n",
      "Epoch: 1600 cost= 20.459820683 W= [[-0.54278235]\n",
      " [ 4.75727832]] b= [[-1.15055693]]\n",
      "Epoch: 1650 cost= 20.449994496 W= [[-0.54236806]\n",
      " [ 4.76500342]] b= [[-1.20429779]]\n",
      "Epoch: 1700 cost= 20.440217614 W= [[-0.54195481]\n",
      " [ 4.77270911]] b= [[-1.25790366]]\n",
      "Epoch: 1750 cost= 20.430489789 W= [[-0.5415426 ]\n",
      " [ 4.78039544]] b= [[-1.31137486]]\n",
      "Epoch: 1800 cost= 20.420810775 W= [[-0.54113143]\n",
      " [ 4.78806247]] b= [[-1.36471174]]\n",
      "Epoch: 1850 cost= 20.411180328 W= [[-0.54072128]\n",
      " [ 4.79571024]] b= [[-1.41791465]]\n",
      "Epoch: 1900 cost= 20.401598204 W= [[-0.54031217]\n",
      " [ 4.80333879]] b= [[-1.4709839]]\n",
      "Epoch: 1950 cost= 20.392064160 W= [[-0.53990409]\n",
      " [ 4.81094818]] b= [[-1.52391985]]\n",
      "Epoch: 2000 cost= 20.382577955 W= [[-0.53949703]\n",
      " [ 4.81853846]] b= [[-1.57672282]]\n",
      "Epoch: 2050 cost= 20.373139349 W= [[-0.53909099]\n",
      " [ 4.82610967]] b= [[-1.62939314]]\n",
      "Epoch: 2100 cost= 20.363748103 W= [[-0.53868597]\n",
      " [ 4.83366186]] b= [[-1.68193116]]\n",
      "Epoch: 2150 cost= 20.354403980 W= [[-0.53828197]\n",
      " [ 4.84119508]] b= [[-1.73433721]]\n",
      "Epoch: 2200 cost= 20.345106742 W= [[-0.53787899]\n",
      " [ 4.84870938]] b= [[-1.78661161]]\n",
      "Epoch: 2250 cost= 20.335856156 W= [[-0.53747702]\n",
      " [ 4.8562048 ]] b= [[-1.83875469]]\n",
      "Epoch: 2300 cost= 20.326651986 W= [[-0.53707605]\n",
      " [ 4.86368139]] b= [[-1.8907668]]\n",
      "Epoch: 2350 cost= 20.317494000 W= [[-0.5366761]\n",
      " [ 4.8711392]] b= [[-1.94264824]]\n",
      "Epoch: 2400 cost= 20.308381966 W= [[-0.53627715]\n",
      " [ 4.87857828]] b= [[-1.99439936]]\n",
      "Epoch: 2450 cost= 20.299315653 W= [[-0.5358792 ]\n",
      " [ 4.88599867]] b= [[-2.04602049]]\n",
      "Epoch: 2500 cost= 20.290294833 W= [[-0.53548225]\n",
      " [ 4.89340042]] b= [[-2.09751193]]\n",
      "Epoch: 2550 cost= 20.281319276 W= [[-0.5350863 ]\n",
      " [ 4.90078358]] b= [[-2.14887404]]\n",
      "Epoch: 2600 cost= 20.272388756 W= [[-0.53469134]\n",
      " [ 4.90814819]] b= [[-2.20010712]]\n",
      "Epoch: 2650 cost= 20.263503047 W= [[-0.53429738]\n",
      " [ 4.9154943 ]] b= [[-2.2512115]]\n",
      "Epoch: 2700 cost= 20.254661924 W= [[-0.5339044 ]\n",
      " [ 4.92282195]] b= [[-2.30218751]]\n",
      "Epoch: 2750 cost= 20.245865163 W= [[-0.53351241]\n",
      " [ 4.9301312 ]] b= [[-2.35303546]]\n",
      "Epoch: 2800 cost= 20.237112541 W= [[-0.53312141]\n",
      " [ 4.93742209]] b= [[-2.40375569]]\n",
      "Epoch: 2850 cost= 20.228403838 W= [[-0.53273139]\n",
      " [ 4.94469466]] b= [[-2.4543485]]\n",
      "Epoch: 2900 cost= 20.219738832 W= [[-0.53234235]\n",
      " [ 4.95194897]] b= [[-2.50481423]]\n",
      "Epoch: 2950 cost= 20.211117304 W= [[-0.53195428]\n",
      " [ 4.95918505]] b= [[-2.55515318]]\n",
      "Epoch: 3000 cost= 20.202539037 W= [[-0.53156719]\n",
      " [ 4.96640296]] b= [[-2.60536569]]\n",
      "Epoch: 3050 cost= 20.194003813 W= [[-0.53118108]\n",
      " [ 4.97360273]] b= [[-2.65545206]]\n",
      "Epoch: 3100 cost= 20.185511417 W= [[-0.53079593]\n",
      " [ 4.98078442]] b= [[-2.70541261]]\n",
      "Epoch: 3150 cost= 20.177061632 W= [[-0.53041175]\n",
      " [ 4.98794806]] b= [[-2.75524766]]\n",
      "Epoch: 3200 cost= 20.168654247 W= [[-0.53002854]\n",
      " [ 4.99509372]] b= [[-2.80495753]]\n",
      "Epoch: 3250 cost= 20.160289047 W= [[-0.52964628]\n",
      " [ 5.00222142]] b= [[-2.85454252]]\n",
      "Epoch: 3300 cost= 20.151965821 W= [[-0.52926499]\n",
      " [ 5.00933122]] b= [[-2.90400296]]\n",
      "Epoch: 3350 cost= 20.143684358 W= [[-0.52888466]\n",
      " [ 5.01642315]] b= [[-2.95333915]]\n",
      "Epoch: 3400 cost= 20.135444450 W= [[-0.52850528]\n",
      " [ 5.02349728]] b= [[-3.0025514]]\n",
      "Epoch: 3450 cost= 20.127245887 W= [[-0.52812685]\n",
      " [ 5.03055363]] b= [[-3.05164004]]\n",
      "Epoch: 3500 cost= 20.119088461 W= [[-0.52774938]\n",
      " [ 5.03759225]] b= [[-3.10060536]]\n",
      "Epoch: 3550 cost= 20.110971968 W= [[-0.52737285]\n",
      " [ 5.0446132 ]] b= [[-3.14944769]]\n",
      "Epoch: 3600 cost= 20.102896201 W= [[-0.52699727]\n",
      " [ 5.05161651]] b= [[-3.19816732]]\n",
      "Epoch: 3650 cost= 20.094860955 W= [[-0.52662264]\n",
      " [ 5.05860223]] b= [[-3.24676457]]\n",
      "Epoch: 3700 cost= 20.086866028 W= [[-0.52624894]\n",
      " [ 5.06557039]] b= [[-3.29523974]]\n",
      "Epoch: 3750 cost= 20.078911217 W= [[-0.52587618]\n",
      " [ 5.07252106]] b= [[-3.34359314]]\n",
      "Epoch: 3800 cost= 20.070996321 W= [[-0.52550436]\n",
      " [ 5.07945426]] b= [[-3.39182508]]\n",
      "Epoch: 3850 cost= 20.063121140 W= [[-0.52513347]\n",
      " [ 5.08637005]] b= [[-3.43993585]]\n",
      "Epoch: 3900 cost= 20.055285474 W= [[-0.52476352]\n",
      " [ 5.09326846]] b= [[-3.48792578]]\n",
      "Epoch: 3950 cost= 20.047489125 W= [[-0.52439449]\n",
      " [ 5.10014955]] b= [[-3.53579515]]\n",
      "Epoch: 4000 cost= 20.039731895 W= [[-0.52402639]\n",
      " [ 5.10701335]] b= [[-3.58354427]]\n",
      "Epoch: 4050 cost= 20.032013590 W= [[-0.52365922]\n",
      " [ 5.11385991]] b= [[-3.63117345]]\n",
      "Epoch: 4100 cost= 20.024334012 W= [[-0.52329297]\n",
      " [ 5.12068927]] b= [[-3.67868298]]\n",
      "Epoch: 4150 cost= 20.016692968 W= [[-0.52292763]\n",
      " [ 5.12750148]] b= [[-3.72607317]]\n",
      "Epoch: 4200 cost= 20.009090265 W= [[-0.52256322]\n",
      " [ 5.13429657]] b= [[-3.77334432]]\n",
      "Epoch: 4250 cost= 20.001525710 W= [[-0.52219972]\n",
      " [ 5.14107459]] b= [[-3.82049671]]\n",
      "Epoch: 4300 cost= 19.993999112 W= [[-0.52183713]\n",
      " [ 5.14783559]] b= [[-3.86753067]]\n",
      "Epoch: 4350 cost= 19.986510279 W= [[-0.52147546]\n",
      " [ 5.1545796 ]] b= [[-3.91444647]]\n",
      "Epoch: 4400 cost= 19.979059024 W= [[-0.52111469]\n",
      " [ 5.16130668]] b= [[-3.96124442]]\n",
      "Epoch: 4450 cost= 19.971645157 W= [[-0.52075483]\n",
      " [ 5.16801685]] b= [[-4.00792481]]\n",
      "Epoch: 4500 cost= 19.964268490 W= [[-0.52039588]\n",
      " [ 5.17471017]] b= [[-4.05448794]]\n",
      "Epoch: 4550 cost= 19.956928838 W= [[-0.52003782]\n",
      " [ 5.18138667]] b= [[-4.1009341]]\n",
      "Epoch: 4600 cost= 19.949626013 W= [[-0.51968067]\n",
      " [ 5.18804641]] b= [[-4.14726359]]\n",
      "Epoch: 4650 cost= 19.942359832 W= [[-0.51932441]\n",
      " [ 5.19468941]] b= [[-4.1934767]]\n",
      "Epoch: 4700 cost= 19.935130111 W= [[-0.51896905]\n",
      " [ 5.20131573]] b= [[-4.23957373]]\n",
      "Epoch: 4750 cost= 19.927936666 W= [[-0.51861458]\n",
      " [ 5.2079254 ]] b= [[-4.28555495]]\n",
      "Epoch: 4800 cost= 19.920779316 W= [[-0.518261  ]\n",
      " [ 5.21451846]] b= [[-4.33142068]]\n",
      "Epoch: 4850 cost= 19.913657879 W= [[-0.5179083 ]\n",
      " [ 5.22109497]] b= [[-4.37717118]]\n",
      "Epoch: 4900 cost= 19.906572175 W= [[-0.5175565 ]\n",
      " [ 5.22765495]] b= [[-4.42280676]]\n",
      "Epoch: 4950 cost= 19.899522026 W= [[-0.51720558]\n",
      " [ 5.23419846]] b= [[-4.46832771]]\n",
      "Epoch: 5000 cost= 19.892507252 W= [[-0.51685554]\n",
      " [ 5.24072553]] b= [[-4.5137343]]\n",
      "Epoch: 5050 cost= 19.885527676 W= [[-0.51650637]\n",
      " [ 5.2472362 ]] b= [[-4.55902684]]\n",
      "Epoch: 5100 cost= 19.878583121 W= [[-0.51615809]\n",
      " [ 5.25373052]] b= [[-4.60420559]]\n",
      "Epoch: 5150 cost= 19.871673412 W= [[-0.51581068]\n",
      " [ 5.26020853]] b= [[-4.64927086]]\n",
      "Epoch: 5200 cost= 19.864798374 W= [[-0.51546414]\n",
      " [ 5.26667026]] b= [[-4.69422293]]\n",
      "Epoch: 5250 cost= 19.857957834 W= [[-0.51511848]\n",
      " [ 5.27311576]] b= [[-4.73906207]]\n",
      "Epoch: 5300 cost= 19.851151616 W= [[-0.51477368]\n",
      " [ 5.27954507]] b= [[-4.78378858]]\n",
      "Epoch: 5350 cost= 19.844379551 W= [[-0.51442975]\n",
      " [ 5.28595823]] b= [[-4.82840274]]\n",
      "Epoch: 5400 cost= 19.837641465 W= [[-0.51408668]\n",
      " [ 5.29235527]] b= [[-4.87290482]]\n",
      "Epoch: 5450 cost= 19.830937190 W= [[-0.51374448]\n",
      " [ 5.29873625]] b= [[-4.91729511]]\n",
      "Epoch: 5500 cost= 19.824266554 W= [[-0.51340313]\n",
      " [ 5.3051012 ]] b= [[-4.9615739]]\n",
      "Epoch: 5550 cost= 19.817629390 W= [[-0.51306264]\n",
      " [ 5.31145016]] b= [[-5.00574146]]\n",
      "Epoch: 5600 cost= 19.811025529 W= [[-0.51272301]\n",
      " [ 5.31778318]] b= [[-5.04979806]]\n",
      "Epoch: 5650 cost= 19.804454804 W= [[-0.51238423]\n",
      " [ 5.32410028]] b= [[-5.093744]]\n",
      "Epoch: 5700 cost= 19.797917050 W= [[-0.5120463 ]\n",
      " [ 5.33040151]] b= [[-5.13757955]]\n",
      "Epoch: 5750 cost= 19.791412099 W= [[-0.51170922]\n",
      " [ 5.33668692]] b= [[-5.18130498]]\n",
      "Epoch: 5800 cost= 19.784939789 W= [[-0.51137298]\n",
      " [ 5.34295654]] b= [[-5.22492057]]\n",
      "Epoch: 5850 cost= 19.778499955 W= [[-0.51103759]\n",
      " [ 5.34921041]] b= [[-5.2684266]]\n",
      "Epoch: 5900 cost= 19.772092434 W= [[-0.51070305]\n",
      " [ 5.35544857]] b= [[-5.31182334]]\n",
      "Epoch: 5950 cost= 19.765717064 W= [[-0.51036934]\n",
      " [ 5.36167105]] b= [[-5.35511106]]\n",
      "Epoch: 6000 cost= 19.759373684 W= [[-0.51003647]\n",
      " [ 5.36787791]] b= [[-5.39829005]]\n",
      "Epoch: 6050 cost= 19.753062133 W= [[-0.50970444]\n",
      " [ 5.37406918]] b= [[-5.44136058]]\n",
      "Epoch: 6100 cost= 19.746782251 W= [[-0.50937324]\n",
      " [ 5.38024489]] b= [[-5.4843229]]\n",
      "Epoch: 6150 cost= 19.740533880 W= [[-0.50904288]\n",
      " [ 5.38640509]] b= [[-5.52717731]]\n",
      "Epoch: 6200 cost= 19.734316862 W= [[-0.50871334]\n",
      " [ 5.39254981]] b= [[-5.56992407]]\n",
      "Epoch: 6250 cost= 19.728131038 W= [[-0.50838463]\n",
      " [ 5.3986791 ]] b= [[-5.61256345]]\n",
      "Epoch: 6300 cost= 19.721976254 W= [[-0.50805675]\n",
      " [ 5.404793  ]] b= [[-5.65509571]]\n",
      "Epoch: 6350 cost= 19.715852352 W= [[-0.50772969]\n",
      " [ 5.41089153]] b= [[-5.69752114]]\n",
      "Epoch: 6400 cost= 19.709759178 W= [[-0.50740346]\n",
      " [ 5.41697475]] b= [[-5.73983999]]\n",
      "Epoch: 6450 cost= 19.703696578 W= [[-0.50707804]\n",
      " [ 5.42304268]] b= [[-5.78205254]]\n",
      "Epoch: 6500 cost= 19.697664398 W= [[-0.50675344]\n",
      " [ 5.42909537]] b= [[-5.82415905]]\n",
      "Epoch: 6550 cost= 19.691662486 W= [[-0.50642965]\n",
      " [ 5.43513286]] b= [[-5.86615978]]\n",
      "Epoch: 6600 cost= 19.685690690 W= [[-0.50610668]\n",
      " [ 5.44115518]] b= [[-5.90805501]]\n",
      "Epoch: 6650 cost= 19.679748859 W= [[-0.50578452]\n",
      " [ 5.44716237]] b= [[-5.949845]]\n",
      "Epoch: 6700 cost= 19.673836842 W= [[-0.50546317]\n",
      " [ 5.45315447]] b= [[-5.99153001]]\n",
      "Epoch: 6750 cost= 19.667954489 W= [[-0.50514263]\n",
      " [ 5.45913152]] b= [[-6.03311031]]\n",
      "Epoch: 6800 cost= 19.662101653 W= [[-0.50482289]\n",
      " [ 5.46509356]] b= [[-6.07458616]]\n",
      "Epoch: 6850 cost= 19.656278184 W= [[-0.50450396]\n",
      " [ 5.47104062]] b= [[-6.11595783]]\n",
      "Epoch: 6900 cost= 19.650483936 W= [[-0.50418582]\n",
      " [ 5.47697274]] b= [[-6.15722556]]\n",
      "Epoch: 6950 cost= 19.644718761 W= [[-0.50386849]\n",
      " [ 5.48288996]] b= [[-6.19838963]]\n",
      "Epoch: 7000 cost= 19.638982515 W= [[-0.50355195]\n",
      " [ 5.48879231]] b= [[-6.2394503]]\n",
      "Epoch: 7050 cost= 19.633275051 W= [[-0.50323621]\n",
      " [ 5.49467984]] b= [[-6.28040782]]\n",
      "Epoch: 7100 cost= 19.627596226 W= [[-0.50292126]\n",
      " [ 5.50055258]] b= [[-6.32126246]]\n",
      "Epoch: 7150 cost= 19.621945895 W= [[-0.5026071 ]\n",
      " [ 5.50641056]] b= [[-6.36201447]]\n",
      "Epoch: 7200 cost= 19.616323916 W= [[-0.50229373]\n",
      " [ 5.51225383]] b= [[-6.40266411]]\n",
      "Epoch: 7250 cost= 19.610730147 W= [[-0.50198115]\n",
      " [ 5.51808242]] b= [[-6.44321163]]\n",
      "Epoch: 7300 cost= 19.605164445 W= [[-0.50166935]\n",
      " [ 5.52389637]] b= [[-6.48365731]]\n",
      "Epoch: 7350 cost= 19.599626671 W= [[-0.50135834]\n",
      " [ 5.52969572]] b= [[-6.52400138]]\n",
      "Epoch: 7400 cost= 19.594116683 W= [[-0.50104811]\n",
      " [ 5.5354805 ]] b= [[-6.56424411]]\n",
      "Epoch: 7450 cost= 19.588634343 W= [[-0.50073865]\n",
      " [ 5.54125074]] b= [[-6.60438574]]\n",
      "Epoch: 7500 cost= 19.583179511 W= [[-0.50042998]\n",
      " [ 5.5470065 ]] b= [[-6.64442654]]\n",
      "Epoch: 7550 cost= 19.577752051 W= [[-0.50012208]\n",
      " [ 5.55274779]] b= [[-6.68436676]]\n",
      "Epoch: 7600 cost= 19.572351823 W= [[-0.49981495]\n",
      " [ 5.55847466]] b= [[-6.72420665]]\n",
      "Epoch: 7650 cost= 19.566978693 W= [[-0.4995086 ]\n",
      " [ 5.56418715]] b= [[-6.76394646]]\n",
      "Epoch: 7700 cost= 19.561632523 W= [[-0.49920301]\n",
      " [ 5.56988528]] b= [[-6.80358645]]\n",
      "Epoch: 7750 cost= 19.556313179 W= [[-0.49889819]\n",
      " [ 5.5755691 ]] b= [[-6.84312685]]\n",
      "Epoch: 7800 cost= 19.551020525 W= [[-0.49859414]\n",
      " [ 5.58123865]] b= [[-6.88256794]]\n",
      "Epoch: 7850 cost= 19.545754429 W= [[-0.49829085]\n",
      " [ 5.58689395]] b= [[-6.92190994]]\n",
      "Epoch: 7900 cost= 19.540514756 W= [[-0.49798832]\n",
      " [ 5.59253504]] b= [[-6.96115312]]\n",
      "Epoch: 7950 cost= 19.535301375 W= [[-0.49768656]\n",
      " [ 5.59816197]] b= [[-7.00029772]]\n",
      "Epoch: 8000 cost= 19.530114153 W= [[-0.49738555]\n",
      " [ 5.60377476]] b= [[-7.03934399]]\n",
      "Epoch: 8050 cost= 19.524952958 W= [[-0.4970853 ]\n",
      " [ 5.60937345]] b= [[-7.07829217]]\n",
      "Epoch: 8100 cost= 19.519817661 W= [[-0.4967858 ]\n",
      " [ 5.61495808]] b= [[-7.11714251]]\n",
      "Epoch: 8150 cost= 19.514708132 W= [[-0.49648705]\n",
      " [ 5.62052867]] b= [[-7.15589527]]\n",
      "Epoch: 8200 cost= 19.509624240 W= [[-0.49618906]\n",
      " [ 5.62608528]] b= [[-7.19455067]]\n",
      "Epoch: 8250 cost= 19.504565858 W= [[-0.49589181]\n",
      " [ 5.63162793]] b= [[-7.23310897]]\n",
      "Epoch: 8300 cost= 19.499532857 W= [[-0.49559531]\n",
      " [ 5.63715665]] b= [[-7.27157042]]\n",
      "Epoch: 8350 cost= 19.494525111 W= [[-0.49529955]\n",
      " [ 5.64267148]] b= [[-7.30993525]]\n",
      "Epoch: 8400 cost= 19.489542492 W= [[-0.49500454]\n",
      " [ 5.64817247]] b= [[-7.3482037]]\n",
      "Epoch: 8450 cost= 19.484584874 W= [[-0.49471027]\n",
      " [ 5.65365963]] b= [[-7.38637603]]\n",
      "Epoch: 8500 cost= 19.479652132 W= [[-0.49441674]\n",
      " [ 5.65913301]] b= [[-7.42445246]]\n",
      "Epoch: 8550 cost= 19.474744141 W= [[-0.49412394]\n",
      " [ 5.66459264]] b= [[-7.46243325]]\n",
      "Epoch: 8600 cost= 19.469860777 W= [[-0.49383188]\n",
      " [ 5.67003856]] b= [[-7.50031863]]\n",
      "Epoch: 8650 cost= 19.465001917 W= [[-0.49354056]\n",
      " [ 5.67547079]] b= [[-7.53810884]]\n",
      "Epoch: 8700 cost= 19.460167436 W= [[-0.49324997]\n",
      " [ 5.68088938]] b= [[-7.57580412]]\n",
      "Epoch: 8750 cost= 19.455357214 W= [[-0.4929601 ]\n",
      " [ 5.68629436]] b= [[-7.61340472]]\n",
      "Epoch: 8800 cost= 19.450571128 W= [[-0.49267097]\n",
      " [ 5.69168576]] b= [[-7.65091085]]\n",
      "Epoch: 8850 cost= 19.445809057 W= [[-0.49238256]\n",
      " [ 5.69706362]] b= [[-7.68832278]]\n",
      "Epoch: 8900 cost= 19.441070880 W= [[-0.49209487]\n",
      " [ 5.70242797]] b= [[-7.72564072]]\n",
      "Epoch: 8950 cost= 19.436356479 W= [[-0.49180791]\n",
      " [ 5.70777884]] b= [[-7.76286492]]\n",
      "Epoch: 9000 cost= 19.431665733 W= [[-0.49152167]\n",
      " [ 5.71311627]] b= [[-7.79999561]]\n",
      "Epoch: 9050 cost= 19.426998524 W= [[-0.49123615]\n",
      " [ 5.7184403 ]] b= [[-7.83703303]]\n",
      "Epoch: 9100 cost= 19.422354733 W= [[-0.49095134]\n",
      " [ 5.72375095]] b= [[-7.87397742]]\n",
      "Epoch: 9150 cost= 19.417734244 W= [[-0.49066725]\n",
      " [ 5.72904826]] b= [[-7.91082899]]\n",
      "Epoch: 9200 cost= 19.413136938 W= [[-0.49038387]\n",
      " [ 5.73433226]] b= [[-7.947588]]\n",
      "Epoch: 9250 cost= 19.408562701 W= [[-0.49010121]\n",
      " [ 5.73960299]] b= [[-7.98425467]]\n",
      "Epoch: 9300 cost= 19.404011416 W= [[-0.48981926]\n",
      " [ 5.74486048]] b= [[-8.02082923]]\n",
      "Epoch: 9350 cost= 19.399482968 W= [[-0.48953801]\n",
      " [ 5.75010476]] b= [[-8.05731191]]\n",
      "Epoch: 9400 cost= 19.394977242 W= [[-0.48925747]\n",
      " [ 5.75533587]] b= [[-8.09370295]]\n",
      "Epoch: 9450 cost= 19.390494125 W= [[-0.48897764]\n",
      " [ 5.76055384]] b= [[-8.13000258]]\n",
      "Epoch: 9500 cost= 19.386033503 W= [[-0.4886985]\n",
      " [ 5.7657587]] b= [[-8.16621102]]\n",
      "Epoch: 9550 cost= 19.381595263 W= [[-0.48842007]\n",
      " [ 5.77095048]] b= [[-8.2023285]]\n",
      "Epoch: 9600 cost= 19.377179292 W= [[-0.48814234]\n",
      " [ 5.77612923]] b= [[-8.23835526]]\n",
      "Epoch: 9650 cost= 19.372785480 W= [[-0.48786531]\n",
      " [ 5.78129496]] b= [[-8.27429152]]\n",
      "Epoch: 9700 cost= 19.368413714 W= [[-0.48758897]\n",
      " [ 5.78644772]] b= [[-8.3101375]]\n",
      "Epoch: 9750 cost= 19.364063885 W= [[-0.48731333]\n",
      " [ 5.79158754]] b= [[-8.34589344]]\n",
      "Epoch: 9800 cost= 19.359735882 W= [[-0.48703838]\n",
      " [ 5.79671444]] b= [[-8.38155957]]\n",
      "Epoch: 9850 cost= 19.355429595 W= [[-0.48676412]\n",
      " [ 5.80182847]] b= [[-8.41713609]]\n",
      "Epoch: 9900 cost= 19.351144916 W= [[-0.48649055]\n",
      " [ 5.80692964]] b= [[-8.45262325]]\n",
      "Epoch: 9950 cost= 19.346881737 W= [[-0.48621766]\n",
      " [ 5.81201801]] b= [[-8.48802127]]\n",
      "Epoch: 10000 cost= 19.342639949 W= [[-0.48594546]\n",
      " [ 5.81709359]] b= [[-8.52333036]]\n",
      "Epoch: 10050 cost= 19.338419444 W= [[-0.48567395]\n",
      " [ 5.82215642]] b= [[-8.55855076]]\n",
      "Epoch: 10100 cost= 19.334220117 W= [[-0.48540311]\n",
      " [ 5.82720654]] b= [[-8.59368268]]\n",
      "Epoch: 10150 cost= 19.330041862 W= [[-0.48513296]\n",
      " [ 5.83224397]] b= [[-8.62872636]]\n",
      "Epoch: 10200 cost= 19.325884571 W= [[-0.48486349]\n",
      " [ 5.83726874]] b= [[-8.663682]]\n",
      "Epoch: 10250 cost= 19.321748140 W= [[-0.48459469]\n",
      " [ 5.84228089]] b= [[-8.69854983]]\n",
      "Epoch: 10300 cost= 19.317632465 W= [[-0.48432657]\n",
      " [ 5.84728045]] b= [[-8.73333008]]\n",
      "Epoch: 10350 cost= 19.313537441 W= [[-0.48405912]\n",
      " [ 5.85226746]] b= [[-8.76802296]]\n",
      "Epoch: 10400 cost= 19.309462965 W= [[-0.48379235]\n",
      " [ 5.85724193]] b= [[-8.80262869]]\n",
      "Epoch: 10450 cost= 19.305408933 W= [[-0.48352624]\n",
      " [ 5.86220391]] b= [[-8.83714748]]\n",
      "Epoch: 10500 cost= 19.301375243 W= [[-0.4832608 ]\n",
      " [ 5.86715343]] b= [[-8.87157957]]\n",
      "Epoch: 10550 cost= 19.297361793 W= [[-0.48299603]\n",
      " [ 5.87209051]] b= [[-8.90592516]]\n",
      "Epoch: 10600 cost= 19.293368481 W= [[-0.48273192]\n",
      " [ 5.87701519]] b= [[-8.94018448]]\n",
      "Epoch: 10650 cost= 19.289395206 W= [[-0.48246848]\n",
      " [ 5.8819275 ]] b= [[-8.97435774]]\n",
      "Epoch: 10700 cost= 19.285441869 W= [[-0.4822057 ]\n",
      " [ 5.88682747]] b= [[-9.00844515]]\n",
      "Epoch: 10750 cost= 19.281508368 W= [[-0.48194358]\n",
      " [ 5.89171513]] b= [[-9.04244694]]\n",
      "Epoch: 10800 cost= 19.277594604 W= [[-0.48168212]\n",
      " [ 5.89659051]] b= [[-9.07636331]]\n",
      "Epoch: 10850 cost= 19.273700478 W= [[-0.48142131]\n",
      " [ 5.90145364]] b= [[-9.11019449]]\n",
      "Epoch: 10900 cost= 19.269825892 W= [[-0.48116116]\n",
      " [ 5.90630456]] b= [[-9.14394068]]\n",
      "Epoch: 10950 cost= 19.265970747 W= [[-0.48090167]\n",
      " [ 5.9111433 ]] b= [[-9.1776021]]\n",
      "Epoch: 11000 cost= 19.262134946 W= [[-0.48064282]\n",
      " [ 5.91596988]] b= [[-9.21117896]]\n",
      "Epoch: 11050 cost= 19.258318392 W= [[-0.48038463]\n",
      " [ 5.92078433]] b= [[-9.24467148]]\n",
      "Epoch: 11100 cost= 19.254520989 W= [[-0.48012708]\n",
      " [ 5.92558669]] b= [[-9.27807986]]\n",
      "Epoch: 11150 cost= 19.250742639 W= [[-0.47987018]\n",
      " [ 5.93037699]] b= [[-9.31140433]]\n",
      "Epoch: 11200 cost= 19.246983249 W= [[-0.47961393]\n",
      " [ 5.93515525]] b= [[-9.34464508]]\n",
      "Epoch: 11250 cost= 19.243242722 W= [[-0.47935832]\n",
      " [ 5.93992151]] b= [[-9.37780233]]\n",
      "Epoch: 11300 cost= 19.239520964 W= [[-0.47910335]\n",
      " [ 5.9446758 ]] b= [[-9.41087628]]\n",
      "Epoch: 11350 cost= 19.235817880 W= [[-0.47884902]\n",
      " [ 5.94941814]] b= [[-9.44386716]]\n",
      "Epoch: 11400 cost= 19.232133377 W= [[-0.47859533]\n",
      " [ 5.95414858]] b= [[-9.47677516]]\n",
      "Epoch: 11450 cost= 19.228467363 W= [[-0.47834228]\n",
      " [ 5.95886713]] b= [[-9.5096005]]\n",
      "Epoch: 11500 cost= 19.224819743 W= [[-0.47808987]\n",
      " [ 5.96357382]] b= [[-9.54234338]]\n",
      "Epoch: 11550 cost= 19.221190426 W= [[-0.47783809]\n",
      " [ 5.96826869]] b= [[-9.57500401]]\n",
      "Epoch: 11600 cost= 19.217579319 W= [[-0.47758694]\n",
      " [ 5.97295177]] b= [[-9.6075826]]\n",
      "Epoch: 11650 cost= 19.213986332 W= [[-0.47733642]\n",
      " [ 5.97762309]] b= [[-9.64007935]]\n",
      "Epoch: 11700 cost= 19.210411374 W= [[-0.47708653]\n",
      " [ 5.98228267]] b= [[-9.67249446]]\n",
      "Epoch: 11750 cost= 19.206854354 W= [[-0.47683727]\n",
      " [ 5.98693055]] b= [[-9.70482815]]\n",
      "Epoch: 11800 cost= 19.203315182 W= [[-0.47658863]\n",
      " [ 5.99156675]] b= [[-9.73708062]]\n",
      "Epoch: 11850 cost= 19.199793768 W= [[-0.47634062]\n",
      " [ 5.9961913 ]] b= [[-9.76925207]]\n",
      "Epoch: 11900 cost= 19.196290024 W= [[-0.47609323]\n",
      " [ 6.00080424]] b= [[-9.8013427]]\n",
      "Epoch: 11950 cost= 19.192803860 W= [[-0.47584647]\n",
      " [ 6.00540559]] b= [[-9.83335272]]\n",
      "Epoch: 12000 cost= 19.189335189 W= [[-0.47560032]\n",
      " [ 6.00999538]] b= [[-9.86528233]]\n",
      "Epoch: 12050 cost= 19.185883923 W= [[-0.47535479]\n",
      " [ 6.01457364]] b= [[-9.89713174]]\n",
      "Epoch: 12100 cost= 19.182449975 W= [[-0.47510988]\n",
      " [ 6.0191404 ]] b= [[-9.92890114]]\n",
      "Epoch: 12150 cost= 19.179033256 W= [[-0.47486559]\n",
      " [ 6.02369569]] b= [[-9.96059073]]\n",
      "Epoch: 12200 cost= 19.175633682 W= [[-0.47462191]\n",
      " [ 6.02823954]] b= [[-9.99220072]]\n",
      "Epoch: 12250 cost= 19.172251166 W= [[-0.47437884]\n",
      " [ 6.03277197]] b= [[-10.02373131]]\n",
      "Epoch: 12300 cost= 19.168885623 W= [[-0.47413638]\n",
      " [ 6.03729302]] b= [[-10.05518269]]\n",
      "Epoch: 12350 cost= 19.165536966 W= [[-0.47389453]\n",
      " [ 6.04180271]] b= [[-10.08655506]]\n",
      "Epoch: 12400 cost= 19.162205113 W= [[-0.47365328]\n",
      " [ 6.04630107]] b= [[-10.11784863]]\n",
      "Epoch: 12450 cost= 19.158889977 W= [[-0.47341265]\n",
      " [ 6.05078813]] b= [[-10.14906358]]\n",
      "Epoch: 12500 cost= 19.155591476 W= [[-0.47317261]\n",
      " [ 6.05526392]] b= [[-10.18020013]]\n",
      "Epoch: 12550 cost= 19.152309526 W= [[-0.47293318]\n",
      " [ 6.05972847]] b= [[-10.21125846]]\n",
      "Epoch: 12600 cost= 19.149044044 W= [[-0.47269436]\n",
      " [ 6.0641818 ]] b= [[-10.24223877]]\n",
      "Epoch: 12650 cost= 19.145794947 W= [[-0.47245613]\n",
      " [ 6.06862394]] b= [[-10.27314125]]\n",
      "Epoch: 12700 cost= 19.142562153 W= [[-0.4722185 ]\n",
      " [ 6.07305493]] b= [[-10.30396611]]\n",
      "Epoch: 12750 cost= 19.139345580 W= [[-0.47198147]\n",
      " [ 6.07747478]] b= [[-10.33471354]]\n",
      "Epoch: 12800 cost= 19.136145147 W= [[-0.47174503]\n",
      " [ 6.08188354]] b= [[-10.36538373]]\n",
      "Epoch: 12850 cost= 19.132960772 W= [[-0.47150919]\n",
      " [ 6.08628121]] b= [[-10.39597688]]\n",
      "Epoch: 12900 cost= 19.129792376 W= [[-0.47127393]\n",
      " [ 6.09066785]] b= [[-10.42649317]]\n",
      "Epoch: 12950 cost= 19.126639879 W= [[-0.47103927]\n",
      " [ 6.09504346]] b= [[-10.45693281]]\n",
      "Epoch: 13000 cost= 19.123503199 W= [[-0.4708052 ]\n",
      " [ 6.09940808]] b= [[-10.48729599]]\n",
      "Epoch: 13050 cost= 19.120382258 W= [[-0.47057172]\n",
      " [ 6.10376173]] b= [[-10.51758289]]\n",
      "Epoch: 13100 cost= 19.117276978 W= [[-0.47033883]\n",
      " [ 6.10810445]] b= [[-10.54779371]]\n",
      "Epoch: 13150 cost= 19.114187278 W= [[-0.47010651]\n",
      " [ 6.11243626]] b= [[-10.57792864]]\n",
      "Epoch: 13200 cost= 19.111113082 W= [[-0.46987479]\n",
      " [ 6.11675719]] b= [[-10.60798787]]\n",
      "Epoch: 13250 cost= 19.108054311 W= [[-0.46964364]\n",
      " [ 6.12106727]] b= [[-10.6379716]]\n",
      "Epoch: 13300 cost= 19.105010889 W= [[-0.46941308]\n",
      " [ 6.12536652]] b= [[-10.66788]]\n",
      "Epoch: 13350 cost= 19.101982737 W= [[-0.46918309]\n",
      " [ 6.12965497]] b= [[-10.69771327]]\n",
      "Epoch: 13400 cost= 19.098969780 W= [[-0.46895368]\n",
      " [ 6.13393264]] b= [[-10.72747161]]\n",
      "Epoch: 13450 cost= 19.095971940 W= [[-0.46872485]\n",
      " [ 6.13819957]] b= [[-10.75715519]]\n",
      "Epoch: 13500 cost= 19.092989144 W= [[-0.4684966 ]\n",
      " [ 6.14245578]] b= [[-10.7867642]]\n",
      "Epoch: 13550 cost= 19.090021313 W= [[-0.46826891]\n",
      " [ 6.1467013 ]] b= [[-10.81629883]]\n",
      "Epoch: 13600 cost= 19.087068375 W= [[-0.4680418 ]\n",
      " [ 6.15093616]] b= [[-10.84575928]]\n",
      "Epoch: 13650 cost= 19.084130253 W= [[-0.46781526]\n",
      " [ 6.15516038]] b= [[-10.87514572]]\n",
      "Epoch: 13700 cost= 19.081206875 W= [[-0.46758929]\n",
      " [ 6.15937398]] b= [[-10.90445834]]\n",
      "Epoch: 13750 cost= 19.078298164 W= [[-0.46736389]\n",
      " [ 6.163577  ]] b= [[-10.93369733]]\n",
      "Epoch: 13800 cost= 19.075404049 W= [[-0.46713905]\n",
      " [ 6.16776947]] b= [[-10.96286286]]\n",
      "Epoch: 13850 cost= 19.072524456 W= [[-0.46691477]\n",
      " [ 6.1719514 ]] b= [[-10.99195514]]\n",
      "Epoch: 13900 cost= 19.069659312 W= [[-0.46669107]\n",
      " [ 6.17612283]] b= [[-11.02097433]]\n",
      "Epoch: 13950 cost= 19.066808544 W= [[-0.46646792]\n",
      " [ 6.18028377]] b= [[-11.04992063]]\n",
      "Epoch: 14000 cost= 19.063972080 W= [[-0.46624533]\n",
      " [ 6.18443427]] b= [[-11.07879422]]\n",
      "Epoch: 14050 cost= 19.061149849 W= [[-0.4660233 ]\n",
      " [ 6.18857434]] b= [[-11.10759527]]\n",
      "Epoch: 14100 cost= 19.058341779 W= [[-0.46580183]\n",
      " [ 6.19270401]] b= [[-11.13632397]]\n",
      "Epoch: 14150 cost= 19.055547799 W= [[-0.46558092]\n",
      " [ 6.19682331]] b= [[-11.16498051]]\n",
      "Epoch: 14200 cost= 19.052767839 W= [[-0.46536056]\n",
      " [ 6.20093225]] b= [[-11.19356507]]\n",
      "Epoch: 14250 cost= 19.050001827 W= [[-0.46514075]\n",
      " [ 6.20503088]] b= [[-11.22207782]]\n",
      "Epoch: 14300 cost= 19.047249695 W= [[-0.4649215 ]\n",
      " [ 6.20911921]] b= [[-11.25051894]]\n",
      "Epoch: 14350 cost= 19.044511371 W= [[-0.4647028 ]\n",
      " [ 6.21319727]] b= [[-11.27888862]]\n",
      "Epoch: 14400 cost= 19.041786788 W= [[-0.46448464]\n",
      " [ 6.21726509]] b= [[-11.30718704]]\n",
      "Epoch: 14450 cost= 19.039075877 W= [[-0.46426704]\n",
      " [ 6.22132269]] b= [[-11.33541436]]\n",
      "Epoch: 14500 cost= 19.036378567 W= [[-0.46404998]\n",
      " [ 6.22537009]] b= [[-11.36357079]]\n",
      "Epoch: 14550 cost= 19.033694792 W= [[-0.46383347]\n",
      " [ 6.22940733]] b= [[-11.39165648]]\n",
      "Epoch: 14600 cost= 19.031024484 W= [[-0.4636175 ]\n",
      " [ 6.23343443]] b= [[-11.41967162]]\n",
      "Epoch: 14650 cost= 19.028367574 W= [[-0.46340207]\n",
      " [ 6.23745141]] b= [[-11.44761639]]\n",
      "Epoch: 14700 cost= 19.025723996 W= [[-0.46318719]\n",
      " [ 6.2414583 ]] b= [[-11.47549096]]\n",
      "Epoch: 14750 cost= 19.023093682 W= [[-0.46297284]\n",
      " [ 6.24545513]] b= [[-11.50329551]]\n",
      "Epoch: 14800 cost= 19.020476567 W= [[-0.46275903]\n",
      " [ 6.24944191]] b= [[-11.53103021]]\n",
      "Epoch: 14850 cost= 19.017872583 W= [[-0.46254576]\n",
      " [ 6.25341868]] b= [[-11.55869524]]\n",
      "Epoch: 14900 cost= 19.015281666 W= [[-0.46233303]\n",
      " [ 6.25738546]] b= [[-11.58629078]]\n",
      "Epoch: 14950 cost= 19.012703749 W= [[-0.46212083]\n",
      " [ 6.26134228]] b= [[-11.613817]]\n",
      "Epoch: 15000 cost= 19.010138767 W= [[-0.46190916]\n",
      " [ 6.26528915]] b= [[-11.64127408]]\n",
      "Epoch: 15050 cost= 19.007586656 W= [[-0.46169802]\n",
      " [ 6.26922612]] b= [[-11.66866218]]\n",
      "Epoch: 15100 cost= 19.005047350 W= [[-0.46148742]\n",
      " [ 6.27315319]] b= [[-11.69598148]]\n",
      "Epoch: 15150 cost= 19.002520786 W= [[-0.46127734]\n",
      " [ 6.2770704 ]] b= [[-11.72323215]]\n",
      "Epoch: 15200 cost= 19.000006899 W= [[-0.46106779]\n",
      " [ 6.28097776]] b= [[-11.75041437]]\n",
      "Epoch: 15250 cost= 18.997505627 W= [[-0.46085877]\n",
      " [ 6.28487531]] b= [[-11.77752831]]\n",
      "Epoch: 15300 cost= 18.995016905 W= [[-0.46065028]\n",
      " [ 6.28876308]] b= [[-11.80457414]]\n",
      "Epoch: 15350 cost= 18.992540670 W= [[-0.4604423 ]\n",
      " [ 6.29264107]] b= [[-11.83155203]]\n",
      "Epoch: 15400 cost= 18.990076861 W= [[-0.46023485]\n",
      " [ 6.29650932]] b= [[-11.85846215]]\n",
      "Epoch: 15450 cost= 18.987625414 W= [[-0.46002792]\n",
      " [ 6.30036786]] b= [[-11.88530467]]\n",
      "Epoch: 15500 cost= 18.985186268 W= [[-0.45982151]\n",
      " [ 6.3042167 ]] b= [[-11.91207977]]\n",
      "Epoch: 15550 cost= 18.982759361 W= [[-0.45961562]\n",
      " [ 6.30805588]] b= [[-11.9387876]]\n",
      "Epoch: 15600 cost= 18.980344631 W= [[-0.45941025]\n",
      " [ 6.31188541]] b= [[-11.96542834]]\n",
      "Epoch: 15650 cost= 18.977942018 W= [[-0.45920539]\n",
      " [ 6.31570532]] b= [[-11.99200217]]\n",
      "Epoch: 15700 cost= 18.975551461 W= [[-0.45900104]\n",
      " [ 6.31951564]] b= [[-12.01850924]]\n",
      "Epoch: 15750 cost= 18.973172898 W= [[-0.45879721]\n",
      " [ 6.32331638]] b= [[-12.04494972]]\n",
      "Epoch: 15800 cost= 18.970806270 W= [[-0.4585939 ]\n",
      " [ 6.32710758]] b= [[-12.07132378]]\n",
      "Epoch: 15850 cost= 18.968451518 W= [[-0.45839109]\n",
      " [ 6.33088925]] b= [[-12.0976316]]\n",
      "Epoch: 15900 cost= 18.966108581 W= [[-0.45818879]\n",
      " [ 6.33466143]] b= [[-12.12387332]]\n",
      "Epoch: 15950 cost= 18.963777400 W= [[-0.457987  ]\n",
      " [ 6.33842413]] b= [[-12.15004913]]\n",
      "Epoch: 16000 cost= 18.961457916 W= [[-0.45778572]\n",
      " [ 6.34217737]] b= [[-12.17615918]]\n",
      "Epoch: 16050 cost= 18.959150071 W= [[-0.45758494]\n",
      " [ 6.34592119]] b= [[-12.20220365]]\n",
      "Epoch: 16100 cost= 18.956853806 W= [[-0.45738467]\n",
      " [ 6.3496556 ]] b= [[-12.22818269]]\n",
      "Epoch: 16150 cost= 18.954569062 W= [[-0.4571849 ]\n",
      " [ 6.35338064]] b= [[-12.25409647]]\n",
      "Epoch: 16200 cost= 18.952295783 W= [[-0.45698563]\n",
      " [ 6.35709631]] b= [[-12.27994516]]\n",
      "Epoch: 16250 cost= 18.950033911 W= [[-0.45678686]\n",
      " [ 6.36080265]] b= [[-12.30572891]]\n",
      "Epoch: 16300 cost= 18.947783388 W= [[-0.45658859]\n",
      " [ 6.36449968]] b= [[-12.3314479]]\n",
      "Epoch: 16350 cost= 18.945544157 W= [[-0.45639082]\n",
      " [ 6.36818743]] b= [[-12.35710227]]\n",
      "Epoch: 16400 cost= 18.943316163 W= [[-0.45619355]\n",
      " [ 6.37186591]] b= [[-12.38269221]]\n",
      "Epoch: 16450 cost= 18.941099347 W= [[-0.45599677]\n",
      " [ 6.37553515]] b= [[-12.40821786]]\n",
      "Epoch: 16500 cost= 18.938893655 W= [[-0.45580049]\n",
      " [ 6.37919517]] b= [[-12.43367939]]\n",
      "Epoch: 16550 cost= 18.936699031 W= [[-0.4556047]\n",
      " [ 6.382846 ]] b= [[-12.45907696]]\n",
      "Epoch: 16600 cost= 18.934515418 W= [[-0.4554094 ]\n",
      " [ 6.38648766]] b= [[-12.48441074]]\n",
      "Epoch: 16650 cost= 18.932342763 W= [[-0.45521459]\n",
      " [ 6.39012017]] b= [[-12.50968087]]\n",
      "Epoch: 16700 cost= 18.930181009 W= [[-0.45502027]\n",
      " [ 6.39374355]] b= [[-12.53488753]]\n",
      "Epoch: 16750 cost= 18.928030102 W= [[-0.45482644]\n",
      " [ 6.39735784]] b= [[-12.56003087]]\n",
      "Epoch: 16800 cost= 18.925889987 W= [[-0.4546331 ]\n",
      " [ 6.40096304]] b= [[-12.58511104]]\n",
      "Epoch: 16850 cost= 18.923760611 W= [[-0.45444024]\n",
      " [ 6.40455919]] b= [[-12.61012822]]\n",
      "Epoch: 16900 cost= 18.921641920 W= [[-0.45424787]\n",
      " [ 6.4081463 ]] b= [[-12.63508255]]\n",
      "Epoch: 16950 cost= 18.919533860 W= [[-0.45405598]\n",
      " [ 6.41172441]] b= [[-12.65997419]]\n",
      "Epoch: 17000 cost= 18.917436377 W= [[-0.45386457]\n",
      " [ 6.41529352]] b= [[-12.68480331]]\n",
      "Epoch: 17050 cost= 18.915349419 W= [[-0.45367364]\n",
      " [ 6.41885367]] b= [[-12.70957006]]\n",
      "Epoch: 17100 cost= 18.913272932 W= [[-0.45348319]\n",
      " [ 6.42240488]] b= [[-12.73427459]]\n",
      "Epoch: 17150 cost= 18.911206865 W= [[-0.45329322]\n",
      " [ 6.42594716]] b= [[-12.75891707]]\n",
      "Epoch: 17200 cost= 18.909151165 W= [[-0.45310373]\n",
      " [ 6.42948055]] b= [[-12.78349764]]\n",
      "Epoch: 17250 cost= 18.907105779 W= [[-0.45291471]\n",
      " [ 6.43300506]] b= [[-12.80801647]]\n",
      "Epoch: 17300 cost= 18.905070657 W= [[-0.45272617]\n",
      " [ 6.43652072]] b= [[-12.8324737]]\n",
      "Epoch: 17350 cost= 18.903045746 W= [[-0.45253811]\n",
      " [ 6.44002755]] b= [[-12.8568695]]\n",
      "Epoch: 17400 cost= 18.901030996 W= [[-0.45235051]\n",
      " [ 6.44352557]] b= [[-12.88120401]]\n",
      "Epoch: 17450 cost= 18.899026355 W= [[-0.45216339]\n",
      " [ 6.4470148 ]] b= [[-12.9054774]]\n",
      "Epoch: 17500 cost= 18.897031773 W= [[-0.45197673]\n",
      " [ 6.45049526]] b= [[-12.92968981]]\n",
      "Epoch: 17550 cost= 18.895047199 W= [[-0.45179055]\n",
      " [ 6.45396698]] b= [[-12.9538414]]\n",
      "Epoch: 17600 cost= 18.893072583 W= [[-0.45160483]\n",
      " [ 6.45742999]] b= [[-12.97793233]]\n",
      "Epoch: 17650 cost= 18.891107875 W= [[-0.45141958]\n",
      " [ 6.46088429]] b= [[-13.00196273]]\n",
      "Epoch: 17700 cost= 18.889153026 W= [[-0.45123479]\n",
      " [ 6.46432991]] b= [[-13.02593277]]\n",
      "Epoch: 17750 cost= 18.887207985 W= [[-0.45105047]\n",
      " [ 6.46776688]] b= [[-13.0498426]]\n",
      "Epoch: 17800 cost= 18.885272704 W= [[-0.45086661]\n",
      " [ 6.47119522]] b= [[-13.07369236]]\n",
      "Epoch: 17850 cost= 18.883347134 W= [[-0.45068322]\n",
      " [ 6.47461494]] b= [[-13.09748222]]\n",
      "Epoch: 17900 cost= 18.881431225 W= [[-0.45050028]\n",
      " [ 6.47802608]] b= [[-13.12121231]]\n",
      "Epoch: 17950 cost= 18.879524930 W= [[-0.4503178 ]\n",
      " [ 6.48142864]] b= [[-13.1448828]]\n",
      "Epoch: 18000 cost= 18.877628200 W= [[-0.45013579]\n",
      " [ 6.48482266]] b= [[-13.16849382]]\n",
      "Epoch: 18050 cost= 18.875740988 W= [[-0.44995422]\n",
      " [ 6.48820815]] b= [[-13.19204553]]\n",
      "Epoch: 18100 cost= 18.873863245 W= [[-0.44977312]\n",
      " [ 6.49158514]] b= [[-13.21553809]]\n",
      "Epoch: 18150 cost= 18.871994924 W= [[-0.44959247]\n",
      " [ 6.49495364]] b= [[-13.23897162]]\n",
      "Epoch: 18200 cost= 18.870135977 W= [[-0.44941227]\n",
      " [ 6.49831369]] b= [[-13.26234629]]\n",
      "Epoch: 18250 cost= 18.868286359 W= [[-0.44923253]\n",
      " [ 6.50166529]] b= [[-13.28566225]]\n",
      "Epoch: 18300 cost= 18.866446021 W= [[-0.44905324]\n",
      " [ 6.50500847]] b= [[-13.30891963]]\n",
      "Epoch: 18350 cost= 18.864614917 W= [[-0.4488744 ]\n",
      " [ 6.50834326]] b= [[-13.3321186]]\n",
      "Epoch: 18400 cost= 18.862793001 W= [[-0.44869601]\n",
      " [ 6.51166967]] b= [[-13.35525928]]\n",
      "Epoch: 18450 cost= 18.860980227 W= [[-0.44851806]\n",
      " [ 6.51498772]] b= [[-13.37834184]]\n",
      "Epoch: 18500 cost= 18.859176550 W= [[-0.44834057]\n",
      " [ 6.51829744]] b= [[-13.40136641]]\n",
      "Epoch: 18550 cost= 18.857381922 W= [[-0.44816351]\n",
      " [ 6.52159884]] b= [[-13.42433315]]\n",
      "Epoch: 18600 cost= 18.855596299 W= [[-0.44798691]\n",
      " [ 6.52489195]] b= [[-13.44724219]]\n",
      "Epoch: 18650 cost= 18.853819636 W= [[-0.44781075]\n",
      " [ 6.52817679]] b= [[-13.47009369]]\n",
      "Epoch: 18700 cost= 18.852051888 W= [[-0.44763502]\n",
      " [ 6.53145337]] b= [[-13.49288778]]\n",
      "Epoch: 18750 cost= 18.850293010 W= [[-0.44745975]\n",
      " [ 6.53472173]] b= [[-13.51562461]]\n",
      "Epoch: 18800 cost= 18.848542957 W= [[-0.44728491]\n",
      " [ 6.53798187]] b= [[-13.53830433]]\n",
      "Epoch: 18850 cost= 18.846801686 W= [[-0.44711051]\n",
      " [ 6.54123383]] b= [[-13.56092707]]\n",
      "Epoch: 18900 cost= 18.845069152 W= [[-0.44693655]\n",
      " [ 6.54447761]] b= [[-13.58349299]]\n",
      "Epoch: 18950 cost= 18.843345311 W= [[-0.44676302]\n",
      " [ 6.54771325]] b= [[-13.60600222]]\n",
      "Epoch: 19000 cost= 18.841630120 W= [[-0.44658993]\n",
      " [ 6.55094076]] b= [[-13.62845491]]\n",
      "Epoch: 19050 cost= 18.839923535 W= [[-0.44641728]\n",
      " [ 6.55416017]] b= [[-13.6508512]]\n",
      "Epoch: 19100 cost= 18.838225514 W= [[-0.44624506]\n",
      " [ 6.55737148]] b= [[-13.67319123]]\n",
      "Epoch: 19150 cost= 18.836536012 W= [[-0.44607327]\n",
      " [ 6.56057473]] b= [[-13.69547514]]\n",
      "Epoch: 19200 cost= 18.834854988 W= [[-0.44590192]\n",
      " [ 6.56376993]] b= [[-13.71770307]]\n",
      "Epoch: 19250 cost= 18.833182399 W= [[-0.44573099]\n",
      " [ 6.56695711]] b= [[-13.73987516]]\n",
      "Epoch: 19300 cost= 18.831518202 W= [[-0.4455605 ]\n",
      " [ 6.57013628]] b= [[-13.76199156]]\n",
      "Epoch: 19350 cost= 18.829862356 W= [[-0.44539043]\n",
      " [ 6.57330746]] b= [[-13.7840524]]\n",
      "Epoch: 19400 cost= 18.828214819 W= [[-0.44522079]\n",
      " [ 6.57647068]] b= [[-13.80605783]]\n",
      "Epoch: 19450 cost= 18.826575548 W= [[-0.44505158]\n",
      " [ 6.57962595]] b= [[-13.82800798]]\n",
      "Epoch: 19500 cost= 18.824944502 W= [[-0.44488279]\n",
      " [ 6.5827733 ]] b= [[-13.84990299]]\n",
      "Epoch: 19550 cost= 18.823321641 W= [[-0.44471442]\n",
      " [ 6.58591273]] b= [[-13.87174299]]\n",
      "Epoch: 19600 cost= 18.821706923 W= [[-0.44454648]\n",
      " [ 6.58904429]] b= [[-13.89352814]]\n",
      "Epoch: 19650 cost= 18.820100307 W= [[-0.44437896]\n",
      " [ 6.59216797]] b= [[-13.91525856]]\n",
      "Epoch: 19700 cost= 18.818501752 W= [[-0.44421186]\n",
      " [ 6.59528381]] b= [[-13.9369344]]\n",
      "Epoch: 19750 cost= 18.816911219 W= [[-0.44404518]\n",
      " [ 6.59839183]] b= [[-13.95855578]]\n",
      "Epoch: 19800 cost= 18.815328666 W= [[-0.44387892]\n",
      " [ 6.60149203]] b= [[-13.98012285]]\n",
      "Epoch: 19850 cost= 18.813754054 W= [[-0.44371307]\n",
      " [ 6.60458445]] b= [[-14.00163575]]\n",
      "Epoch: 19900 cost= 18.812187343 W= [[-0.44354765]\n",
      " [ 6.6076691 ]] b= [[-14.0230946]]\n",
      "Epoch: 19950 cost= 18.810628494 W= [[-0.44338264]\n",
      " [ 6.610746  ]] b= [[-14.04449955]]\n",
      "Epoch: 20000 cost= 18.809077466 W= [[-0.44321804]\n",
      " [ 6.61381517]] b= [[-14.06585073]]\n",
      "Epoch: 20050 cost= 18.807534221 W= [[-0.44305386]\n",
      " [ 6.61687663]] b= [[-14.08714827]]\n",
      "Epoch: 20100 cost= 18.805998719 W= [[-0.44289009]\n",
      " [ 6.6199304 ]] b= [[-14.10839232]]\n",
      "Epoch: 20150 cost= 18.804470922 W= [[-0.44272673]\n",
      " [ 6.6229765 ]] b= [[-14.129583]]\n",
      "Epoch: 20200 cost= 18.802950791 W= [[-0.44256378]\n",
      " [ 6.62601495]] b= [[-14.15072045]]\n",
      "Epoch: 20250 cost= 18.801438288 W= [[-0.44240124]\n",
      " [ 6.62904577]] b= [[-14.1718048]]\n",
      "Epoch: 20300 cost= 18.799933374 W= [[-0.44223911]\n",
      " [ 6.63206897]] b= [[-14.19283619]]\n",
      "Epoch: 20350 cost= 18.798436011 W= [[-0.44207738]\n",
      " [ 6.63508458]] b= [[-14.21381475]]\n",
      "Epoch: 20400 cost= 18.796946162 W= [[-0.44191606]\n",
      " [ 6.63809261]] b= [[-14.23474061]]\n",
      "Epoch: 20450 cost= 18.795463788 W= [[-0.44175515]\n",
      " [ 6.64109309]] b= [[-14.2556139]]\n",
      "Epoch: 20500 cost= 18.793988852 W= [[-0.44159464]\n",
      " [ 6.64408603]] b= [[-14.27643476]]\n",
      "Epoch: 20550 cost= 18.792521317 W= [[-0.44143454]\n",
      " [ 6.64707145]] b= [[-14.29720332]]\n",
      "Epoch: 20600 cost= 18.791061146 W= [[-0.44127483]\n",
      " [ 6.65004937]] b= [[-14.3179197]]\n",
      "Epoch: 20650 cost= 18.789608301 W= [[-0.44111553]\n",
      " [ 6.65301981]] b= [[-14.33858405]]\n",
      "Epoch: 20700 cost= 18.788162747 W= [[-0.44095663]\n",
      " [ 6.65598279]] b= [[-14.35919649]]\n",
      "Epoch: 20750 cost= 18.786724445 W= [[-0.44079813]\n",
      " [ 6.65893833]] b= [[-14.37975715]]\n",
      "Epoch: 20800 cost= 18.785293361 W= [[-0.44064002]\n",
      " [ 6.66188644]] b= [[-14.40026616]]\n",
      "Epoch: 20850 cost= 18.783869457 W= [[-0.44048232]\n",
      " [ 6.66482715]] b= [[-14.42072365]]\n",
      "Epoch: 20900 cost= 18.782452699 W= [[-0.440325  ]\n",
      " [ 6.66776047]] b= [[-14.44112975]]\n",
      "Epoch: 20950 cost= 18.781043049 W= [[-0.44016809]\n",
      " [ 6.67068642]] b= [[-14.46148459]]\n",
      "Epoch: 21000 cost= 18.779640472 W= [[-0.44001157]\n",
      " [ 6.67360502]] b= [[-14.4817883]]\n",
      "Epoch: 21050 cost= 18.778244933 W= [[-0.43985544]\n",
      " [ 6.67651629]] b= [[-14.50204101]]\n",
      "Epoch: 21100 cost= 18.776856396 W= [[-0.4396997 ]\n",
      " [ 6.67942024]] b= [[-14.52224284]]\n",
      "Epoch: 21150 cost= 18.775474827 W= [[-0.43954436]\n",
      " [ 6.6823169 ]] b= [[-14.54239393]]\n",
      "Epoch: 21200 cost= 18.774100190 W= [[-0.4393894 ]\n",
      " [ 6.68520629]] b= [[-14.56249439]]\n",
      "Epoch: 21250 cost= 18.772732450 W= [[-0.43923484]\n",
      " [ 6.68808842]] b= [[-14.58254437]]\n",
      "Epoch: 21300 cost= 18.771371574 W= [[-0.43908066]\n",
      " [ 6.6909633 ]] b= [[-14.60254397]]\n",
      "Epoch: 21350 cost= 18.770017526 W= [[-0.43892687]\n",
      " [ 6.69383097]] b= [[-14.62249334]]\n",
      "Epoch: 21400 cost= 18.768670272 W= [[-0.43877346]\n",
      " [ 6.69669143]] b= [[-14.6423926]]\n",
      "Epoch: 21450 cost= 18.767329778 W= [[-0.43862045]\n",
      " [ 6.6995447 ]] b= [[-14.66224187]]\n",
      "Epoch: 21500 cost= 18.765996010 W= [[-0.43846781]\n",
      " [ 6.70239081]] b= [[-14.68204127]]\n",
      "Epoch: 21550 cost= 18.764668935 W= [[-0.43831556]\n",
      " [ 6.70522977]] b= [[-14.70179094]]\n",
      "Epoch: 21600 cost= 18.763348519 W= [[-0.43816369]\n",
      " [ 6.7080616 ]] b= [[-14.721491]]\n",
      "Epoch: 21650 cost= 18.762034728 W= [[-0.43801221]\n",
      " [ 6.71088631]] b= [[-14.74114158]]\n",
      "Epoch: 21700 cost= 18.760727529 W= [[-0.4378611 ]\n",
      " [ 6.71370393]] b= [[-14.76074279]]\n",
      "Epoch: 21750 cost= 18.759426890 W= [[-0.43771037]\n",
      " [ 6.71651447]] b= [[-14.78029476]]\n",
      "Epoch: 21800 cost= 18.758132777 W= [[-0.43756003]\n",
      " [ 6.71931795]] b= [[-14.79979761]]\n",
      "Epoch: 21850 cost= 18.756845157 W= [[-0.43741006]\n",
      " [ 6.72211439]] b= [[-14.81925148]]\n",
      "Epoch: 21900 cost= 18.755563998 W= [[-0.43726046]\n",
      " [ 6.7249038 ]] b= [[-14.83865648]]\n",
      "Epoch: 21950 cost= 18.754289268 W= [[-0.43711124]\n",
      " [ 6.72768621]] b= [[-14.85801273]]\n",
      "Epoch: 22000 cost= 18.753020934 W= [[-0.4369624 ]\n",
      " [ 6.73046163]] b= [[-14.87732036]]\n",
      "Epoch: 22050 cost= 18.751758963 W= [[-0.43681393]\n",
      " [ 6.73323007]] b= [[-14.89657949]]\n",
      "Epoch: 22100 cost= 18.750503326 W= [[-0.43666584]\n",
      " [ 6.73599156]] b= [[-14.91579023]]\n",
      "Epoch: 22150 cost= 18.749253988 W= [[-0.43651811]\n",
      " [ 6.73874612]] b= [[-14.93495273]]\n",
      "Epoch: 22200 cost= 18.748010920 W= [[-0.43637076]\n",
      " [ 6.74149375]] b= [[-14.95406708]]\n",
      "Epoch: 22250 cost= 18.746774088 W= [[-0.43622378]\n",
      " [ 6.74423448]] b= [[-14.97313342]]\n",
      "Epoch: 22300 cost= 18.745543463 W= [[-0.43607716]\n",
      " [ 6.74696833]] b= [[-14.99215187]]\n",
      "Epoch: 22350 cost= 18.744319013 W= [[-0.43593092]\n",
      " [ 6.74969531]] b= [[-15.01112254]]\n",
      "Epoch: 22400 cost= 18.743100706 W= [[-0.43578504]\n",
      " [ 6.75241544]] b= [[-15.03004555]]\n",
      "Epoch: 22450 cost= 18.741888513 W= [[-0.43563953]\n",
      " [ 6.75512874]] b= [[-15.04892103]]\n",
      "Epoch: 22500 cost= 18.740682402 W= [[-0.43549438]\n",
      " [ 6.75783522]] b= [[-15.0677491]]\n",
      "Epoch: 22550 cost= 18.739482343 W= [[-0.4353496]\n",
      " [ 6.7605349]] b= [[-15.08652987]]\n",
      "Epoch: 22600 cost= 18.738288306 W= [[-0.43520518]\n",
      " [ 6.7632278 ]] b= [[-15.10526346]]\n",
      "Epoch: 22650 cost= 18.737100260 W= [[-0.43506113]\n",
      " [ 6.76591394]] b= [[-15.12394999]]\n",
      "Epoch: 22700 cost= 18.735918175 W= [[-0.43491743]\n",
      " [ 6.76859333]] b= [[-15.14258959]]\n",
      "Epoch: 22750 cost= 18.734742022 W= [[-0.4347741 ]\n",
      " [ 6.77126598]] b= [[-15.16118235]]\n",
      "Epoch: 22800 cost= 18.733571770 W= [[-0.43463113]\n",
      " [ 6.77393193]] b= [[-15.17972842]]\n",
      "Epoch: 22850 cost= 18.732407390 W= [[-0.43448852]\n",
      " [ 6.77659118]] b= [[-15.1982279]]\n",
      "Epoch: 22900 cost= 18.731248853 W= [[-0.43434626]\n",
      " [ 6.77924374]] b= [[-15.2166809]]\n",
      "Epoch: 22950 cost= 18.730096128 W= [[-0.43420436]\n",
      " [ 6.78188965]] b= [[-15.23508755]]\n",
      "Epoch: 23000 cost= 18.728949188 W= [[-0.43406282]\n",
      " [ 6.7845289 ]] b= [[-15.25344797]]\n",
      "Epoch: 23050 cost= 18.727808003 W= [[-0.43392164]\n",
      " [ 6.78716153]] b= [[-15.27176226]]\n",
      "Epoch: 23100 cost= 18.726672544 W= [[-0.43378081]\n",
      " [ 6.78978755]] b= [[-15.29003055]]\n",
      "Epoch: 23150 cost= 18.725542782 W= [[-0.43364033]\n",
      " [ 6.79240696]] b= [[-15.30825294]]\n",
      "Epoch: 23200 cost= 18.724418690 W= [[-0.43350021]\n",
      " [ 6.7950198 ]] b= [[-15.32642957]]\n",
      "Epoch: 23250 cost= 18.723300237 W= [[-0.43336044]\n",
      " [ 6.79762608]] b= [[-15.34456053]]\n",
      "Epoch: 23300 cost= 18.722187397 W= [[-0.43322101]\n",
      " [ 6.8002258 ]] b= [[-15.36264595]]\n",
      "Epoch: 23350 cost= 18.721080140 W= [[-0.43308194]\n",
      " [ 6.802819  ]] b= [[-15.38068593]]\n",
      "Epoch: 23400 cost= 18.719978440 W= [[-0.43294322]\n",
      " [ 6.80540568]] b= [[-15.3986806]]\n",
      "Epoch: 23450 cost= 18.718882267 W= [[-0.43280485]\n",
      " [ 6.80798587]] b= [[-15.41663007]]\n",
      "Epoch: 23500 cost= 18.717791595 W= [[-0.43266682]\n",
      " [ 6.81055957]] b= [[-15.43453445]]\n",
      "Epoch: 23550 cost= 18.716706395 W= [[-0.43252915]\n",
      " [ 6.81312681]] b= [[-15.45239385]]\n",
      "Epoch: 23600 cost= 18.715626641 W= [[-0.43239181]\n",
      " [ 6.8156876 ]] b= [[-15.47020839]]\n",
      "Epoch: 23650 cost= 18.714552304 W= [[-0.43225482]\n",
      " [ 6.81824196]] b= [[-15.48797818]]\n",
      "Epoch: 23700 cost= 18.713483359 W= [[-0.43211818]\n",
      " [ 6.8207899 ]] b= [[-15.50570333]]\n",
      "Epoch: 23750 cost= 18.712419776 W= [[-0.43198188]\n",
      " [ 6.82333144]] b= [[-15.52338395]]\n",
      "Epoch: 23800 cost= 18.711361531 W= [[-0.43184592]\n",
      " [ 6.82586659]] b= [[-15.54102016]]\n",
      "Epoch: 23850 cost= 18.710308596 W= [[-0.43171031]\n",
      " [ 6.82839538]] b= [[-15.55861207]]\n",
      "Epoch: 23900 cost= 18.709260943 W= [[-0.43157503]\n",
      " [ 6.83091781]] b= [[-15.57615979]]\n",
      "Epoch: 23950 cost= 18.708218548 W= [[-0.43144009]\n",
      " [ 6.83343391]] b= [[-15.59366343]]\n",
      "Epoch: 24000 cost= 18.707181383 W= [[-0.4313055 ]\n",
      " [ 6.83594369]] b= [[-15.6111231]]\n",
      "Epoch: 24050 cost= 18.706149422 W= [[-0.43117124]\n",
      " [ 6.83844716]] b= [[-15.62853891]]\n",
      "Epoch: 24100 cost= 18.705122640 W= [[-0.43103732]\n",
      " [ 6.84094435]] b= [[-15.64591097]]\n",
      "Epoch: 24150 cost= 18.704101009 W= [[-0.43090373]\n",
      " [ 6.84343526]] b= [[-15.66323939]]\n",
      "Epoch: 24200 cost= 18.703084505 W= [[-0.43077048]\n",
      " [ 6.84591991]] b= [[-15.68052428]]\n",
      "Epoch: 24250 cost= 18.702073101 W= [[-0.43063757]\n",
      " [ 6.84839833]] b= [[-15.69776576]]\n",
      "Epoch: 24300 cost= 18.701066772 W= [[-0.43050499]\n",
      " [ 6.85087051]] b= [[-15.71496392]]\n",
      "Epoch: 24350 cost= 18.700065493 W= [[-0.43037274]\n",
      " [ 6.85333649]] b= [[-15.73211888]]\n",
      "Epoch: 24400 cost= 18.699069238 W= [[-0.43024082]\n",
      " [ 6.85579627]] b= [[-15.74923075]]\n",
      "Epoch: 24450 cost= 18.698077981 W= [[-0.43010924]\n",
      " [ 6.85824988]] b= [[-15.76629963]]\n",
      "Epoch: 24500 cost= 18.697091699 W= [[-0.42997798]\n",
      " [ 6.86069732]] b= [[-15.78332564]]\n",
      "Epoch: 24550 cost= 18.696110365 W= [[-0.42984706]\n",
      " [ 6.86313861]] b= [[-15.80030887]]\n",
      "Epoch: 24600 cost= 18.695133955 W= [[-0.42971646]\n",
      " [ 6.86557377]] b= [[-15.81724945]]\n",
      "Epoch: 24650 cost= 18.694162445 W= [[-0.4295862 ]\n",
      " [ 6.86800281]] b= [[-15.83414747]]\n",
      "Epoch: 24700 cost= 18.693195810 W= [[-0.42945626]\n",
      " [ 6.87042575]] b= [[-15.85100304]]\n",
      "Epoch: 24750 cost= 18.692234024 W= [[-0.42932664]\n",
      " [ 6.87284261]] b= [[-15.86781627]]\n",
      "Epoch: 24800 cost= 18.691277065 W= [[-0.42919736]\n",
      " [ 6.87525339]] b= [[-15.88458726]]\n",
      "Epoch: 24850 cost= 18.690324908 W= [[-0.42906839]\n",
      " [ 6.87765812]] b= [[-15.90131613]]\n",
      "Epoch: 24900 cost= 18.689377528 W= [[-0.42893975]\n",
      " [ 6.8800568 ]] b= [[-15.91800297]]\n",
      "Epoch: 24950 cost= 18.688434901 W= [[-0.42881144]\n",
      " [ 6.88244946]] b= [[-15.9346479]]\n",
      "Epoch: 25000 cost= 18.687497005 W= [[-0.42868344]\n",
      " [ 6.88483611]] b= [[-15.95125101]]\n",
      "Epoch: 25050 cost= 18.686563815 W= [[-0.42855577]\n",
      " [ 6.88721677]] b= [[-15.96781242]]\n",
      "Epoch: 25100 cost= 18.685635307 W= [[-0.42842842]\n",
      " [ 6.88959144]] b= [[-15.98433222]]\n",
      "Epoch: 25150 cost= 18.684711458 W= [[-0.42830139]\n",
      " [ 6.89196015]] b= [[-16.00081053]]\n",
      "Epoch: 25200 cost= 18.683792245 W= [[-0.42817468]\n",
      " [ 6.89432291]] b= [[-16.01724744]]\n",
      "Epoch: 25250 cost= 18.682877644 W= [[-0.42804828]\n",
      " [ 6.89667974]] b= [[-16.03364306]]\n",
      "Epoch: 25300 cost= 18.681967632 W= [[-0.4279222 ]\n",
      " [ 6.89903064]] b= [[-16.0499975]]\n",
      "Epoch: 25350 cost= 18.681062187 W= [[-0.42779644]\n",
      " [ 6.90137564]] b= [[-16.06631085]]\n",
      "Epoch: 25400 cost= 18.680161284 W= [[-0.427671  ]\n",
      " [ 6.90371475]] b= [[-16.08258323]]\n",
      "Epoch: 25450 cost= 18.679264902 W= [[-0.42754587]\n",
      " [ 6.90604798]] b= [[-16.09881472]]\n",
      "Epoch: 25500 cost= 18.678373018 W= [[-0.42742106]\n",
      " [ 6.90837535]] b= [[-16.11500545]]\n",
      "Epoch: 25550 cost= 18.677485610 W= [[-0.42729656]\n",
      " [ 6.91069687]] b= [[-16.1311555]]\n",
      "Epoch: 25600 cost= 18.676602653 W= [[-0.42717237]\n",
      " [ 6.91301257]] b= [[-16.14726499]]\n",
      "Epoch: 25650 cost= 18.675724128 W= [[-0.42704849]\n",
      " [ 6.91532244]] b= [[-16.16333401]]\n",
      "Epoch: 25700 cost= 18.674850010 W= [[-0.42692493]\n",
      " [ 6.91762652]] b= [[-16.17936266]]\n",
      "Epoch: 25750 cost= 18.673980279 W= [[-0.42680167]\n",
      " [ 6.9199248 ]] b= [[-16.19535105]]\n",
      "Epoch: 25800 cost= 18.673114911 W= [[-0.42667873]\n",
      " [ 6.92221731]] b= [[-16.21129927]]\n",
      "Epoch: 25850 cost= 18.672253886 W= [[-0.42655609]\n",
      " [ 6.92450407]] b= [[-16.22720743]]\n",
      "Epoch: 25900 cost= 18.671397181 W= [[-0.42643376]\n",
      " [ 6.92678507]] b= [[-16.24307564]]\n",
      "Epoch: 25950 cost= 18.670544775 W= [[-0.42631174]\n",
      " [ 6.92906035]] b= [[-16.25890398]]\n",
      "Epoch: 26000 cost= 18.669696646 W= [[-0.42619002]\n",
      " [ 6.93132992]] b= [[-16.27469256]]\n",
      "Epoch: 26050 cost= 18.668852773 W= [[-0.42606862]\n",
      " [ 6.93359378]] b= [[-16.29044147]]\n",
      "Epoch: 26100 cost= 18.668013134 W= [[-0.42594751]\n",
      " [ 6.93585196]] b= [[-16.30615083]]\n",
      "Epoch: 26150 cost= 18.667177708 W= [[-0.42582671]\n",
      " [ 6.93810446]] b= [[-16.32182073]]\n",
      "Epoch: 26200 cost= 18.666346474 W= [[-0.42570622]\n",
      " [ 6.9403513 ]] b= [[-16.33745126]]\n",
      "Epoch: 26250 cost= 18.665519411 W= [[-0.42558602]\n",
      " [ 6.9425925 ]] b= [[-16.35304253]]\n",
      "Epoch: 26300 cost= 18.664696497 W= [[-0.42546613]\n",
      " [ 6.94482807]] b= [[-16.36859463]]\n",
      "Epoch: 26350 cost= 18.663877713 W= [[-0.42534654]\n",
      " [ 6.94705803]] b= [[-16.38410766]]\n",
      "Epoch: 26400 cost= 18.663063037 W= [[-0.42522725]\n",
      " [ 6.94928238]] b= [[-16.39958173]]\n",
      "Epoch: 26450 cost= 18.662252450 W= [[-0.42510826]\n",
      " [ 6.95150115]] b= [[-16.41501693]]\n",
      "Epoch: 26500 cost= 18.661445929 W= [[-0.42498957]\n",
      " [ 6.95371434]] b= [[-16.43041335]]\n",
      "Epoch: 26550 cost= 18.660643455 W= [[-0.42487118]\n",
      " [ 6.95592197]] b= [[-16.4457711]]\n",
      "Epoch: 26600 cost= 18.659845008 W= [[-0.42475308]\n",
      " [ 6.95812406]] b= [[-16.46109027]]\n",
      "Epoch: 26650 cost= 18.659050567 W= [[-0.42463528]\n",
      " [ 6.96032061]] b= [[-16.47637095]]\n",
      "Epoch: 26700 cost= 18.658260113 W= [[-0.42451778]\n",
      " [ 6.96251165]] b= [[-16.49161325]]\n",
      "Epoch: 26750 cost= 18.657473625 W= [[-0.42440057]\n",
      " [ 6.96469719]] b= [[-16.50681726]]\n",
      "Epoch: 26800 cost= 18.656691083 W= [[-0.42428366]\n",
      " [ 6.96687723]] b= [[-16.52198308]]\n",
      "Epoch: 26850 cost= 18.655912468 W= [[-0.42416704]\n",
      " [ 6.9690518 ]] b= [[-16.53711081]]\n",
      "Epoch: 26900 cost= 18.655137759 W= [[-0.42405071]\n",
      " [ 6.9712209 ]] b= [[-16.55220053]]\n",
      "Epoch: 26950 cost= 18.654366938 W= [[-0.42393467]\n",
      " [ 6.97338456]] b= [[-16.56725235]]\n",
      "Epoch: 27000 cost= 18.653599985 W= [[-0.42381893]\n",
      " [ 6.97554278]] b= [[-16.58226635]]\n",
      "Epoch: 27050 cost= 18.652836879 W= [[-0.42370348]\n",
      " [ 6.97769558]] b= [[-16.59724264]]\n",
      "Epoch: 27100 cost= 18.652077603 W= [[-0.42358832]\n",
      " [ 6.97984297]] b= [[-16.61218131]]\n",
      "Epoch: 27150 cost= 18.651322137 W= [[-0.42347344]\n",
      " [ 6.98198497]] b= [[-16.62708246]]\n",
      "Epoch: 27200 cost= 18.650570462 W= [[-0.42335886]\n",
      " [ 6.98412158]] b= [[-16.64194617]]\n",
      "Epoch: 27250 cost= 18.649822558 W= [[-0.42324456]\n",
      " [ 6.98625283]] b= [[-16.65677254]]\n",
      "Epoch: 27300 cost= 18.649078407 W= [[-0.42313055]\n",
      " [ 6.98837873]] b= [[-16.67156167]]\n",
      "Epoch: 27350 cost= 18.648337990 W= [[-0.42301683]\n",
      " [ 6.99049928]] b= [[-16.68631366]]\n",
      "Epoch: 27400 cost= 18.647601288 W= [[-0.42290339]\n",
      " [ 6.99261451]] b= [[-16.70102858]]\n",
      "Epoch: 27450 cost= 18.646868282 W= [[-0.42279024]\n",
      " [ 6.99472443]] b= [[-16.71570654]]\n",
      "Epoch: 27500 cost= 18.646138955 W= [[-0.42267737]\n",
      " [ 6.99682904]] b= [[-16.73034763]]\n",
      "Epoch: 27550 cost= 18.645413287 W= [[-0.42256478]\n",
      " [ 6.99892837]] b= [[-16.74495194]]\n",
      "Epoch: 27600 cost= 18.644691260 W= [[-0.42245248]\n",
      " [ 7.00102242]] b= [[-16.75951956]]\n",
      "Epoch: 27650 cost= 18.643972857 W= [[-0.42234046]\n",
      " [ 7.00311122]] b= [[-16.77405059]]\n",
      "Epoch: 27700 cost= 18.643258058 W= [[-0.42222872]\n",
      " [ 7.00519477]] b= [[-16.78854512]]\n",
      "Epoch: 27750 cost= 18.642546845 W= [[-0.42211727]\n",
      " [ 7.00727308]] b= [[-16.80300323]]\n",
      "Epoch: 27800 cost= 18.641839202 W= [[-0.42200609]\n",
      " [ 7.00934617]] b= [[-16.81742503]]\n",
      "Epoch: 27850 cost= 18.641135109 W= [[-0.42189519]\n",
      " [ 7.01141406]] b= [[-16.8318106]]\n",
      "Epoch: 27900 cost= 18.640434549 W= [[-0.42178457]\n",
      " [ 7.01347675]] b= [[-16.84616004]]\n",
      "Epoch: 27950 cost= 18.639737504 W= [[-0.42167423]\n",
      " [ 7.01553426]] b= [[-16.86047342]]\n",
      "Epoch: 28000 cost= 18.639043957 W= [[-0.42156416]\n",
      " [ 7.0175866 ]] b= [[-16.87475086]]\n",
      "Epoch: 28050 cost= 18.638353889 W= [[-0.42145437]\n",
      " [ 7.01963378]] b= [[-16.88899242]]\n",
      "Epoch: 28100 cost= 18.637667285 W= [[-0.42134486]\n",
      " [ 7.02167582]] b= [[-16.90319822]]\n",
      "Epoch: 28150 cost= 18.636984125 W= [[-0.42123562]\n",
      " [ 7.02371274]] b= [[-16.91736832]]\n",
      "Epoch: 28200 cost= 18.636304394 W= [[-0.42112666]\n",
      " [ 7.02574453]] b= [[-16.93150284]]\n",
      "Epoch: 28250 cost= 18.635628073 W= [[-0.42101797]\n",
      " [ 7.02777122]] b= [[-16.94560184]]\n",
      "Epoch: 28300 cost= 18.634955145 W= [[-0.42090955]\n",
      " [ 7.02979283]] b= [[-16.95966543]]\n",
      "Epoch: 28350 cost= 18.634285595 W= [[-0.42080141]\n",
      " [ 7.03180935]] b= [[-16.97369369]]\n",
      "Epoch: 28400 cost= 18.633619404 W= [[-0.42069354]\n",
      " [ 7.03382081]] b= [[-16.98768672]]\n",
      "Epoch: 28450 cost= 18.632956555 W= [[-0.42058593]\n",
      " [ 7.03582721]] b= [[-17.00164459]]\n",
      "Epoch: 28500 cost= 18.632297033 W= [[-0.4204786 ]\n",
      " [ 7.03782857]] b= [[-17.0155674]]\n",
      "Epoch: 28550 cost= 18.631640820 W= [[-0.42037154]\n",
      " [ 7.03982491]] b= [[-17.02945523]]\n",
      "Epoch: 28600 cost= 18.630987899 W= [[-0.42026475]\n",
      " [ 7.04181623]] b= [[-17.04330818]]\n",
      "Epoch: 28650 cost= 18.630338255 W= [[-0.42015822]\n",
      " [ 7.04380255]] b= [[-17.05712633]]\n",
      "Epoch: 28700 cost= 18.629691870 W= [[-0.42005197]\n",
      " [ 7.04578388]] b= [[-17.07090977]]\n",
      "Epoch: 28750 cost= 18.629048729 W= [[-0.41994598]\n",
      " [ 7.04776024]] b= [[-17.08465859]]\n",
      "Epoch: 28800 cost= 18.628408815 W= [[-0.41984025]\n",
      " [ 7.04973163]] b= [[-17.09837286]]\n",
      "Epoch: 28850 cost= 18.627772112 W= [[-0.4197348 ]\n",
      " [ 7.05169806]] b= [[-17.11205269]]\n",
      "Epoch: 28900 cost= 18.627138603 W= [[-0.4196296 ]\n",
      " [ 7.05365956]] b= [[-17.12569815]]\n",
      "Epoch: 28950 cost= 18.626508273 W= [[-0.41952467]\n",
      " [ 7.05561613]] b= [[-17.13930934]]\n",
      "Epoch: 29000 cost= 18.625881107 W= [[-0.41942001]\n",
      " [ 7.05756778]] b= [[-17.15288634]]\n",
      "Epoch: 29050 cost= 18.625257087 W= [[-0.41931561]\n",
      " [ 7.05951453]] b= [[-17.16642922]]\n",
      "Epoch: 29100 cost= 18.624636198 W= [[-0.41921147]\n",
      " [ 7.0614564 ]] b= [[-17.17993809]]\n",
      "Epoch: 29150 cost= 18.624018425 W= [[-0.41910759]\n",
      " [ 7.06339338]] b= [[-17.19341303]]\n",
      "Epoch: 29200 cost= 18.623403751 W= [[-0.41900397]\n",
      " [ 7.0653255 ]] b= [[-17.20685411]]\n",
      "Epoch: 29250 cost= 18.622792162 W= [[-0.41890061]\n",
      " [ 7.06725276]] b= [[-17.22026144]]\n",
      "Epoch: 29300 cost= 18.622183641 W= [[-0.41879751]\n",
      " [ 7.06917519]] b= [[-17.23363508]]\n",
      "Epoch: 29350 cost= 18.621578174 W= [[-0.41869468]\n",
      " [ 7.07109278]] b= [[-17.24697513]]\n",
      "Epoch: 29400 cost= 18.620975745 W= [[-0.41859209]\n",
      " [ 7.07300556]] b= [[-17.26028166]]\n",
      "Epoch: 29450 cost= 18.620376339 W= [[-0.41848977]\n",
      " [ 7.07491353]] b= [[-17.27355478]]\n",
      "Epoch: 29500 cost= 18.619779940 W= [[-0.41838771]\n",
      " [ 7.07681671]] b= [[-17.28679454]]\n",
      "Epoch: 29550 cost= 18.619186534 W= [[-0.4182859 ]\n",
      " [ 7.07871511]] b= [[-17.30000106]]\n",
      "Epoch: 29600 cost= 18.618596105 W= [[-0.41818434]\n",
      " [ 7.08060874]] b= [[-17.31317439]]\n",
      "Epoch: 29650 cost= 18.618008639 W= [[-0.41808304]\n",
      " [ 7.08249761]] b= [[-17.32631464]]\n",
      "Epoch: 29700 cost= 18.617424121 W= [[-0.417982  ]\n",
      " [ 7.08438174]] b= [[-17.33942187]]\n",
      "Epoch: 29750 cost= 18.616842536 W= [[-0.41788121]\n",
      " [ 7.08626113]] b= [[-17.35249618]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-80a25acd64f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# TODO: implement sess.run for for full batch gradient descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'x1:0'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m#pred_ = sess.run(pred, feed_dict={X: train_X})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#print(pred_.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 908\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    909\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1143\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1144\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1324\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1325\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1328\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1313\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1315\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tsf36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1421\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1422\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1423\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        # TODO: implement sess.run for for full batch gradient descent\n",
    "        sess.run(optimizer, feed_dict={'x1:0': train_X, Y: train_Y})\n",
    "        #pred_ = sess.run(pred, feed_dict={X: train_X})\n",
    "        #print(pred_.shape)\n",
    "        #y_  = sess.run(Y, feed_dict={Y: train_Y})\n",
    "        #print(y_.shape)\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % 50 == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tsf36]",
   "language": "python",
   "name": "conda-env-tsf36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "# https://www.kaggle.com/c/zillow-prize-1/data\n",
    "train = pd.read_csv('train_2016.csv')\n",
    "prop = pd.read_csv('properties_2016.csv')\n",
    "\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        prop[c] = prop[c].astype(np.float32)\n",
    "\n",
    "df_train = train.merge(prop, how='left', on='parcelid')\n",
    "\n",
    "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode'], axis=1)\n",
    "y_train = df_train['logerror'].values\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "train_columns = x_train.columns\n",
    "\n",
    "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
    "    x_train[c] = (x_train[c] == True)\n",
    "\n",
    "del df_train; gc.collect()\n",
    "\n",
    "split = 90000\n",
    "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "x_train = x_train.values.astype(np.float32, copy=False)\n",
    "x_valid = x_valid.values.astype(np.float32, copy=False)\n",
    "\n",
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "d_valid = lgb.Dataset(x_valid, label=y_valid)\n",
    "\n",
    "params = {}\n",
    "params['learning_rate'] = 0.002\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'mae'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 60\n",
    "params['min_data'] = 500\n",
    "params['min_hessian'] = 1\n",
    "params['device'] = 'gpu'\n",
    "\n",
    "watchlist = [d_valid]\n",
    "clf = lgb.train(params, d_train, 500, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train_2016.csv')\n",
    "prop = pd.read_csv('properties_2016.csv')\n",
    "\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        prop[c] = prop[c].astype(np.float32)\n",
    "\n",
    "df_train = train.merge(prop, how='left', on='parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90275, 55) (90275,)\n"
     ]
    }
   ],
   "source": [
    "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode'], axis=1)\n",
    "y_train = df_train['logerror'].values\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns = x_train.columns\n",
    "\n",
    "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
    "    x_train[c] = (x_train[c] == True)\n",
    "\n",
    "del df_train; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 90000\n",
    "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "x_train = x_train.values.astype(np.float32, copy=False)\n",
    "x_valid = x_valid.values.astype(np.float32, copy=False)\n",
    "\n",
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "d_valid = lgb.Dataset(x_valid, label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.072126\n",
      "[2]\tvalid_0's l1: 0.0721243\n",
      "[3]\tvalid_0's l1: 0.072126\n",
      "[4]\tvalid_0's l1: 0.0721218\n",
      "[5]\tvalid_0's l1: 0.0721217\n",
      "[6]\tvalid_0's l1: 0.0721211\n",
      "[7]\tvalid_0's l1: 0.0721216\n",
      "[8]\tvalid_0's l1: 0.0721224\n",
      "[9]\tvalid_0's l1: 0.0721208\n",
      "[10]\tvalid_0's l1: 0.0721203\n",
      "[11]\tvalid_0's l1: 0.0721215\n",
      "[12]\tvalid_0's l1: 0.072124\n",
      "[13]\tvalid_0's l1: 0.0721219\n",
      "[14]\tvalid_0's l1: 0.0721221\n",
      "[15]\tvalid_0's l1: 0.0721225\n",
      "[16]\tvalid_0's l1: 0.0721217\n",
      "[17]\tvalid_0's l1: 0.0721202\n",
      "[18]\tvalid_0's l1: 0.0721183\n",
      "[19]\tvalid_0's l1: 0.0721193\n",
      "[20]\tvalid_0's l1: 0.0721187\n",
      "[21]\tvalid_0's l1: 0.0721169\n",
      "[22]\tvalid_0's l1: 0.0721187\n",
      "[23]\tvalid_0's l1: 0.0721122\n",
      "[24]\tvalid_0's l1: 0.0721112\n",
      "[25]\tvalid_0's l1: 0.0721075\n",
      "[26]\tvalid_0's l1: 0.0721047\n",
      "[27]\tvalid_0's l1: 0.0721055\n",
      "[28]\tvalid_0's l1: 0.0721048\n",
      "[29]\tvalid_0's l1: 0.072106\n",
      "[30]\tvalid_0's l1: 0.072106\n",
      "[31]\tvalid_0's l1: 0.0721121\n",
      "[32]\tvalid_0's l1: 0.0721068\n",
      "[33]\tvalid_0's l1: 0.0721088\n",
      "[34]\tvalid_0's l1: 0.0721104\n",
      "[35]\tvalid_0's l1: 0.0721075\n",
      "[36]\tvalid_0's l1: 0.0721045\n",
      "[37]\tvalid_0's l1: 0.0721046\n",
      "[38]\tvalid_0's l1: 0.0721052\n",
      "[39]\tvalid_0's l1: 0.0721026\n",
      "[40]\tvalid_0's l1: 0.0721049\n",
      "[41]\tvalid_0's l1: 0.0721073\n",
      "[42]\tvalid_0's l1: 0.0721098\n",
      "[43]\tvalid_0's l1: 0.0721085\n",
      "[44]\tvalid_0's l1: 0.072108\n",
      "[45]\tvalid_0's l1: 0.0721085\n",
      "[46]\tvalid_0's l1: 0.0721053\n",
      "[47]\tvalid_0's l1: 0.0721046\n",
      "[48]\tvalid_0's l1: 0.0721\n",
      "[49]\tvalid_0's l1: 0.0721014\n",
      "[50]\tvalid_0's l1: 0.0721008\n",
      "[51]\tvalid_0's l1: 0.072096\n",
      "[52]\tvalid_0's l1: 0.0720959\n",
      "[53]\tvalid_0's l1: 0.0720926\n",
      "[54]\tvalid_0's l1: 0.0720904\n",
      "[55]\tvalid_0's l1: 0.0720885\n",
      "[56]\tvalid_0's l1: 0.0720907\n",
      "[57]\tvalid_0's l1: 0.0720899\n",
      "[58]\tvalid_0's l1: 0.0720867\n",
      "[59]\tvalid_0's l1: 0.0720847\n",
      "[60]\tvalid_0's l1: 0.0720835\n",
      "[61]\tvalid_0's l1: 0.0720847\n",
      "[62]\tvalid_0's l1: 0.0720795\n",
      "[63]\tvalid_0's l1: 0.0720778\n",
      "[64]\tvalid_0's l1: 0.0720752\n",
      "[65]\tvalid_0's l1: 0.0720731\n",
      "[66]\tvalid_0's l1: 0.0720727\n",
      "[67]\tvalid_0's l1: 0.0720738\n",
      "[68]\tvalid_0's l1: 0.0720764\n",
      "[69]\tvalid_0's l1: 0.0720776\n",
      "[70]\tvalid_0's l1: 0.0720765\n",
      "[71]\tvalid_0's l1: 0.0720733\n",
      "[72]\tvalid_0's l1: 0.0720757\n",
      "[73]\tvalid_0's l1: 0.0720737\n",
      "[74]\tvalid_0's l1: 0.0720729\n",
      "[75]\tvalid_0's l1: 0.0720744\n",
      "[76]\tvalid_0's l1: 0.0720731\n",
      "[77]\tvalid_0's l1: 0.0720712\n",
      "[78]\tvalid_0's l1: 0.0720728\n",
      "[79]\tvalid_0's l1: 0.0720736\n",
      "[80]\tvalid_0's l1: 0.0720711\n",
      "[81]\tvalid_0's l1: 0.0720755\n",
      "[82]\tvalid_0's l1: 0.0720724\n",
      "[83]\tvalid_0's l1: 0.0720686\n",
      "[84]\tvalid_0's l1: 0.0720686\n",
      "[85]\tvalid_0's l1: 0.0720678\n",
      "[86]\tvalid_0's l1: 0.0720668\n",
      "[87]\tvalid_0's l1: 0.0720662\n",
      "[88]\tvalid_0's l1: 0.0720611\n",
      "[89]\tvalid_0's l1: 0.0720598\n",
      "[90]\tvalid_0's l1: 0.0720595\n",
      "[91]\tvalid_0's l1: 0.0720584\n",
      "[92]\tvalid_0's l1: 0.0720571\n",
      "[93]\tvalid_0's l1: 0.072058\n",
      "[94]\tvalid_0's l1: 0.0720568\n",
      "[95]\tvalid_0's l1: 0.0720543\n",
      "[96]\tvalid_0's l1: 0.0720535\n",
      "[97]\tvalid_0's l1: 0.0720515\n",
      "[98]\tvalid_0's l1: 0.0720507\n",
      "[99]\tvalid_0's l1: 0.0720524\n",
      "[100]\tvalid_0's l1: 0.0720548\n",
      "[101]\tvalid_0's l1: 0.0720535\n",
      "[102]\tvalid_0's l1: 0.0720501\n",
      "[103]\tvalid_0's l1: 0.0720498\n",
      "[104]\tvalid_0's l1: 0.0720481\n",
      "[105]\tvalid_0's l1: 0.0720517\n",
      "[106]\tvalid_0's l1: 0.0720524\n",
      "[107]\tvalid_0's l1: 0.0720501\n",
      "[108]\tvalid_0's l1: 0.0720511\n",
      "[109]\tvalid_0's l1: 0.0720478\n",
      "[110]\tvalid_0's l1: 0.0720493\n",
      "[111]\tvalid_0's l1: 0.0720496\n",
      "[112]\tvalid_0's l1: 0.0720458\n",
      "[113]\tvalid_0's l1: 0.0720441\n",
      "[114]\tvalid_0's l1: 0.0720456\n",
      "[115]\tvalid_0's l1: 0.0720476\n",
      "[116]\tvalid_0's l1: 0.0720472\n",
      "[117]\tvalid_0's l1: 0.0720445\n",
      "[118]\tvalid_0's l1: 0.0720432\n",
      "[119]\tvalid_0's l1: 0.072039\n",
      "[120]\tvalid_0's l1: 0.0720342\n",
      "[121]\tvalid_0's l1: 0.0720323\n",
      "[122]\tvalid_0's l1: 0.0720316\n",
      "[123]\tvalid_0's l1: 0.0720314\n",
      "[124]\tvalid_0's l1: 0.0720322\n",
      "[125]\tvalid_0's l1: 0.0720301\n",
      "[126]\tvalid_0's l1: 0.0720284\n",
      "[127]\tvalid_0's l1: 0.0720296\n",
      "[128]\tvalid_0's l1: 0.07203\n",
      "[129]\tvalid_0's l1: 0.0720314\n",
      "[130]\tvalid_0's l1: 0.0720301\n",
      "[131]\tvalid_0's l1: 0.07203\n",
      "[132]\tvalid_0's l1: 0.0720286\n",
      "[133]\tvalid_0's l1: 0.0720245\n",
      "[134]\tvalid_0's l1: 0.072024\n",
      "[135]\tvalid_0's l1: 0.0720256\n",
      "[136]\tvalid_0's l1: 0.0720239\n",
      "[137]\tvalid_0's l1: 0.0720246\n",
      "[138]\tvalid_0's l1: 0.0720233\n",
      "[139]\tvalid_0's l1: 0.0720217\n",
      "[140]\tvalid_0's l1: 0.0720171\n",
      "[141]\tvalid_0's l1: 0.0720185\n",
      "[142]\tvalid_0's l1: 0.0720174\n",
      "[143]\tvalid_0's l1: 0.0720135\n",
      "[144]\tvalid_0's l1: 0.0720155\n",
      "[145]\tvalid_0's l1: 0.0720143\n",
      "[146]\tvalid_0's l1: 0.0720172\n",
      "[147]\tvalid_0's l1: 0.0720169\n",
      "[148]\tvalid_0's l1: 0.0720178\n",
      "[149]\tvalid_0's l1: 0.0720138\n",
      "[150]\tvalid_0's l1: 0.0720167\n",
      "[151]\tvalid_0's l1: 0.072017\n",
      "[152]\tvalid_0's l1: 0.0720165\n",
      "[153]\tvalid_0's l1: 0.0720155\n",
      "[154]\tvalid_0's l1: 0.0720119\n",
      "[155]\tvalid_0's l1: 0.0720129\n",
      "[156]\tvalid_0's l1: 0.072013\n",
      "[157]\tvalid_0's l1: 0.0720148\n",
      "[158]\tvalid_0's l1: 0.0720138\n",
      "[159]\tvalid_0's l1: 0.0720173\n",
      "[160]\tvalid_0's l1: 0.0720184\n",
      "[161]\tvalid_0's l1: 0.07202\n",
      "[162]\tvalid_0's l1: 0.0720175\n",
      "[163]\tvalid_0's l1: 0.0720194\n",
      "[164]\tvalid_0's l1: 0.0720173\n",
      "[165]\tvalid_0's l1: 0.0720187\n",
      "[166]\tvalid_0's l1: 0.0720166\n",
      "[167]\tvalid_0's l1: 0.0720161\n",
      "[168]\tvalid_0's l1: 0.0720148\n",
      "[169]\tvalid_0's l1: 0.0720169\n",
      "[170]\tvalid_0's l1: 0.0720178\n",
      "[171]\tvalid_0's l1: 0.072018\n",
      "[172]\tvalid_0's l1: 0.0720181\n",
      "[173]\tvalid_0's l1: 0.0720154\n",
      "[174]\tvalid_0's l1: 0.0720113\n",
      "[175]\tvalid_0's l1: 0.0720096\n",
      "[176]\tvalid_0's l1: 0.0720099\n",
      "[177]\tvalid_0's l1: 0.0720095\n",
      "[178]\tvalid_0's l1: 0.0720064\n",
      "[179]\tvalid_0's l1: 0.0720065\n",
      "[180]\tvalid_0's l1: 0.0720054\n",
      "[181]\tvalid_0's l1: 0.0720033\n",
      "[182]\tvalid_0's l1: 0.0720004\n",
      "[183]\tvalid_0's l1: 0.0719953\n",
      "[184]\tvalid_0's l1: 0.071996\n",
      "[185]\tvalid_0's l1: 0.0719968\n",
      "[186]\tvalid_0's l1: 0.0719976\n",
      "[187]\tvalid_0's l1: 0.0719987\n",
      "[188]\tvalid_0's l1: 0.0719986\n",
      "[189]\tvalid_0's l1: 0.0719986\n",
      "[190]\tvalid_0's l1: 0.0719977\n",
      "[191]\tvalid_0's l1: 0.0719961\n",
      "[192]\tvalid_0's l1: 0.0719963\n",
      "[193]\tvalid_0's l1: 0.0719965\n",
      "[194]\tvalid_0's l1: 0.0720009\n",
      "[195]\tvalid_0's l1: 0.0719985\n",
      "[196]\tvalid_0's l1: 0.0719981\n",
      "[197]\tvalid_0's l1: 0.0719972\n",
      "[198]\tvalid_0's l1: 0.0719975\n",
      "[199]\tvalid_0's l1: 0.0719962\n",
      "[200]\tvalid_0's l1: 0.0719954\n",
      "[201]\tvalid_0's l1: 0.0719956\n",
      "[202]\tvalid_0's l1: 0.0719937\n",
      "[203]\tvalid_0's l1: 0.0719929\n",
      "[204]\tvalid_0's l1: 0.0719894\n",
      "[205]\tvalid_0's l1: 0.0719894\n",
      "[206]\tvalid_0's l1: 0.0719892\n",
      "[207]\tvalid_0's l1: 0.0719861\n",
      "[208]\tvalid_0's l1: 0.0719858\n",
      "[209]\tvalid_0's l1: 0.0719829\n",
      "[210]\tvalid_0's l1: 0.0719817\n",
      "[211]\tvalid_0's l1: 0.0719785\n",
      "[212]\tvalid_0's l1: 0.0719788\n",
      "[213]\tvalid_0's l1: 0.0719769\n",
      "[214]\tvalid_0's l1: 0.0719739\n",
      "[215]\tvalid_0's l1: 0.0719756\n",
      "[216]\tvalid_0's l1: 0.0719743\n",
      "[217]\tvalid_0's l1: 0.071971\n",
      "[218]\tvalid_0's l1: 0.0719695\n",
      "[219]\tvalid_0's l1: 0.071967\n",
      "[220]\tvalid_0's l1: 0.0719681\n",
      "[221]\tvalid_0's l1: 0.0719671\n",
      "[222]\tvalid_0's l1: 0.0719665\n",
      "[223]\tvalid_0's l1: 0.0719649\n",
      "[224]\tvalid_0's l1: 0.0719635\n",
      "[225]\tvalid_0's l1: 0.0719601\n",
      "[226]\tvalid_0's l1: 0.0719594\n",
      "[227]\tvalid_0's l1: 0.0719612\n",
      "[228]\tvalid_0's l1: 0.0719605\n",
      "[229]\tvalid_0's l1: 0.0719604\n",
      "[230]\tvalid_0's l1: 0.0719591\n",
      "[231]\tvalid_0's l1: 0.0719582\n",
      "[232]\tvalid_0's l1: 0.0719547\n",
      "[233]\tvalid_0's l1: 0.0719524\n",
      "[234]\tvalid_0's l1: 0.0719489\n",
      "[235]\tvalid_0's l1: 0.0719496\n",
      "[236]\tvalid_0's l1: 0.0719489\n",
      "[237]\tvalid_0's l1: 0.0719498\n",
      "[238]\tvalid_0's l1: 0.0719522\n",
      "[239]\tvalid_0's l1: 0.0719523\n",
      "[240]\tvalid_0's l1: 0.0719507\n",
      "[241]\tvalid_0's l1: 0.0719497\n",
      "[242]\tvalid_0's l1: 0.0719471\n",
      "[243]\tvalid_0's l1: 0.071947\n",
      "[244]\tvalid_0's l1: 0.071947\n",
      "[245]\tvalid_0's l1: 0.0719443\n",
      "[246]\tvalid_0's l1: 0.071945\n",
      "[247]\tvalid_0's l1: 0.0719406\n",
      "[248]\tvalid_0's l1: 0.071937\n",
      "[249]\tvalid_0's l1: 0.0719383\n",
      "[250]\tvalid_0's l1: 0.0719351\n",
      "[251]\tvalid_0's l1: 0.0719358\n",
      "[252]\tvalid_0's l1: 0.0719347\n",
      "[253]\tvalid_0's l1: 0.0719319\n",
      "[254]\tvalid_0's l1: 0.0719303\n",
      "[255]\tvalid_0's l1: 0.0719316\n",
      "[256]\tvalid_0's l1: 0.071933\n",
      "[257]\tvalid_0's l1: 0.0719328\n",
      "[258]\tvalid_0's l1: 0.0719307\n",
      "[259]\tvalid_0's l1: 0.0719278\n",
      "[260]\tvalid_0's l1: 0.0719279\n",
      "[261]\tvalid_0's l1: 0.0719277\n",
      "[262]\tvalid_0's l1: 0.0719244\n",
      "[263]\tvalid_0's l1: 0.071923\n",
      "[264]\tvalid_0's l1: 0.0719215\n",
      "[265]\tvalid_0's l1: 0.0719186\n",
      "[266]\tvalid_0's l1: 0.071921\n",
      "[267]\tvalid_0's l1: 0.071918\n",
      "[268]\tvalid_0's l1: 0.0719162\n",
      "[269]\tvalid_0's l1: 0.0719152\n",
      "[270]\tvalid_0's l1: 0.0719134\n",
      "[271]\tvalid_0's l1: 0.0719123\n",
      "[272]\tvalid_0's l1: 0.0719142\n",
      "[273]\tvalid_0's l1: 0.071912\n",
      "[274]\tvalid_0's l1: 0.0719117\n",
      "[275]\tvalid_0's l1: 0.0719136\n",
      "[276]\tvalid_0's l1: 0.0719129\n",
      "[277]\tvalid_0's l1: 0.0719137\n",
      "[278]\tvalid_0's l1: 0.0719137\n",
      "[279]\tvalid_0's l1: 0.0719142\n",
      "[280]\tvalid_0's l1: 0.0719123\n",
      "[281]\tvalid_0's l1: 0.0719106\n",
      "[282]\tvalid_0's l1: 0.0719075\n",
      "[283]\tvalid_0's l1: 0.0719048\n",
      "[284]\tvalid_0's l1: 0.0719027\n",
      "[285]\tvalid_0's l1: 0.0719019\n",
      "[286]\tvalid_0's l1: 0.0719018\n",
      "[287]\tvalid_0's l1: 0.071902\n",
      "[288]\tvalid_0's l1: 0.0719014\n",
      "[289]\tvalid_0's l1: 0.0718996\n",
      "[290]\tvalid_0's l1: 0.0719008\n",
      "[291]\tvalid_0's l1: 0.0719003\n",
      "[292]\tvalid_0's l1: 0.0719001\n",
      "[293]\tvalid_0's l1: 0.071899\n",
      "[294]\tvalid_0's l1: 0.071897\n",
      "[295]\tvalid_0's l1: 0.0718942\n",
      "[296]\tvalid_0's l1: 0.0718914\n",
      "[297]\tvalid_0's l1: 0.0718899\n",
      "[298]\tvalid_0's l1: 0.0718879\n",
      "[299]\tvalid_0's l1: 0.0718875\n",
      "[300]\tvalid_0's l1: 0.071886\n",
      "[301]\tvalid_0's l1: 0.071888\n",
      "[302]\tvalid_0's l1: 0.0718863\n",
      "[303]\tvalid_0's l1: 0.0718863\n",
      "[304]\tvalid_0's l1: 0.0718868\n",
      "[305]\tvalid_0's l1: 0.0718866\n",
      "[306]\tvalid_0's l1: 0.0718886\n",
      "[307]\tvalid_0's l1: 0.0718889\n",
      "[308]\tvalid_0's l1: 0.0718884\n",
      "[309]\tvalid_0's l1: 0.0718888\n",
      "[310]\tvalid_0's l1: 0.071889\n",
      "[311]\tvalid_0's l1: 0.0718878\n",
      "[312]\tvalid_0's l1: 0.0718894\n",
      "[313]\tvalid_0's l1: 0.0718876\n",
      "[314]\tvalid_0's l1: 0.0718873\n",
      "[315]\tvalid_0's l1: 0.0718869\n",
      "[316]\tvalid_0's l1: 0.0718864\n",
      "[317]\tvalid_0's l1: 0.0718859\n",
      "[318]\tvalid_0's l1: 0.0718872\n",
      "[319]\tvalid_0's l1: 0.0718867\n",
      "[320]\tvalid_0's l1: 0.0718909\n",
      "[321]\tvalid_0's l1: 0.0718909\n",
      "[322]\tvalid_0's l1: 0.0718918\n",
      "[323]\tvalid_0's l1: 0.0718889\n",
      "[324]\tvalid_0's l1: 0.0718905\n",
      "[325]\tvalid_0's l1: 0.0718918\n",
      "[326]\tvalid_0's l1: 0.0718938\n",
      "[327]\tvalid_0's l1: 0.071892\n",
      "[328]\tvalid_0's l1: 0.0718908\n",
      "[329]\tvalid_0's l1: 0.0718899\n",
      "[330]\tvalid_0's l1: 0.0718888\n",
      "[331]\tvalid_0's l1: 0.07189\n",
      "[332]\tvalid_0's l1: 0.0718866\n",
      "[333]\tvalid_0's l1: 0.0718829\n",
      "[334]\tvalid_0's l1: 0.0718825\n",
      "[335]\tvalid_0's l1: 0.0718826\n",
      "[336]\tvalid_0's l1: 0.0718842\n",
      "[337]\tvalid_0's l1: 0.0718854\n",
      "[338]\tvalid_0's l1: 0.0718844\n",
      "[339]\tvalid_0's l1: 0.0718809\n",
      "[340]\tvalid_0's l1: 0.0718789\n",
      "[341]\tvalid_0's l1: 0.0718767\n",
      "[342]\tvalid_0's l1: 0.0718754\n",
      "[343]\tvalid_0's l1: 0.0718762\n",
      "[344]\tvalid_0's l1: 0.0718769\n",
      "[345]\tvalid_0's l1: 0.0718782\n",
      "[346]\tvalid_0's l1: 0.0718788\n",
      "[347]\tvalid_0's l1: 0.071879\n",
      "[348]\tvalid_0's l1: 0.0718797\n",
      "[349]\tvalid_0's l1: 0.0718811\n",
      "[350]\tvalid_0's l1: 0.0718813\n",
      "[351]\tvalid_0's l1: 0.0718805\n",
      "[352]\tvalid_0's l1: 0.0718808\n",
      "[353]\tvalid_0's l1: 0.0718806\n",
      "[354]\tvalid_0's l1: 0.0718799\n",
      "[355]\tvalid_0's l1: 0.0718821\n",
      "[356]\tvalid_0's l1: 0.0718824\n",
      "[357]\tvalid_0's l1: 0.0718831\n",
      "[358]\tvalid_0's l1: 0.0718825\n",
      "[359]\tvalid_0's l1: 0.0718835\n",
      "[360]\tvalid_0's l1: 0.0718861\n",
      "[361]\tvalid_0's l1: 0.0718875\n",
      "[362]\tvalid_0's l1: 0.0718905\n",
      "[363]\tvalid_0's l1: 0.0718895\n",
      "[364]\tvalid_0's l1: 0.0718872\n",
      "[365]\tvalid_0's l1: 0.0718858\n",
      "[366]\tvalid_0's l1: 0.0718868\n",
      "[367]\tvalid_0's l1: 0.0718868\n",
      "[368]\tvalid_0's l1: 0.0718847\n",
      "[369]\tvalid_0's l1: 0.0718863\n",
      "[370]\tvalid_0's l1: 0.0718869\n",
      "[371]\tvalid_0's l1: 0.0718845\n",
      "[372]\tvalid_0's l1: 0.0718846\n",
      "[373]\tvalid_0's l1: 0.071882\n",
      "[374]\tvalid_0's l1: 0.071883\n",
      "[375]\tvalid_0's l1: 0.0718805\n",
      "[376]\tvalid_0's l1: 0.0718822\n",
      "[377]\tvalid_0's l1: 0.0718829\n",
      "[378]\tvalid_0's l1: 0.0718847\n",
      "[379]\tvalid_0's l1: 0.0718848\n",
      "[380]\tvalid_0's l1: 0.0718864\n",
      "[381]\tvalid_0's l1: 0.0718871\n",
      "[382]\tvalid_0's l1: 0.0718881\n",
      "[383]\tvalid_0's l1: 0.0718852\n",
      "[384]\tvalid_0's l1: 0.0718855\n",
      "[385]\tvalid_0's l1: 0.0718851\n",
      "[386]\tvalid_0's l1: 0.0718873\n",
      "[387]\tvalid_0's l1: 0.0718887\n",
      "[388]\tvalid_0's l1: 0.0718911\n",
      "[389]\tvalid_0's l1: 0.07189\n",
      "[390]\tvalid_0's l1: 0.0718916\n",
      "[391]\tvalid_0's l1: 0.0718951\n",
      "[392]\tvalid_0's l1: 0.0718962\n",
      "[393]\tvalid_0's l1: 0.0718976\n",
      "[394]\tvalid_0's l1: 0.0718989\n",
      "[395]\tvalid_0's l1: 0.0718984\n",
      "[396]\tvalid_0's l1: 0.0718992\n",
      "[397]\tvalid_0's l1: 0.0719024\n",
      "[398]\tvalid_0's l1: 0.0719024\n",
      "[399]\tvalid_0's l1: 0.071901\n",
      "[400]\tvalid_0's l1: 0.071902\n",
      "[401]\tvalid_0's l1: 0.071905\n",
      "[402]\tvalid_0's l1: 0.0719041\n",
      "[403]\tvalid_0's l1: 0.0719042\n",
      "[404]\tvalid_0's l1: 0.0719041\n",
      "[405]\tvalid_0's l1: 0.0719055\n",
      "[406]\tvalid_0's l1: 0.0719068\n",
      "[407]\tvalid_0's l1: 0.0719019\n",
      "[408]\tvalid_0's l1: 0.0719018\n",
      "[409]\tvalid_0's l1: 0.0718998\n",
      "[410]\tvalid_0's l1: 0.071898\n",
      "[411]\tvalid_0's l1: 0.0718986\n",
      "[412]\tvalid_0's l1: 0.0718995\n",
      "[413]\tvalid_0's l1: 0.0719026\n",
      "[414]\tvalid_0's l1: 0.071902\n",
      "[415]\tvalid_0's l1: 0.071904\n",
      "[416]\tvalid_0's l1: 0.0719033\n",
      "[417]\tvalid_0's l1: 0.0719021\n",
      "[418]\tvalid_0's l1: 0.0719027\n",
      "[419]\tvalid_0's l1: 0.0719027\n",
      "[420]\tvalid_0's l1: 0.0719019\n",
      "[421]\tvalid_0's l1: 0.0719035\n",
      "[422]\tvalid_0's l1: 0.0719038\n",
      "[423]\tvalid_0's l1: 0.0719049\n",
      "[424]\tvalid_0's l1: 0.0719059\n",
      "[425]\tvalid_0's l1: 0.071905\n",
      "[426]\tvalid_0's l1: 0.0719026\n",
      "[427]\tvalid_0's l1: 0.0719051\n",
      "[428]\tvalid_0's l1: 0.0719037\n",
      "[429]\tvalid_0's l1: 0.0719035\n",
      "[430]\tvalid_0's l1: 0.0719025\n",
      "[431]\tvalid_0's l1: 0.0719022\n",
      "[432]\tvalid_0's l1: 0.0719023\n",
      "[433]\tvalid_0's l1: 0.0719036\n",
      "[434]\tvalid_0's l1: 0.0719033\n",
      "[435]\tvalid_0's l1: 0.071904\n",
      "[436]\tvalid_0's l1: 0.0719039\n",
      "[437]\tvalid_0's l1: 0.0719036\n",
      "[438]\tvalid_0's l1: 0.0719051\n",
      "[439]\tvalid_0's l1: 0.0719042\n",
      "[440]\tvalid_0's l1: 0.0719044\n",
      "[441]\tvalid_0's l1: 0.0719024\n",
      "[442]\tvalid_0's l1: 0.0719011\n",
      "[443]\tvalid_0's l1: 0.0719005\n",
      "[444]\tvalid_0's l1: 0.071902\n",
      "[445]\tvalid_0's l1: 0.0719021\n",
      "[446]\tvalid_0's l1: 0.071904\n",
      "[447]\tvalid_0's l1: 0.0719041\n",
      "[448]\tvalid_0's l1: 0.0719066\n",
      "[449]\tvalid_0's l1: 0.0719102\n",
      "[450]\tvalid_0's l1: 0.0719114\n",
      "[451]\tvalid_0's l1: 0.0719112\n",
      "[452]\tvalid_0's l1: 0.0719136\n",
      "[453]\tvalid_0's l1: 0.0719154\n",
      "[454]\tvalid_0's l1: 0.0719175\n",
      "[455]\tvalid_0's l1: 0.071918\n",
      "[456]\tvalid_0's l1: 0.0719199\n",
      "[457]\tvalid_0's l1: 0.0719187\n",
      "[458]\tvalid_0's l1: 0.0719198\n",
      "[459]\tvalid_0's l1: 0.0719202\n",
      "[460]\tvalid_0's l1: 0.0719215\n",
      "[461]\tvalid_0's l1: 0.0719209\n",
      "[462]\tvalid_0's l1: 0.071918\n",
      "[463]\tvalid_0's l1: 0.0719196\n",
      "[464]\tvalid_0's l1: 0.0719208\n",
      "[465]\tvalid_0's l1: 0.0719206\n",
      "[466]\tvalid_0's l1: 0.071923\n",
      "[467]\tvalid_0's l1: 0.0719202\n",
      "[468]\tvalid_0's l1: 0.0719193\n",
      "[469]\tvalid_0's l1: 0.0719191\n",
      "[470]\tvalid_0's l1: 0.0719176\n",
      "[471]\tvalid_0's l1: 0.0719148\n",
      "[472]\tvalid_0's l1: 0.0719134\n",
      "[473]\tvalid_0's l1: 0.0719125\n",
      "[474]\tvalid_0's l1: 0.0719129\n",
      "[475]\tvalid_0's l1: 0.0719157\n",
      "[476]\tvalid_0's l1: 0.0719145\n",
      "[477]\tvalid_0's l1: 0.0719131\n",
      "[478]\tvalid_0's l1: 0.071914\n",
      "[479]\tvalid_0's l1: 0.0719145\n",
      "[480]\tvalid_0's l1: 0.071912\n",
      "[481]\tvalid_0's l1: 0.0719078\n",
      "[482]\tvalid_0's l1: 0.0719054\n",
      "[483]\tvalid_0's l1: 0.0719077\n",
      "[484]\tvalid_0's l1: 0.0719092\n",
      "[485]\tvalid_0's l1: 0.071911\n",
      "[486]\tvalid_0's l1: 0.0719118\n",
      "[487]\tvalid_0's l1: 0.0719115\n",
      "[488]\tvalid_0's l1: 0.0719093\n",
      "[489]\tvalid_0's l1: 0.0719069\n",
      "[490]\tvalid_0's l1: 0.0719073\n",
      "[491]\tvalid_0's l1: 0.0719085\n",
      "[492]\tvalid_0's l1: 0.0719076\n",
      "[493]\tvalid_0's l1: 0.0719081\n",
      "[494]\tvalid_0's l1: 0.0719093\n",
      "[495]\tvalid_0's l1: 0.0719106\n",
      "[496]\tvalid_0's l1: 0.0719156\n",
      "[497]\tvalid_0's l1: 0.0719161\n",
      "[498]\tvalid_0's l1: 0.0719168\n",
      "[499]\tvalid_0's l1: 0.071916\n",
      "[500]\tvalid_0's l1: 0.0719165\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['learning_rate'] = 0.002\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'mae'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 60\n",
    "params['min_data'] = 500\n",
    "params['min_hessian'] = 1\n",
    "params['device'] = 'gpu'\n",
    "\n",
    "watchlist = [d_valid]\n",
    "clf = lgb.train(params, d_train, 500, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'D:\\\\mingw-w64\\\\x86_64-7.3.0-posix-seh-rt_v5-rev0\\\\mingw64\\\\bin'\n",
    "cv_path = 'D:\\\\opencv\\\\build\\\\install\\\\x64\\\\vc14\\\\bin'\n",
    "os.environ['PATH'] = cv_path + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# use DMatrix for xgbosot\n",
    "dtrain = xgb.DMatrix(X_train.repeat(300000,axis=0), label=y_train.repeat(300000))\n",
    "dtest = xgb.DMatrix(X_test.repeat(300000,axis=0), label=y_test.repeat(300000))\n",
    "\n",
    "# set xgboost params\n",
    "param = {\n",
    "    'tree_method': 'gpu_exact',\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3,\n",
    "    'n_jobs':10}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations\n",
    "\n",
    "#------------- numpy array ------------------\n",
    "# training and testing - numpy matrices\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGBoost gets its lauded performance and efficiency gains by utilizing its own optimized data structure for datasets called a DMatrix, You can construct DMatrix from numpy.arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DMatrix: churn_dmatrix\n",
    "churn_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:logistic\", \"max_depth\":3}\n",
    "\n",
    "# Perform cross-validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=3, num_boost_round=5, metrics=\"error\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Print the accuracy\n",
    "print(((1-cv_results[\"test-error-mean\"]).iloc[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||test-error-mean|test-error-std|train-error-mean|train-error-std|\n",
    "|--|----|----|----|-----|\n",
    "|0|0.28378|0.001932|0.28232|0.002366|\n",
    "|1|0.27190|0.001932|0.26951|0.001855|\n",
    "|2|0.25798|0.003963|0.25605|0.003213|\n",
    "|3|0.25434|0.003827|0.25090|0.001845|\n",
    "|4|0.24852|0.000934|0.24654|0.001981|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instead of using error, we use **auc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross_validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=3, num_boost_round=5, metrics=\"auc\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Print the AUC\n",
    "print((cv_results[\"test-auc-mean\"]).iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||test-auc-mean|test-auc-std|train-auc-mean|train-auc-std|\n",
    "|--|------|-----|-----|------|\n",
    "|0|0.767863|0.002820|0.768893|0.001544|\n",
    "|1|0.789157|0.006846|0.790864|0.006758|\n",
    "|2|0.814476|0.005997|0.815872|0.003900|\n",
    "|3|0.821682|0.003912|0.822959|0.002018|\n",
    "|4|0.826191|0.001937|0.827528|0.000769|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When to use XGBoost\n",
    "* You have a large number of training samples\n",
    "    * $> 1000$ training samples, $< 100$ features\n",
    "    * Number of features $<$ Number of training samples\n",
    "* You have a mixture of categorical and numerical features, or just numeric features\n",
    "\n",
    "# When not to use XGBoost\n",
    "* Deep learning problem\n",
    "    * Image Recongnition\n",
    "    * Computer Vision\n",
    "    * NLP or understanding problem\n",
    "* Small number of training samples\n",
    "\n",
    "# Objective (loss) functions and base learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data)\n",
    "X.columns = boston.feature_names\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24.0\n",
       "1    21.6\n",
       "2    34.7\n",
       "3    33.4\n",
       "4    36.2\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Series(boston.target)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Objective (loss) functions\n",
    "    * $reg:linear$ use for regression problems\n",
    "    * $reg:logistic$ use for classification problems when you want just decision, not probability\n",
    "    * $binary:logistic$ use when you want probability rather than just decision\n",
    "    \n",
    "### By default, XGBoost uses **trees as base learners**, so you don't have to specify that you want to use trees here with $booster='gbtree'$   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.12579</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.556</td>\n",
       "      <td>29.1</td>\n",
       "      <td>4.5667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>382.84</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.47547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>6.113</td>\n",
       "      <td>58.8</td>\n",
       "      <td>4.0019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>396.23</td>\n",
       "      <td>12.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.85204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.965</td>\n",
       "      <td>89.2</td>\n",
       "      <td>4.0123</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>392.53</td>\n",
       "      <td>13.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.63796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.096</td>\n",
       "      <td>84.5</td>\n",
       "      <td>4.4619</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.02</td>\n",
       "      <td>10.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>5.66998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>6.683</td>\n",
       "      <td>96.8</td>\n",
       "      <td>1.3567</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>375.33</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS   RAD    TAX  \\\n",
       "188  0.12579  45.0   3.44   0.0  0.437  6.556  29.1  4.5667   5.0  398.0   \n",
       "319  0.47547   0.0   9.90   0.0  0.544  6.113  58.8  4.0019   4.0  304.0   \n",
       "21   0.85204   0.0   8.14   0.0  0.538  5.965  89.2  4.0123   4.0  307.0   \n",
       "14   0.63796   0.0   8.14   0.0  0.538  6.096  84.5  4.4619   4.0  307.0   \n",
       "369  5.66998   0.0  18.10   1.0  0.631  6.683  96.8  1.3567  24.0  666.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "188     15.2  382.84   4.56  \n",
       "319     18.4  396.23  12.73  \n",
       "21      21.0  392.53  13.83  \n",
       "14      21.0  380.02  10.26  \n",
       "369     20.2  375.33   3.73  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Specify an objective of $reg:linear$ and use **10 trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary:logistic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbooster\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gbtree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_delta_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolsample_bylevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_lambda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_pos_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Implementation of the scikit-learn API for XGBoost classification.\n",
       "\n",
       "    Parameters\n",
       "----------\n",
       "max_depth : int\n",
       "    Maximum tree depth for base learners.\n",
       "learning_rate : float\n",
       "    Boosting learning rate (xgb's \"eta\")\n",
       "n_estimators : int\n",
       "    Number of boosted trees to fit.\n",
       "silent : boolean\n",
       "    Whether to print messages while running boosting.\n",
       "objective : string or callable\n",
       "    Specify the learning task and the corresponding learning objective or\n",
       "    a custom objective function to be used (see note below).\n",
       "booster: string\n",
       "    Specify which booster to use: gbtree, gblinear or dart.\n",
       "nthread : int\n",
       "    Number of parallel threads used to run xgboost.  (Deprecated, please use n_jobs)\n",
       "n_jobs : int\n",
       "    Number of parallel threads used to run xgboost.  (replaces nthread)\n",
       "gamma : float\n",
       "    Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
       "min_child_weight : int\n",
       "    Minimum sum of instance weight(hessian) needed in a child.\n",
       "max_delta_step : int\n",
       "    Maximum delta step we allow each tree's weight estimation to be.\n",
       "subsample : float\n",
       "    Subsample ratio of the training instance.\n",
       "colsample_bytree : float\n",
       "    Subsample ratio of columns when constructing each tree.\n",
       "colsample_bylevel : float\n",
       "    Subsample ratio of columns for each split, in each level.\n",
       "reg_alpha : float (xgb's alpha)\n",
       "    L1 regularization term on weights\n",
       "reg_lambda : float (xgb's lambda)\n",
       "    L2 regularization term on weights\n",
       "scale_pos_weight : float\n",
       "    Balancing of positive and negative weights.\n",
       "base_score:\n",
       "    The initial prediction score of all instances, global bias.\n",
       "seed : int\n",
       "    Random number seed.  (Deprecated, please use random_state)\n",
       "random_state : int\n",
       "    Random number seed.  (replaces seed)\n",
       "missing : float, optional\n",
       "    Value in the data which needs to be present as a missing value. If\n",
       "    None, defaults to np.nan.\n",
       "**kwargs : dict, optional\n",
       "    Keyword arguments for XGBoost Booster object.  Full documentation of parameters can\n",
       "    be found here: https://github.com/dmlc/xgboost/blob/master/doc/parameter.md.\n",
       "    Attempting to set a parameter via the constructor args and **kwargs dict simultaneously\n",
       "    will result in a TypeError.\n",
       "    Note:\n",
       "        **kwargs is unsupported by Sklearn.  We do not guarantee that parameters passed via\n",
       "        this argument will interact properly with Sklearn.\n",
       "\n",
       "Note\n",
       "----\n",
       "A custom objective function can be provided for the ``objective``\n",
       "parameter. In this case, it should have the signature\n",
       "``objective(y_true, y_pred) -> grad, hess``:\n",
       "\n",
       "y_true: array_like of shape [n_samples]\n",
       "    The target values\n",
       "y_pred: array_like of shape [n_samples]\n",
       "    The predicted values\n",
       "\n",
       "grad: array_like of shape [n_samples]\n",
       "    The value of the gradient for each sample point.\n",
       "hess: array_like of shape [n_samples]\n",
       "    The value of the second derivative for each sample point\n",
       "\u001b[1;31mFile:\u001b[0m           d:\\anaconda\\envs\\py36\\lib\\site-packages\\xgboost-0.71-py3.6.egg\\xgboost\\sklearn.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?xgb.XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective='reg:linear', n_estimators=10, seed=112, updater='grow_gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.78716946,  10.50298691,  17.08686638,  12.33439445,   7.14900589], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = xg_reg.predict(X_test)\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53     23.4\n",
       "490     8.1\n",
       "240    22.0\n",
       "375    15.0\n",
       "417    10.4\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.3515554285535458"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear base learners\n",
    "* Allows you to create a regularized linear regression using XGBoost's\n",
    "* Because it's uncommon, you have to use **XGBoost's own non-scikit-learn** compatible functions to build the model, such as $xgb.train()$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gblinear', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=10,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=112,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective='reg:linear', booster='gblinear', n_estimators=10, seed=112)\n",
    "xg_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 23.2250824 ,  21.23382759,  25.30643463,  20.00174904,  14.4765892 ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = xg_reg.predict(X_test)\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.2354372577190738"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "DM_test = xgb.DMatrix(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "b'[06:00:15] E:\\\\xgboostGPU\\\\src\\\\linear\\\\linear_updater.cc:16: Unknown linear updater grow_gpu_hist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-539dfebc61f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'objective'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'reg:linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'booster'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'gblinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tree_method'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'gpu_hist'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxg_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDM_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\py36\\lib\\site-packages\\xgboost-0.71-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py36\\lib\\site-packages\\xgboost-0.71-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py36\\lib\\site-packages\\xgboost-0.71-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m--> 894\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m    895\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py36\\lib\\site-packages\\xgboost-0.71-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: b'[06:00:15] E:\\\\xgboostGPU\\\\src\\\\linear\\\\linear_updater.cc:16: Unknown linear updater grow_gpu_hist'"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'reg:linear', 'booster': 'gblinear', 'tree_method':'gpu_hist'}\n",
    "xg_reg = xgb.train(params=params, dtrain=DM_train, num_boost_round=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.8958784218085043"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = xg_reg.predict(DM_test)\n",
    "np.sqrt(mean_squared_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:37: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "D:\\Anaconda\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:42: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with GPU ...\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "if sys.version_info[0] >= 3:\n",
    "    from urllib.request import urlretrieve\n",
    "else:\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\"\n",
    "dmatrix_train_filename = \"higgs_train.dmatrix\"\n",
    "dmatrix_test_filename = \"higgs_test.dmatrix\"\n",
    "csv_filename = \"HIGGS.csv.gz\"\n",
    "train_rows = 10500000\n",
    "test_rows = 500000\n",
    "num_round = 1000\n",
    "\n",
    "plot = True\n",
    "\n",
    "# return xgboost dmatrix\n",
    "def load_higgs():\n",
    "    if os.path.isfile(dmatrix_train_filename) and os.path.isfile(dmatrix_test_filename):           \n",
    "        dtrain = xgb.DMatrix(dmatrix_train_filename)\n",
    "        dtest = xgb.DMatrix(dmatrix_test_filename)\n",
    "        print(\"Loading cached dmatrix...\")\n",
    "        return dtrain, dtest\n",
    "\n",
    "#     if not os.path.isfile(csv_filename):\n",
    "#         print(\"Downloading higgs file...\")\n",
    "#         urlretrieve(data_url, csv_filename)\n",
    "\n",
    "    df_higgs_train = pandas.read_csv(csv_filename, dtype=np.float32, \n",
    "                                     nrows=train_rows, header=None)\n",
    "    dtrain = xgb.DMatrix(df_higgs_train.ix[:, 1:29], df_higgs_train[0])\n",
    "    dtrain.save_binary(dmatrix_train_filename)\n",
    "    df_higgs_test = pandas.read_csv(csv_filename, dtype=np.float32, \n",
    "                                    skiprows=train_rows, nrows=test_rows, \n",
    "                                    header=None)\n",
    "    dtest = xgb.DMatrix(df_higgs_test.ix[:, 1:29], df_higgs_test[0])\n",
    "    dtest.save_binary(dmatrix_test_filename)\n",
    "\n",
    "    return dtrain, dtest\n",
    "\n",
    "\n",
    "dtrain, dtest = load_higgs()\n",
    "param = {}\n",
    "param['objective'] = 'binary:logitraw'\n",
    "param['eval_metric'] = 'error'\n",
    "param['tree_method'] = 'gpu_hist'\n",
    "param['silent'] = 1\n",
    "\n",
    "print(\"Training with GPU ...\")\n",
    "tmp = time.time()\n",
    "gpu_res = {}\n",
    "xgb.train(param, dtrain, num_round, evals=[(dtest, \"test\")], \n",
    "          evals_result=gpu_res)\n",
    "gpu_time = time.time() - tmp\n",
    "print(\"GPU Training Time: %s seconds\" % (str(gpu_time)))\n",
    "\n",
    "print(\"Training with CPU ...\")\n",
    "param['tree_method'] = 'hist'\n",
    "tmp = time.time()\n",
    "cpu_res = {}\n",
    "xgb.train(param, dtrain, num_round, evals=[(dtest, \"test\")], \n",
    "          evals_result=cpu_res)\n",
    "cpu_time = time.time() - tmp\n",
    "print(\"CPU Training Time: %s seconds\" % (str(cpu_time)))\n",
    "\n",
    "if plot:\n",
    "    import matplotlib.pyplot as plt\n",
    "    min_error = min(min(gpu_res[\"test\"][param['eval_metric']]), \n",
    "                    min(cpu_res[\"test\"][param['eval_metric']]))\n",
    "    gpu_iteration_time = [x / (num_round * 1.0) * gpu_time for x in range(0, num_round)]\n",
    "    cpu_iteration_time = [x / (num_round * 1.0) * cpu_time for x in range(0, num_round)]\n",
    "    plt.plot(gpu_iteration_time, gpu_res['test'][param['eval_metric']], label='Tesla P100')\n",
    "    plt.plot(cpu_iteration_time, cpu_res['test'][param['eval_metric']], label='2x Haswell E5-2698 v3 (32 cores)')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Test error')\n",
    "    plt.axhline(y=min_error, color='r', linestyle='dashed')\n",
    "    plt.margins(x=0)\n",
    "    plt.ylim((0.23, 0.35))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

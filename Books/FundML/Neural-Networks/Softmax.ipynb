{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 7005 on context None\n",
      "Mapped name None to device cuda: Quadro K2100M (0000:01:00.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cuda,floatX=float32\"\n",
    "import theano\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2)\n",
    "# y_train = y_train.astype(int)\n",
    "# y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "softmax.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = softmax.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 92.09\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: {:.4}'.format(100*accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 91.14\n"
     ]
    }
   ],
   "source": [
    "# one-vs-rest logistic regression\n",
    "softmax = LogisticRegression(C=1e5, solver='lbfgs', multi_class='ovr')\n",
    "softmax.fit(X_train, y_train)\n",
    "y_pred = softmax.predict(X_test)\n",
    "print('Accuracy score: {:.4}'.format(100*accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    \"\"\"\n",
    "    Compute softmax values for each sets of scores in V.\n",
    "    each column of V is a set of scores.    \n",
    "    Z: a numpy array of shape (N, C)\n",
    "    return a numpy array of shape (N, C)\n",
    "    \"\"\"\n",
    "    e_Z = np.exp(Z)\n",
    "    return e_Z/np.sum(e_Z, axis=1, keepdims=True)\n",
    "\n",
    "def softmax_stable(Z):\n",
    "    \"\"\"\n",
    "    Compute softmax values for each sets of scores in Z.\n",
    "    each row of Z is a set of scores.    \n",
    "    \"\"\"\n",
    "    Z-=np.max(Z, axis=1, keepdims=True)\n",
    "    e_Z = np.exp(Z)\n",
    "    return e_Z/np.sum(e_Z, axis=1, keepdims=True)\n",
    "\n",
    "def softmax_loss(X, y, W):\n",
    "    \"\"\"\n",
    "    W: 2d numpy array of shape (d, C), \n",
    "        each column correspoding to one output node\n",
    "    X: 2d numpy array of shape (N, d), each row is one data point\n",
    "    y: 1d numpy array -- label of each row of X \n",
    "    \"\"\"\n",
    "    A=softmax_stable(np.dot(X, W))\n",
    "    enum=range(len(A))\n",
    "    return -np.mean(np.log(A[enum, y]))\n",
    "\n",
    "def softmax_grad(X, y, W):\n",
    "    \"\"\"\n",
    "    W: 2d numpy array of shape (d, C), \n",
    "        each column correspoding to one output node\n",
    "    X: 2d numpy array of shape (N, d), each row is one data point\n",
    "    y: 1d numpy array -- label of each row of X \n",
    "    \"\"\"\n",
    "    A=softmax_stable(np.dot(X, W))\n",
    "    enum=range(len(A))\n",
    "    A[enum, y]-=1\n",
    "    return np.dot(X.T, A)/len(X)\n",
    "\n",
    "def softmax_fit(X, y, W, lr=0.01, nepoches=100, batch_size=10):\n",
    "    W_old = W.copy()\n",
    "    # store history of loss in loss_hist\n",
    "    loss_hist=[softmax_loss(X, y, W)]\n",
    "    ep=0\n",
    "    n_batches=int(len(X)/batch_size)\n",
    "    while ep < nepoches:\n",
    "        mix_idx = np.random.permutation(X.shape[0])\n",
    "        for i in range(n_batches):\n",
    "            batch=mix_idx[batch_size*i:batch_size*(i+1)]\n",
    "            X_batch, y_batch = X[batch], y[batch]\n",
    "            W-=lr*(softmax_grad(X_batch, y_batch, W))\n",
    "        loss_hist.append(softmax_loss(X, y, W))\n",
    "        if np.linalg.norm(W)/W.size < 1e-5:\n",
    "            break\n",
    "        ep+=1\n",
    "        W_old=W.copy()\n",
    "    return W, loss_hist\n",
    "\n",
    "def pred(W, X):\n",
    "    \"\"\"\n",
    "    predict output of each columns of X\n",
    "    Class of each x_i is determined by location of max probability\n",
    "    Note that class are indexed by [0, 1, 2, ...., C-1]\n",
    "    \"\"\"\n",
    "    return np.argmax(softmax_stable(np.dot(X, W)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "C = 3 \n",
    "N = 3000\n",
    "X = np.random.randn(N, d)\n",
    "y = np.random.randint(0, C, N)\n",
    "W = np.random.randn(d, C)\n",
    "W, loss_hist = softmax_fit(X, y, W, batch_size = 100, lr= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b381443e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Softmax to MNist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_shape = (X_train.shape[1], len(np.unique(y_train)))\n",
    "W = np.random.normal(0, np.sqrt(2./np.sum(W_shape)), W_shape)\n",
    "W, loss_hist = softmax_fit(X_train, y_train, W, batch_size = 100, lr= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 85.44\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: {:.4}'.format(100*accuracy_score(y_test, pred(W, X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
